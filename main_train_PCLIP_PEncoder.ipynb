{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyOwNF/XGPGPCpQkOKnFVjn0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JiSmFahELEfC","executionInfo":{"status":"ok","timestamp":1702106791152,"user_tz":-540,"elapsed":25016,"user":{"displayName":"김채현코랩1","userId":"16338580172282075794"}},"outputId":"85623e21-af32-405d-9a7b-0a1460ba55b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["cd drive/MyDrive/COSE474_PCLIP/diffusion-point-cloud"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8DJyivAbL-6z","executionInfo":{"status":"ok","timestamp":1702106791152,"user_tz":-540,"elapsed":4,"user":{"displayName":"김채현코랩1","userId":"16338580172282075794"}},"outputId":"78dfda5e-456d-46b2-c019-0aa34f031fe0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/COSE474_PCLIP/diffusion-point-cloud\n"]}]},{"cell_type":"code","source":["# !git clone https://github.com/luost26/diffusion-point-cloud.git"],"metadata":{"id":"GzEuEn_kYhnI","executionInfo":{"status":"ok","timestamp":1702106791152,"user_tz":-540,"elapsed":2,"user":{"displayName":"김채현코랩1","userId":"16338580172282075794"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!pip install ftfy regex tqdm\n","!pip install git+https://github.com/openai/CLIP.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jr4bSBbLMO0-","executionInfo":{"status":"ok","timestamp":1702106809357,"user_tz":-540,"elapsed":18207,"user":{"displayName":"김채현코랩1","userId":"16338580172282075794"}},"outputId":"188bf644-04ec-4be3-b522-fd6153551412"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ftfy\n","  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.12)\n","Installing collected packages: ftfy\n","Successfully installed ftfy-6.1.3\n","Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-6h9jkbkn\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-6h9jkbkn\n","  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.1.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.1.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.16.0+cu118)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.12)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n","Building wheels for collected packages: clip\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369497 sha256=76d870cdf8e968654ded58a76de71e2aab9a661b432eba8ed26e0fb08d1a8f94\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-_x7u20pz/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n","Successfully built clip\n","Installing collected packages: clip\n","Successfully installed clip-1.0\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import clip\n","from PIL import Image"],"metadata":{"id":"sYyZLdWWOEuR","executionInfo":{"status":"ok","timestamp":1702106815454,"user_tz":-540,"elapsed":6100,"user":{"displayName":"김채현코랩1","userId":"16338580172282075794"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!python train_pclip_PEncoder.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tu71S0Ivzcnf","executionInfo":{"status":"ok","timestamp":1702107392470,"user_tz":-540,"elapsed":577020,"user":{"displayName":"김채현코랩1","userId":"16338580172282075794"}},"outputId":"4524a2b2-40aa-40ee-cbbf-4167e1893aef"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","[2023-12-09 07:28:29,088::train::INFO] [Train] Iter 0022 | Loss 0.826602 | Grad 0.6440 \n","[2023-12-09 07:28:29,172::train::INFO] [Train] Iter 0023 | Loss 0.809195 | Grad 0.6891 \n","[2023-12-09 07:28:29,258::train::INFO] [Train] Iter 0024 | Loss 0.760642 | Grad 0.6515 \n","[2023-12-09 07:28:29,342::train::INFO] [Train] Iter 0025 | Loss 0.720582 | Grad 0.5631 \n","[2023-12-09 07:28:29,426::train::INFO] [Train] Iter 0026 | Loss 0.690444 | Grad 0.5219 \n","[2023-12-09 07:28:29,511::train::INFO] [Train] Iter 0027 | Loss 0.682992 | Grad 0.5885 \n","[2023-12-09 07:28:29,599::train::INFO] [Train] Iter 0028 | Loss 0.637521 | Grad 0.5513 \n","[2023-12-09 07:28:29,682::train::INFO] [Train] Iter 0029 | Loss 0.605332 | Grad 0.4611 \n","[2023-12-09 07:28:29,764::train::INFO] [Train] Iter 0030 | Loss 0.595225 | Grad 0.5513 \n","[2023-12-09 07:28:29,848::train::INFO] [Train] Iter 0031 | Loss 0.590113 | Grad 0.4487 \n","[2023-12-09 07:28:29,933::train::INFO] [Train] Iter 0032 | Loss 0.560862 | Grad 0.4315 \n","[2023-12-09 07:28:30,016::train::INFO] [Train] Iter 0033 | Loss 0.543395 | Grad 0.4966 \n","[2023-12-09 07:28:30,100::train::INFO] [Train] Iter 0034 | Loss 0.553745 | Grad 0.4362 \n","[2023-12-09 07:28:30,183::train::INFO] [Train] Iter 0035 | Loss 0.515146 | Grad 0.4797 \n","[2023-12-09 07:28:30,266::train::INFO] [Train] Iter 0036 | Loss 0.476781 | Grad 0.5306 \n","[2023-12-09 07:28:30,352::train::INFO] [Train] Iter 0037 | Loss 0.484923 | Grad 0.4368 \n","[2023-12-09 07:28:30,436::train::INFO] [Train] Iter 0038 | Loss 0.470830 | Grad 0.5783 \n","[2023-12-09 07:28:30,519::train::INFO] [Train] Iter 0039 | Loss 0.470728 | Grad 0.5267 \n","[2023-12-09 07:28:30,602::train::INFO] [Train] Iter 0040 | Loss 0.465993 | Grad 0.4441 \n","[2023-12-09 07:28:30,688::train::INFO] [Train] Iter 0041 | Loss 0.447839 | Grad 0.9470 \n","[2023-12-09 07:28:30,772::train::INFO] [Train] Iter 0042 | Loss 0.435827 | Grad 0.4709 \n","[2023-12-09 07:28:30,857::train::INFO] [Train] Iter 0043 | Loss 0.430265 | Grad 0.4488 \n","[2023-12-09 07:28:30,941::train::INFO] [Train] Iter 0044 | Loss 0.420069 | Grad 0.4155 \n","[2023-12-09 07:28:31,023::train::INFO] [Train] Iter 0045 | Loss 0.403040 | Grad 0.4484 \n","[2023-12-09 07:28:31,107::train::INFO] [Train] Iter 0046 | Loss 0.411591 | Grad 0.4396 \n","[2023-12-09 07:28:31,190::train::INFO] [Train] Iter 0047 | Loss 0.398616 | Grad 0.5758 \n","[2023-12-09 07:28:31,274::train::INFO] [Train] Iter 0048 | Loss 0.381526 | Grad 0.5446 \n","[2023-12-09 07:28:31,359::train::INFO] [Train] Iter 0049 | Loss 0.376379 | Grad 0.7447 \n","[2023-12-09 07:28:31,443::train::INFO] [Train] Iter 0050 | Loss 0.371517 | Grad 0.4496 \n","[2023-12-09 07:28:31,529::train::INFO] [Train] Iter 0051 | Loss 0.388349 | Grad 0.4566 \n","[2023-12-09 07:28:31,613::train::INFO] [Train] Iter 0052 | Loss 0.354523 | Grad 0.6687 \n","[2023-12-09 07:28:31,698::train::INFO] [Train] Iter 0053 | Loss 0.369294 | Grad 0.5268 \n","[2023-12-09 07:28:31,782::train::INFO] [Train] Iter 0054 | Loss 0.350417 | Grad 0.6453 \n","[2023-12-09 07:28:31,866::train::INFO] [Train] Iter 0055 | Loss 0.352957 | Grad 0.8968 \n","[2023-12-09 07:28:31,949::train::INFO] [Train] Iter 0056 | Loss 0.351800 | Grad 0.6810 \n","[2023-12-09 07:28:32,035::train::INFO] [Train] Iter 0057 | Loss 0.337813 | Grad 0.5513 \n","[2023-12-09 07:28:32,123::train::INFO] [Train] Iter 0058 | Loss 0.333484 | Grad 0.7116 \n","[2023-12-09 07:28:32,211::train::INFO] [Train] Iter 0059 | Loss 0.326212 | Grad 0.4122 \n","[2023-12-09 07:28:32,295::train::INFO] [Train] Iter 0060 | Loss 0.320249 | Grad 0.3124 \n","[2023-12-09 07:28:32,378::train::INFO] [Train] Iter 0061 | Loss 0.322066 | Grad 0.5035 \n","[2023-12-09 07:28:32,472::train::INFO] [Train] Iter 0062 | Loss 0.320856 | Grad 0.5225 \n","[2023-12-09 07:28:32,565::train::INFO] [Train] Iter 0063 | Loss 0.318994 | Grad 0.8379 \n","[2023-12-09 07:28:32,657::train::INFO] [Train] Iter 0064 | Loss 0.302325 | Grad 0.5608 \n","[2023-12-09 07:28:32,753::train::INFO] [Train] Iter 0065 | Loss 0.305349 | Grad 0.6099 \n","[2023-12-09 07:28:32,845::train::INFO] [Train] Iter 0066 | Loss 0.316609 | Grad 0.4980 \n","[2023-12-09 07:28:32,938::train::INFO] [Train] Iter 0067 | Loss 0.295324 | Grad 0.3644 \n","[2023-12-09 07:28:33,031::train::INFO] [Train] Iter 0068 | Loss 0.298755 | Grad 0.5174 \n","[2023-12-09 07:28:33,122::train::INFO] [Train] Iter 0069 | Loss 0.287259 | Grad 0.5483 \n","[2023-12-09 07:28:33,214::train::INFO] [Train] Iter 0070 | Loss 0.284575 | Grad 0.5340 \n","[2023-12-09 07:28:33,307::train::INFO] [Train] Iter 0071 | Loss 0.278465 | Grad 0.6902 \n","[2023-12-09 07:28:33,398::train::INFO] [Train] Iter 0072 | Loss 0.284815 | Grad 0.7309 \n","[2023-12-09 07:28:33,490::train::INFO] [Train] Iter 0073 | Loss 0.283051 | Grad 0.6055 \n","[2023-12-09 07:28:33,580::train::INFO] [Train] Iter 0074 | Loss 0.276484 | Grad 0.4364 \n","[2023-12-09 07:28:33,671::train::INFO] [Train] Iter 0075 | Loss 0.270908 | Grad 0.5395 \n","[2023-12-09 07:28:33,761::train::INFO] [Train] Iter 0076 | Loss 0.274110 | Grad 0.5152 \n","[2023-12-09 07:28:33,856::train::INFO] [Train] Iter 0077 | Loss 0.276123 | Grad 0.3780 \n","[2023-12-09 07:28:33,947::train::INFO] [Train] Iter 0078 | Loss 0.266717 | Grad 0.3158 \n","[2023-12-09 07:28:34,041::train::INFO] [Train] Iter 0079 | Loss 0.266020 | Grad 0.3970 \n","[2023-12-09 07:28:34,132::train::INFO] [Train] Iter 0080 | Loss 0.259735 | Grad 0.2837 \n","[2023-12-09 07:28:34,224::train::INFO] [Train] Iter 0081 | Loss 0.263111 | Grad 0.7750 \n","[2023-12-09 07:28:34,316::train::INFO] [Train] Iter 0082 | Loss 0.255429 | Grad 0.6550 \n","[2023-12-09 07:28:34,407::train::INFO] [Train] Iter 0083 | Loss 0.254740 | Grad 0.8740 \n","[2023-12-09 07:28:34,498::train::INFO] [Train] Iter 0084 | Loss 0.255998 | Grad 0.6116 \n","[2023-12-09 07:28:34,587::train::INFO] [Train] Iter 0085 | Loss 0.254526 | Grad 0.5317 \n","[2023-12-09 07:28:34,677::train::INFO] [Train] Iter 0086 | Loss 0.258623 | Grad 0.7348 \n","[2023-12-09 07:28:34,767::train::INFO] [Train] Iter 0087 | Loss 0.244384 | Grad 0.4434 \n","[2023-12-09 07:28:34,857::train::INFO] [Train] Iter 0088 | Loss 0.240734 | Grad 0.6346 \n","[2023-12-09 07:28:34,948::train::INFO] [Train] Iter 0089 | Loss 0.244108 | Grad 0.7765 \n","[2023-12-09 07:28:35,039::train::INFO] [Train] Iter 0090 | Loss 0.252900 | Grad 0.4068 \n","[2023-12-09 07:28:35,129::train::INFO] [Train] Iter 0091 | Loss 0.237744 | Grad 0.6046 \n","[2023-12-09 07:28:35,220::train::INFO] [Train] Iter 0092 | Loss 0.241069 | Grad 0.5286 \n","[2023-12-09 07:28:35,311::train::INFO] [Train] Iter 0093 | Loss 0.237702 | Grad 0.3921 \n","[2023-12-09 07:28:35,402::train::INFO] [Train] Iter 0094 | Loss 0.235456 | Grad 1.3700 \n","[2023-12-09 07:28:35,494::train::INFO] [Train] Iter 0095 | Loss 0.230888 | Grad 0.3409 \n","[2023-12-09 07:28:35,588::train::INFO] [Train] Iter 0096 | Loss 0.231229 | Grad 0.6707 \n","[2023-12-09 07:28:35,680::train::INFO] [Train] Iter 0097 | Loss 0.231010 | Grad 0.7155 \n","[2023-12-09 07:28:35,770::train::INFO] [Train] Iter 0098 | Loss 0.227594 | Grad 0.7284 \n","[2023-12-09 07:28:35,872::train::INFO] [Train] Iter 0099 | Loss 0.224757 | Grad 0.3099 \n","[2023-12-09 07:28:35,964::train::INFO] [Train] Iter 0100 | Loss 0.228754 | Grad 0.3335 \n","[2023-12-09 07:28:36,056::train::INFO] [Train] Iter 0101 | Loss 0.224176 | Grad 0.3969 \n","[2023-12-09 07:28:36,147::train::INFO] [Train] Iter 0102 | Loss 0.220219 | Grad 0.6740 \n","[2023-12-09 07:28:36,237::train::INFO] [Train] Iter 0103 | Loss 0.220753 | Grad 0.6831 \n","[2023-12-09 07:28:36,327::train::INFO] [Train] Iter 0104 | Loss 0.219580 | Grad 0.6563 \n","[2023-12-09 07:28:36,417::train::INFO] [Train] Iter 0105 | Loss 0.212894 | Grad 0.6386 \n","[2023-12-09 07:28:36,507::train::INFO] [Train] Iter 0106 | Loss 0.218205 | Grad 0.4056 \n","[2023-12-09 07:28:36,597::train::INFO] [Train] Iter 0107 | Loss 0.218296 | Grad 0.3664 \n","[2023-12-09 07:28:36,687::train::INFO] [Train] Iter 0108 | Loss 0.210685 | Grad 0.3179 \n","[2023-12-09 07:28:36,779::train::INFO] [Train] Iter 0109 | Loss 0.216033 | Grad 0.4889 \n","[2023-12-09 07:28:36,882::train::INFO] [Train] Iter 0110 | Loss 0.205947 | Grad 0.2791 \n","[2023-12-09 07:28:36,976::train::INFO] [Train] Iter 0111 | Loss 0.208080 | Grad 0.4245 \n","[2023-12-09 07:28:37,068::train::INFO] [Train] Iter 0112 | Loss 0.214728 | Grad 0.2743 \n","[2023-12-09 07:28:37,166::train::INFO] [Train] Iter 0113 | Loss 0.212405 | Grad 0.4805 \n","[2023-12-09 07:28:37,258::train::INFO] [Train] Iter 0114 | Loss 0.202536 | Grad 0.4557 \n","[2023-12-09 07:28:37,350::train::INFO] [Train] Iter 0115 | Loss 0.199906 | Grad 0.6369 \n","[2023-12-09 07:28:37,442::train::INFO] [Train] Iter 0116 | Loss 0.207021 | Grad 0.4763 \n","[2023-12-09 07:28:37,532::train::INFO] [Train] Iter 0117 | Loss 0.193558 | Grad 0.7206 \n","[2023-12-09 07:28:37,621::train::INFO] [Train] Iter 0118 | Loss 0.195373 | Grad 0.2878 \n","[2023-12-09 07:28:37,711::train::INFO] [Train] Iter 0119 | Loss 0.189670 | Grad 0.3786 \n","[2023-12-09 07:28:37,801::train::INFO] [Train] Iter 0120 | Loss 0.194988 | Grad 0.3602 \n","[2023-12-09 07:28:37,893::train::INFO] [Train] Iter 0121 | Loss 0.197990 | Grad 0.5616 \n","[2023-12-09 07:28:37,983::train::INFO] [Train] Iter 0122 | Loss 0.197334 | Grad 0.3940 \n","[2023-12-09 07:28:38,076::train::INFO] [Train] Iter 0123 | Loss 0.182879 | Grad 0.5211 \n","[2023-12-09 07:28:38,167::train::INFO] [Train] Iter 0124 | Loss 0.190974 | Grad 0.3738 \n","[2023-12-09 07:28:38,258::train::INFO] [Train] Iter 0125 | Loss 0.185198 | Grad 0.2817 \n","[2023-12-09 07:28:38,351::train::INFO] [Train] Iter 0126 | Loss 0.188011 | Grad 0.4464 \n","[2023-12-09 07:28:38,445::train::INFO] [Train] Iter 0127 | Loss 0.185140 | Grad 0.4204 \n","[2023-12-09 07:28:38,537::train::INFO] [Train] Iter 0128 | Loss 0.184659 | Grad 0.4491 \n","[2023-12-09 07:28:38,627::train::INFO] [Train] Iter 0129 | Loss 0.188479 | Grad 0.7337 \n","[2023-12-09 07:28:38,712::train::INFO] [Train] Iter 0130 | Loss 0.181801 | Grad 0.8093 \n","[2023-12-09 07:28:38,795::train::INFO] [Train] Iter 0131 | Loss 0.183002 | Grad 0.4885 \n","[2023-12-09 07:28:38,878::train::INFO] [Train] Iter 0132 | Loss 0.182403 | Grad 0.3761 \n","[2023-12-09 07:28:38,962::train::INFO] [Train] Iter 0133 | Loss 0.182392 | Grad 0.5419 \n","[2023-12-09 07:28:39,045::train::INFO] [Train] Iter 0134 | Loss 0.177987 | Grad 0.2573 \n","[2023-12-09 07:28:39,129::train::INFO] [Train] Iter 0135 | Loss 0.174653 | Grad 0.4835 \n","[2023-12-09 07:28:39,213::train::INFO] [Train] Iter 0136 | Loss 0.180111 | Grad 0.5605 \n","[2023-12-09 07:28:39,297::train::INFO] [Train] Iter 0137 | Loss 0.173792 | Grad 0.1964 \n","[2023-12-09 07:28:39,381::train::INFO] [Train] Iter 0138 | Loss 0.170504 | Grad 0.6552 \n","[2023-12-09 07:28:39,464::train::INFO] [Train] Iter 0139 | Loss 0.188149 | Grad 0.4609 \n","[2023-12-09 07:28:39,547::train::INFO] [Train] Iter 0140 | Loss 0.174980 | Grad 0.4896 \n","[2023-12-09 07:28:39,631::train::INFO] [Train] Iter 0141 | Loss 0.172077 | Grad 0.8342 \n","[2023-12-09 07:28:39,715::train::INFO] [Train] Iter 0142 | Loss 0.170529 | Grad 0.6238 \n","[2023-12-09 07:28:39,798::train::INFO] [Train] Iter 0143 | Loss 0.180248 | Grad 0.6403 \n","[2023-12-09 07:28:39,883::train::INFO] [Train] Iter 0144 | Loss 0.173979 | Grad 0.5060 \n","[2023-12-09 07:28:39,968::train::INFO] [Train] Iter 0145 | Loss 0.166435 | Grad 0.4050 \n","[2023-12-09 07:28:40,054::train::INFO] [Train] Iter 0146 | Loss 0.169064 | Grad 0.6145 \n","[2023-12-09 07:28:40,138::train::INFO] [Train] Iter 0147 | Loss 0.167151 | Grad 0.3123 \n","[2023-12-09 07:28:40,222::train::INFO] [Train] Iter 0148 | Loss 0.165991 | Grad 0.5944 \n","[2023-12-09 07:28:40,305::train::INFO] [Train] Iter 0149 | Loss 0.172316 | Grad 0.5740 \n","[2023-12-09 07:28:40,390::train::INFO] [Train] Iter 0150 | Loss 0.166788 | Grad 0.6294 \n","[2023-12-09 07:28:40,472::train::INFO] [Train] Iter 0151 | Loss 0.167555 | Grad 1.1454 \n","[2023-12-09 07:28:40,557::train::INFO] [Train] Iter 0152 | Loss 0.169058 | Grad 0.6375 \n","[2023-12-09 07:28:40,640::train::INFO] [Train] Iter 0153 | Loss 0.163389 | Grad 0.6232 \n","[2023-12-09 07:28:40,723::train::INFO] [Train] Iter 0154 | Loss 0.164628 | Grad 0.6877 \n","[2023-12-09 07:28:40,808::train::INFO] [Train] Iter 0155 | Loss 0.162567 | Grad 0.5869 \n","[2023-12-09 07:28:40,894::train::INFO] [Train] Iter 0156 | Loss 0.163445 | Grad 0.4612 \n","[2023-12-09 07:28:40,976::train::INFO] [Train] Iter 0157 | Loss 0.165099 | Grad 0.7148 \n","[2023-12-09 07:28:41,062::train::INFO] [Train] Iter 0158 | Loss 0.156234 | Grad 0.4212 \n","[2023-12-09 07:28:41,146::train::INFO] [Train] Iter 0159 | Loss 0.166510 | Grad 1.1495 \n","[2023-12-09 07:28:41,229::train::INFO] [Train] Iter 0160 | Loss 0.156077 | Grad 0.5511 \n","[2023-12-09 07:28:41,313::train::INFO] [Train] Iter 0161 | Loss 0.153291 | Grad 0.4476 \n","[2023-12-09 07:28:41,399::train::INFO] [Train] Iter 0162 | Loss 0.157738 | Grad 0.4389 \n","[2023-12-09 07:28:41,482::train::INFO] [Train] Iter 0163 | Loss 0.157043 | Grad 0.6699 \n","[2023-12-09 07:28:41,565::train::INFO] [Train] Iter 0164 | Loss 0.161426 | Grad 0.4056 \n","[2023-12-09 07:28:41,649::train::INFO] [Train] Iter 0165 | Loss 0.152428 | Grad 0.3826 \n","[2023-12-09 07:28:41,733::train::INFO] [Train] Iter 0166 | Loss 0.153987 | Grad 0.5123 \n","[2023-12-09 07:28:41,817::train::INFO] [Train] Iter 0167 | Loss 0.151716 | Grad 0.5834 \n","[2023-12-09 07:28:41,901::train::INFO] [Train] Iter 0168 | Loss 0.149067 | Grad 0.4173 \n","[2023-12-09 07:28:41,985::train::INFO] [Train] Iter 0169 | Loss 0.149806 | Grad 1.1812 \n","[2023-12-09 07:28:42,071::train::INFO] [Train] Iter 0170 | Loss 0.158657 | Grad 0.6244 \n","[2023-12-09 07:28:42,158::train::INFO] [Train] Iter 0171 | Loss 0.147723 | Grad 0.4285 \n","[2023-12-09 07:28:42,241::train::INFO] [Train] Iter 0172 | Loss 0.152523 | Grad 0.4099 \n","[2023-12-09 07:28:42,326::train::INFO] [Train] Iter 0173 | Loss 0.163158 | Grad 0.5849 \n","[2023-12-09 07:28:42,409::train::INFO] [Train] Iter 0174 | Loss 0.154530 | Grad 0.7093 \n","[2023-12-09 07:28:42,492::train::INFO] [Train] Iter 0175 | Loss 0.145500 | Grad 0.4500 \n","[2023-12-09 07:28:42,577::train::INFO] [Train] Iter 0176 | Loss 0.147969 | Grad 0.2897 \n","[2023-12-09 07:28:42,661::train::INFO] [Train] Iter 0177 | Loss 0.142783 | Grad 0.4402 \n","[2023-12-09 07:28:42,744::train::INFO] [Train] Iter 0178 | Loss 0.143351 | Grad 0.5573 \n","[2023-12-09 07:28:42,827::train::INFO] [Train] Iter 0179 | Loss 0.141210 | Grad 0.3220 \n","[2023-12-09 07:28:42,912::train::INFO] [Train] Iter 0180 | Loss 0.142149 | Grad 0.4154 \n","[2023-12-09 07:28:42,996::train::INFO] [Train] Iter 0181 | Loss 0.148592 | Grad 0.3217 \n","[2023-12-09 07:28:43,083::train::INFO] [Train] Iter 0182 | Loss 0.136365 | Grad 0.4462 \n","[2023-12-09 07:28:43,165::train::INFO] [Train] Iter 0183 | Loss 0.140220 | Grad 0.5128 \n","[2023-12-09 07:28:43,259::train::INFO] [Train] Iter 0184 | Loss 0.143203 | Grad 0.6075 \n","[2023-12-09 07:28:43,344::train::INFO] [Train] Iter 0185 | Loss 0.144437 | Grad 0.6257 \n","[2023-12-09 07:28:43,428::train::INFO] [Train] Iter 0186 | Loss 0.137858 | Grad 0.7009 \n","[2023-12-09 07:28:43,514::train::INFO] [Train] Iter 0187 | Loss 0.134225 | Grad 0.4468 \n","[2023-12-09 07:28:43,597::train::INFO] [Train] Iter 0188 | Loss 0.133673 | Grad 0.3236 \n","[2023-12-09 07:28:43,680::train::INFO] [Train] Iter 0189 | Loss 0.136063 | Grad 0.4791 \n","[2023-12-09 07:28:43,763::train::INFO] [Train] Iter 0190 | Loss 0.139314 | Grad 0.4014 \n","[2023-12-09 07:28:43,846::train::INFO] [Train] Iter 0191 | Loss 0.140860 | Grad 0.5419 \n","[2023-12-09 07:28:43,930::train::INFO] [Train] Iter 0192 | Loss 0.145911 | Grad 0.6250 \n","[2023-12-09 07:28:44,014::train::INFO] [Train] Iter 0193 | Loss 0.132110 | Grad 0.4288 \n","[2023-12-09 07:28:44,102::train::INFO] [Train] Iter 0194 | Loss 0.134151 | Grad 0.3593 \n","[2023-12-09 07:28:44,185::train::INFO] [Train] Iter 0195 | Loss 0.136980 | Grad 0.3155 \n","[2023-12-09 07:28:44,268::train::INFO] [Train] Iter 0196 | Loss 0.136165 | Grad 0.2571 \n","[2023-12-09 07:28:44,351::train::INFO] [Train] Iter 0197 | Loss 0.131369 | Grad 0.5150 \n","[2023-12-09 07:28:44,435::train::INFO] [Train] Iter 0198 | Loss 0.129397 | Grad 0.3451 \n","[2023-12-09 07:28:44,519::train::INFO] [Train] Iter 0199 | Loss 0.132574 | Grad 0.3866 \n","[2023-12-09 07:28:44,602::train::INFO] [Train] Iter 0200 | Loss 0.130446 | Grad 0.3017 \n","[2023-12-09 07:28:44,687::train::INFO] [Train] Iter 0201 | Loss 0.130468 | Grad 0.3888 \n","[2023-12-09 07:28:44,769::train::INFO] [Train] Iter 0202 | Loss 0.130678 | Grad 0.4072 \n","[2023-12-09 07:28:44,853::train::INFO] [Train] Iter 0203 | Loss 0.127730 | Grad 0.5091 \n","[2023-12-09 07:28:44,936::train::INFO] [Train] Iter 0204 | Loss 0.132974 | Grad 0.3108 \n","[2023-12-09 07:28:45,023::train::INFO] [Train] Iter 0205 | Loss 0.135310 | Grad 0.2755 \n","[2023-12-09 07:28:45,109::train::INFO] [Train] Iter 0206 | Loss 0.127016 | Grad 0.4601 \n","[2023-12-09 07:28:45,192::train::INFO] [Train] Iter 0207 | Loss 0.125443 | Grad 0.3904 \n","[2023-12-09 07:28:45,275::train::INFO] [Train] Iter 0208 | Loss 0.127216 | Grad 0.3588 \n","[2023-12-09 07:28:45,361::train::INFO] [Train] Iter 0209 | Loss 0.119299 | Grad 0.3717 \n","[2023-12-09 07:28:45,445::train::INFO] [Train] Iter 0210 | Loss 0.134003 | Grad 0.6122 \n","[2023-12-09 07:28:45,528::train::INFO] [Train] Iter 0211 | Loss 0.122296 | Grad 0.5240 \n","[2023-12-09 07:28:45,610::train::INFO] [Train] Iter 0212 | Loss 0.123722 | Grad 0.4143 \n","[2023-12-09 07:28:45,693::train::INFO] [Train] Iter 0213 | Loss 0.124391 | Grad 0.8189 \n","[2023-12-09 07:28:45,777::train::INFO] [Train] Iter 0214 | Loss 0.126922 | Grad 0.4114 \n","[2023-12-09 07:28:45,861::train::INFO] [Train] Iter 0215 | Loss 0.127542 | Grad 0.2427 \n","[2023-12-09 07:28:45,944::train::INFO] [Train] Iter 0216 | Loss 0.123243 | Grad 0.4692 \n","[2023-12-09 07:28:46,029::train::INFO] [Train] Iter 0217 | Loss 0.129726 | Grad 0.4703 \n","[2023-12-09 07:28:46,113::train::INFO] [Train] Iter 0218 | Loss 0.121841 | Grad 0.2813 \n","[2023-12-09 07:28:46,195::train::INFO] [Train] Iter 0219 | Loss 0.121788 | Grad 0.3428 \n","[2023-12-09 07:28:46,279::train::INFO] [Train] Iter 0220 | Loss 0.124614 | Grad 0.8143 \n","[2023-12-09 07:28:46,363::train::INFO] [Train] Iter 0221 | Loss 0.118169 | Grad 0.3614 \n","[2023-12-09 07:28:46,447::train::INFO] [Train] Iter 0222 | Loss 0.117011 | Grad 0.6082 \n","[2023-12-09 07:28:46,532::train::INFO] [Train] Iter 0223 | Loss 0.119017 | Grad 0.3807 \n","[2023-12-09 07:28:46,615::train::INFO] [Train] Iter 0224 | Loss 0.119176 | Grad 0.3218 \n","[2023-12-09 07:28:46,698::train::INFO] [Train] Iter 0225 | Loss 0.117420 | Grad 0.4274 \n","[2023-12-09 07:28:46,781::train::INFO] [Train] Iter 0226 | Loss 0.121789 | Grad 0.2974 \n","[2023-12-09 07:28:46,865::train::INFO] [Train] Iter 0227 | Loss 0.117193 | Grad 0.5813 \n","[2023-12-09 07:28:46,949::train::INFO] [Train] Iter 0228 | Loss 0.113286 | Grad 0.4295 \n","[2023-12-09 07:28:47,035::train::INFO] [Train] Iter 0229 | Loss 0.119054 | Grad 0.3088 \n","[2023-12-09 07:28:47,119::train::INFO] [Train] Iter 0230 | Loss 0.115782 | Grad 0.2699 \n","[2023-12-09 07:28:47,204::train::INFO] [Train] Iter 0231 | Loss 0.116661 | Grad 0.2553 \n","[2023-12-09 07:28:47,289::train::INFO] [Train] Iter 0232 | Loss 0.115678 | Grad 0.1684 \n","[2023-12-09 07:28:47,375::train::INFO] [Train] Iter 0233 | Loss 0.116917 | Grad 0.4246 \n","[2023-12-09 07:28:47,459::train::INFO] [Train] Iter 0234 | Loss 0.114197 | Grad 0.3706 \n","[2023-12-09 07:28:47,546::train::INFO] [Train] Iter 0235 | Loss 0.117499 | Grad 0.5658 \n","[2023-12-09 07:28:47,629::train::INFO] [Train] Iter 0236 | Loss 0.111901 | Grad 0.2637 \n","[2023-12-09 07:28:47,713::train::INFO] [Train] Iter 0237 | Loss 0.115284 | Grad 0.4940 \n","[2023-12-09 07:28:47,796::train::INFO] [Train] Iter 0238 | Loss 0.112903 | Grad 0.2510 \n","[2023-12-09 07:28:47,879::train::INFO] [Train] Iter 0239 | Loss 0.111789 | Grad 0.3004 \n","[2023-12-09 07:28:47,962::train::INFO] [Train] Iter 0240 | Loss 0.109389 | Grad 0.2822 \n","[2023-12-09 07:28:48,046::train::INFO] [Train] Iter 0241 | Loss 0.117004 | Grad 0.3779 \n","[2023-12-09 07:28:48,130::train::INFO] [Train] Iter 0242 | Loss 0.107266 | Grad 0.5954 \n","[2023-12-09 07:28:48,214::train::INFO] [Train] Iter 0243 | Loss 0.109017 | Grad 0.2836 \n","[2023-12-09 07:28:48,297::train::INFO] [Train] Iter 0244 | Loss 0.112614 | Grad 0.4972 \n","[2023-12-09 07:28:48,381::train::INFO] [Train] Iter 0245 | Loss 0.110600 | Grad 0.4551 \n","[2023-12-09 07:28:48,464::train::INFO] [Train] Iter 0246 | Loss 0.111149 | Grad 0.4442 \n","[2023-12-09 07:28:48,547::train::INFO] [Train] Iter 0247 | Loss 0.108755 | Grad 0.2488 \n","[2023-12-09 07:28:48,631::train::INFO] [Train] Iter 0248 | Loss 0.113528 | Grad 0.5010 \n","[2023-12-09 07:28:48,727::train::INFO] [Train] Iter 0249 | Loss 0.108915 | Grad 0.3010 \n","[2023-12-09 07:28:48,822::train::INFO] [Train] Iter 0250 | Loss 0.113783 | Grad 0.2590 \n","[2023-12-09 07:28:48,914::train::INFO] [Train] Iter 0251 | Loss 0.106244 | Grad 0.6383 \n","[2023-12-09 07:28:49,006::train::INFO] [Train] Iter 0252 | Loss 0.108798 | Grad 0.3266 \n","[2023-12-09 07:28:49,097::train::INFO] [Train] Iter 0253 | Loss 0.104986 | Grad 0.4054 \n","[2023-12-09 07:28:49,193::train::INFO] [Train] Iter 0254 | Loss 0.107704 | Grad 0.3095 \n","[2023-12-09 07:28:49,284::train::INFO] [Train] Iter 0255 | Loss 0.105618 | Grad 0.4276 \n","[2023-12-09 07:28:49,376::train::INFO] [Train] Iter 0256 | Loss 0.109420 | Grad 0.2774 \n","[2023-12-09 07:28:49,467::train::INFO] [Train] Iter 0257 | Loss 0.105701 | Grad 0.5029 \n","[2023-12-09 07:28:49,558::train::INFO] [Train] Iter 0258 | Loss 0.103628 | Grad 0.5214 \n","[2023-12-09 07:28:49,650::train::INFO] [Train] Iter 0259 | Loss 0.104310 | Grad 0.3464 \n","[2023-12-09 07:28:49,742::train::INFO] [Train] Iter 0260 | Loss 0.110200 | Grad 0.6731 \n","[2023-12-09 07:28:49,833::train::INFO] [Train] Iter 0261 | Loss 0.106031 | Grad 0.3331 \n","[2023-12-09 07:28:49,926::train::INFO] [Train] Iter 0262 | Loss 0.104144 | Grad 0.3828 \n","[2023-12-09 07:28:50,016::train::INFO] [Train] Iter 0263 | Loss 0.105030 | Grad 0.2480 \n","[2023-12-09 07:28:50,106::train::INFO] [Train] Iter 0264 | Loss 0.104785 | Grad 0.6723 \n","[2023-12-09 07:28:50,200::train::INFO] [Train] Iter 0265 | Loss 0.103253 | Grad 0.2277 \n","[2023-12-09 07:28:50,298::train::INFO] [Train] Iter 0266 | Loss 0.103649 | Grad 0.3035 \n","[2023-12-09 07:28:50,389::train::INFO] [Train] Iter 0267 | Loss 0.101405 | Grad 0.2517 \n","[2023-12-09 07:28:50,480::train::INFO] [Train] Iter 0268 | Loss 0.101855 | Grad 0.2287 \n","[2023-12-09 07:28:50,571::train::INFO] [Train] Iter 0269 | Loss 0.103141 | Grad 0.2093 \n","[2023-12-09 07:28:50,665::train::INFO] [Train] Iter 0270 | Loss 0.104826 | Grad 0.4105 \n","[2023-12-09 07:28:50,758::train::INFO] [Train] Iter 0271 | Loss 0.103484 | Grad 0.4429 \n","[2023-12-09 07:28:50,851::train::INFO] [Train] Iter 0272 | Loss 0.100455 | Grad 0.4684 \n","[2023-12-09 07:28:50,942::train::INFO] [Train] Iter 0273 | Loss 0.100553 | Grad 0.3208 \n","[2023-12-09 07:28:51,033::train::INFO] [Train] Iter 0274 | Loss 0.101974 | Grad 0.3552 \n","[2023-12-09 07:28:51,125::train::INFO] [Train] Iter 0275 | Loss 0.104087 | Grad 0.4327 \n","[2023-12-09 07:28:51,219::train::INFO] [Train] Iter 0276 | Loss 0.098740 | Grad 0.3187 \n","[2023-12-09 07:28:51,311::train::INFO] [Train] Iter 0277 | Loss 0.097409 | Grad 0.2551 \n","[2023-12-09 07:28:51,403::train::INFO] [Train] Iter 0278 | Loss 0.102838 | Grad 0.5668 \n","[2023-12-09 07:28:51,494::train::INFO] [Train] Iter 0279 | Loss 0.098642 | Grad 0.6163 \n","[2023-12-09 07:28:51,587::train::INFO] [Train] Iter 0280 | Loss 0.098191 | Grad 0.2119 \n","[2023-12-09 07:28:51,678::train::INFO] [Train] Iter 0281 | Loss 0.099751 | Grad 0.2332 \n","[2023-12-09 07:28:51,768::train::INFO] [Train] Iter 0282 | Loss 0.099518 | Grad 0.3998 \n","[2023-12-09 07:28:51,861::train::INFO] [Train] Iter 0283 | Loss 0.100883 | Grad 0.1957 \n","[2023-12-09 07:28:51,953::train::INFO] [Train] Iter 0284 | Loss 0.099960 | Grad 0.3904 \n","[2023-12-09 07:28:52,046::train::INFO] [Train] Iter 0285 | Loss 0.101422 | Grad 0.2345 \n","[2023-12-09 07:28:52,144::train::INFO] [Train] Iter 0286 | Loss 0.095922 | Grad 0.5415 \n","[2023-12-09 07:28:52,235::train::INFO] [Train] Iter 0287 | Loss 0.094267 | Grad 0.3769 \n","[2023-12-09 07:28:52,330::train::INFO] [Train] Iter 0288 | Loss 0.096945 | Grad 0.4798 \n","[2023-12-09 07:28:52,421::train::INFO] [Train] Iter 0289 | Loss 0.100685 | Grad 0.3880 \n","[2023-12-09 07:28:52,511::train::INFO] [Train] Iter 0290 | Loss 0.095222 | Grad 0.4032 \n","[2023-12-09 07:28:52,603::train::INFO] [Train] Iter 0291 | Loss 0.097737 | Grad 0.4026 \n","[2023-12-09 07:28:52,694::train::INFO] [Train] Iter 0292 | Loss 0.096007 | Grad 0.3572 \n","[2023-12-09 07:28:52,791::train::INFO] [Train] Iter 0293 | Loss 0.095237 | Grad 0.2960 \n","[2023-12-09 07:28:52,883::train::INFO] [Train] Iter 0294 | Loss 0.095417 | Grad 0.4283 \n","[2023-12-09 07:28:52,978::train::INFO] [Train] Iter 0295 | Loss 0.095597 | Grad 0.5579 \n","[2023-12-09 07:28:53,076::train::INFO] [Train] Iter 0296 | Loss 0.095115 | Grad 0.3331 \n","[2023-12-09 07:28:53,168::train::INFO] [Train] Iter 0297 | Loss 0.092727 | Grad 0.2365 \n","[2023-12-09 07:28:53,259::train::INFO] [Train] Iter 0298 | Loss 0.096250 | Grad 0.2412 \n","[2023-12-09 07:28:53,354::train::INFO] [Train] Iter 0299 | Loss 0.095900 | Grad 0.3074 \n","[2023-12-09 07:28:53,446::train::INFO] [Train] Iter 0300 | Loss 0.092967 | Grad 0.3616 \n","[2023-12-09 07:28:53,539::train::INFO] [Train] Iter 0301 | Loss 0.092581 | Grad 0.2195 \n","[2023-12-09 07:28:53,630::train::INFO] [Train] Iter 0302 | Loss 0.093024 | Grad 0.4051 \n","[2023-12-09 07:28:53,724::train::INFO] [Train] Iter 0303 | Loss 0.092302 | Grad 0.5908 \n","[2023-12-09 07:28:53,813::train::INFO] [Train] Iter 0304 | Loss 0.093615 | Grad 0.4128 \n","[2023-12-09 07:28:53,904::train::INFO] [Train] Iter 0305 | Loss 0.096178 | Grad 0.2923 \n","[2023-12-09 07:28:53,994::train::INFO] [Train] Iter 0306 | Loss 0.092672 | Grad 0.8587 \n","[2023-12-09 07:28:54,084::train::INFO] [Train] Iter 0307 | Loss 0.089533 | Grad 0.2847 \n","[2023-12-09 07:28:54,178::train::INFO] [Train] Iter 0308 | Loss 0.094620 | Grad 0.4481 \n","[2023-12-09 07:28:54,270::train::INFO] [Train] Iter 0309 | Loss 0.091195 | Grad 1.0577 \n","[2023-12-09 07:28:54,364::train::INFO] [Train] Iter 0310 | Loss 0.092565 | Grad 0.3515 \n","[2023-12-09 07:28:54,457::train::INFO] [Train] Iter 0311 | Loss 0.091333 | Grad 0.2877 \n","[2023-12-09 07:28:54,548::train::INFO] [Train] Iter 0312 | Loss 0.091465 | Grad 0.5703 \n","[2023-12-09 07:28:54,638::train::INFO] [Train] Iter 0313 | Loss 0.099733 | Grad 0.5350 \n","[2023-12-09 07:28:54,729::train::INFO] [Train] Iter 0314 | Loss 0.092178 | Grad 0.2241 \n","[2023-12-09 07:28:54,818::train::INFO] [Train] Iter 0315 | Loss 0.090882 | Grad 0.2870 \n","[2023-12-09 07:28:54,906::train::INFO] [Train] Iter 0316 | Loss 0.092194 | Grad 0.4483 \n","[2023-12-09 07:28:54,989::train::INFO] [Train] Iter 0317 | Loss 0.093459 | Grad 0.5942 \n","[2023-12-09 07:28:55,073::train::INFO] [Train] Iter 0318 | Loss 0.097566 | Grad 0.6946 \n","[2023-12-09 07:28:55,156::train::INFO] [Train] Iter 0319 | Loss 0.085981 | Grad 0.7273 \n","[2023-12-09 07:28:55,242::train::INFO] [Train] Iter 0320 | Loss 0.091517 | Grad 0.2771 \n","[2023-12-09 07:28:55,324::train::INFO] [Train] Iter 0321 | Loss 0.088966 | Grad 0.5732 \n","[2023-12-09 07:28:55,408::train::INFO] [Train] Iter 0322 | Loss 0.089884 | Grad 0.3164 \n","[2023-12-09 07:28:55,494::train::INFO] [Train] Iter 0323 | Loss 0.089479 | Grad 0.3520 \n","[2023-12-09 07:28:55,577::train::INFO] [Train] Iter 0324 | Loss 0.087010 | Grad 0.3118 \n","[2023-12-09 07:28:55,660::train::INFO] [Train] Iter 0325 | Loss 0.089473 | Grad 0.4047 \n","[2023-12-09 07:28:55,743::train::INFO] [Train] Iter 0326 | Loss 0.097079 | Grad 0.4286 \n","[2023-12-09 07:28:55,826::train::INFO] [Train] Iter 0327 | Loss 0.087641 | Grad 0.2369 \n","[2023-12-09 07:28:55,909::train::INFO] [Train] Iter 0328 | Loss 0.082130 | Grad 0.2921 \n","[2023-12-09 07:28:55,993::train::INFO] [Train] Iter 0329 | Loss 0.089816 | Grad 0.2562 \n","[2023-12-09 07:28:56,075::train::INFO] [Train] Iter 0330 | Loss 0.083654 | Grad 0.4262 \n","[2023-12-09 07:28:56,158::train::INFO] [Train] Iter 0331 | Loss 0.085076 | Grad 0.4775 \n","[2023-12-09 07:28:56,242::train::INFO] [Train] Iter 0332 | Loss 0.085529 | Grad 0.2394 \n","[2023-12-09 07:28:56,325::train::INFO] [Train] Iter 0333 | Loss 0.086869 | Grad 0.3068 \n","[2023-12-09 07:28:56,408::train::INFO] [Train] Iter 0334 | Loss 0.085792 | Grad 0.2544 \n","[2023-12-09 07:28:56,493::train::INFO] [Train] Iter 0335 | Loss 0.084313 | Grad 0.2358 \n","[2023-12-09 07:28:56,576::train::INFO] [Train] Iter 0336 | Loss 0.086055 | Grad 0.2654 \n","[2023-12-09 07:28:56,659::train::INFO] [Train] Iter 0337 | Loss 0.083272 | Grad 0.2307 \n","[2023-12-09 07:28:56,743::train::INFO] [Train] Iter 0338 | Loss 0.083588 | Grad 0.2499 \n","[2023-12-09 07:28:56,826::train::INFO] [Train] Iter 0339 | Loss 0.084526 | Grad 0.1861 \n","[2023-12-09 07:28:56,867::train::INFO] [Train] Iter 0340 | Loss 0.085898 | Grad 0.2735 \n","[2023-12-09 07:28:56,950::train::INFO] [Train] Iter 0341 | Loss 0.088850 | Grad 0.4569 \n","[2023-12-09 07:28:57,033::train::INFO] [Train] Iter 0342 | Loss 0.089150 | Grad 0.4455 \n","[2023-12-09 07:28:57,117::train::INFO] [Train] Iter 0343 | Loss 0.086126 | Grad 0.2128 \n","[2023-12-09 07:28:57,200::train::INFO] [Train] Iter 0344 | Loss 0.085168 | Grad 0.1595 \n","[2023-12-09 07:28:57,284::train::INFO] [Train] Iter 0345 | Loss 0.083737 | Grad 0.2074 \n","[2023-12-09 07:28:57,368::train::INFO] [Train] Iter 0346 | Loss 0.084107 | Grad 0.2109 \n","[2023-12-09 07:28:57,451::train::INFO] [Train] Iter 0347 | Loss 0.084270 | Grad 0.2315 \n","[2023-12-09 07:28:57,534::train::INFO] [Train] Iter 0348 | Loss 0.084809 | Grad 0.2440 \n","[2023-12-09 07:28:57,616::train::INFO] [Train] Iter 0349 | Loss 0.079911 | Grad 0.1546 \n","[2023-12-09 07:28:57,700::train::INFO] [Train] Iter 0350 | Loss 0.084300 | Grad 0.2342 \n","[2023-12-09 07:28:57,782::train::INFO] [Train] Iter 0351 | Loss 0.082348 | Grad 0.2905 \n","[2023-12-09 07:28:57,866::train::INFO] [Train] Iter 0352 | Loss 0.080313 | Grad 0.1737 \n","[2023-12-09 07:28:57,949::train::INFO] [Train] Iter 0353 | Loss 0.080988 | Grad 0.2260 \n","[2023-12-09 07:28:58,033::train::INFO] [Train] Iter 0354 | Loss 0.082736 | Grad 0.1694 \n","[2023-12-09 07:28:58,117::train::INFO] [Train] Iter 0355 | Loss 0.081813 | Grad 0.1905 \n","[2023-12-09 07:28:58,203::train::INFO] [Train] Iter 0356 | Loss 0.080498 | Grad 0.1576 \n","[2023-12-09 07:28:58,287::train::INFO] [Train] Iter 0357 | Loss 0.079765 | Grad 0.2027 \n","[2023-12-09 07:28:58,370::train::INFO] [Train] Iter 0358 | Loss 0.081849 | Grad 0.2763 \n","[2023-12-09 07:28:58,454::train::INFO] [Train] Iter 0359 | Loss 0.080738 | Grad 0.2691 \n","[2023-12-09 07:28:58,540::train::INFO] [Train] Iter 0360 | Loss 0.080815 | Grad 0.2948 \n","[2023-12-09 07:28:58,624::train::INFO] [Train] Iter 0361 | Loss 0.077463 | Grad 0.2427 \n","[2023-12-09 07:28:58,706::train::INFO] [Train] Iter 0362 | Loss 0.080329 | Grad 0.2005 \n","[2023-12-09 07:28:58,789::train::INFO] [Train] Iter 0363 | Loss 0.084361 | Grad 0.2813 \n","[2023-12-09 07:28:58,871::train::INFO] [Train] Iter 0364 | Loss 0.084164 | Grad 0.3426 \n","[2023-12-09 07:28:58,954::train::INFO] [Train] Iter 0365 | Loss 0.080600 | Grad 0.3490 \n","[2023-12-09 07:28:59,039::train::INFO] [Train] Iter 0366 | Loss 0.078762 | Grad 0.1800 \n","[2023-12-09 07:28:59,122::train::INFO] [Train] Iter 0367 | Loss 0.082064 | Grad 0.3338 \n","[2023-12-09 07:28:59,205::train::INFO] [Train] Iter 0368 | Loss 0.077863 | Grad 0.1852 \n","[2023-12-09 07:28:59,290::train::INFO] [Train] Iter 0369 | Loss 0.077931 | Grad 0.1278 \n","[2023-12-09 07:28:59,373::train::INFO] [Train] Iter 0370 | Loss 0.078531 | Grad 0.4033 \n","[2023-12-09 07:28:59,455::train::INFO] [Train] Iter 0371 | Loss 0.078031 | Grad 0.2028 \n","[2023-12-09 07:28:59,542::train::INFO] [Train] Iter 0372 | Loss 0.076602 | Grad 0.2599 \n","[2023-12-09 07:28:59,624::train::INFO] [Train] Iter 0373 | Loss 0.078219 | Grad 0.4019 \n","[2023-12-09 07:28:59,710::train::INFO] [Train] Iter 0374 | Loss 0.080431 | Grad 0.2564 \n","[2023-12-09 07:28:59,792::train::INFO] [Train] Iter 0375 | Loss 0.076544 | Grad 0.3419 \n","[2023-12-09 07:28:59,875::train::INFO] [Train] Iter 0376 | Loss 0.075206 | Grad 0.3110 \n","[2023-12-09 07:28:59,961::train::INFO] [Train] Iter 0377 | Loss 0.076975 | Grad 0.4197 \n","[2023-12-09 07:29:00,045::train::INFO] [Train] Iter 0378 | Loss 0.077273 | Grad 0.1703 \n","[2023-12-09 07:29:00,128::train::INFO] [Train] Iter 0379 | Loss 0.077088 | Grad 0.2667 \n","[2023-12-09 07:29:00,211::train::INFO] [Train] Iter 0380 | Loss 0.078764 | Grad 0.5142 \n","[2023-12-09 07:29:00,294::train::INFO] [Train] Iter 0381 | Loss 0.074892 | Grad 0.2462 \n","[2023-12-09 07:29:00,379::train::INFO] [Train] Iter 0382 | Loss 0.076398 | Grad 0.2908 \n","[2023-12-09 07:29:00,462::train::INFO] [Train] Iter 0383 | Loss 0.077855 | Grad 0.3043 \n","[2023-12-09 07:29:00,551::train::INFO] [Train] Iter 0384 | Loss 0.075247 | Grad 0.1417 \n","[2023-12-09 07:29:00,634::train::INFO] [Train] Iter 0385 | Loss 0.073977 | Grad 0.1683 \n","[2023-12-09 07:29:00,717::train::INFO] [Train] Iter 0386 | Loss 0.075919 | Grad 0.2343 \n","[2023-12-09 07:29:00,802::train::INFO] [Train] Iter 0387 | Loss 0.074164 | Grad 0.3188 \n","[2023-12-09 07:29:00,885::train::INFO] [Train] Iter 0388 | Loss 0.073420 | Grad 0.2234 \n","[2023-12-09 07:29:00,975::train::INFO] [Train] Iter 0389 | Loss 0.076733 | Grad 0.3050 \n","[2023-12-09 07:29:01,058::train::INFO] [Train] Iter 0390 | Loss 0.072889 | Grad 0.2907 \n","[2023-12-09 07:29:01,142::train::INFO] [Train] Iter 0391 | Loss 0.080067 | Grad 0.3675 \n","[2023-12-09 07:29:01,227::train::INFO] [Train] Iter 0392 | Loss 0.072768 | Grad 0.1668 \n","[2023-12-09 07:29:01,310::train::INFO] [Train] Iter 0393 | Loss 0.075199 | Grad 0.4005 \n","[2023-12-09 07:29:01,400::train::INFO] [Train] Iter 0394 | Loss 0.075300 | Grad 0.3294 \n","[2023-12-09 07:29:01,485::train::INFO] [Train] Iter 0395 | Loss 0.075965 | Grad 0.2851 \n","[2023-12-09 07:29:01,576::train::INFO] [Train] Iter 0396 | Loss 0.076231 | Grad 0.2429 \n","[2023-12-09 07:29:01,661::train::INFO] [Train] Iter 0397 | Loss 0.073819 | Grad 0.3122 \n","[2023-12-09 07:29:01,745::train::INFO] [Train] Iter 0398 | Loss 0.073500 | Grad 0.3048 \n","[2023-12-09 07:29:01,830::train::INFO] [Train] Iter 0399 | Loss 0.072542 | Grad 0.1317 \n","[2023-12-09 07:29:01,913::train::INFO] [Train] Iter 0400 | Loss 0.072351 | Grad 0.1094 \n","[2023-12-09 07:29:01,997::train::INFO] [Train] Iter 0401 | Loss 0.073753 | Grad 0.2847 \n","[2023-12-09 07:29:02,080::train::INFO] [Train] Iter 0402 | Loss 0.076103 | Grad 0.1281 \n","[2023-12-09 07:29:02,166::train::INFO] [Train] Iter 0403 | Loss 0.073425 | Grad 0.1078 \n","[2023-12-09 07:29:02,251::train::INFO] [Train] Iter 0404 | Loss 0.071708 | Grad 0.2252 \n","[2023-12-09 07:29:02,334::train::INFO] [Train] Iter 0405 | Loss 0.072585 | Grad 0.2524 \n","[2023-12-09 07:29:02,417::train::INFO] [Train] Iter 0406 | Loss 0.075706 | Grad 0.3263 \n","[2023-12-09 07:29:02,500::train::INFO] [Train] Iter 0407 | Loss 0.071513 | Grad 0.3040 \n","[2023-12-09 07:29:02,583::train::INFO] [Train] Iter 0408 | Loss 0.071425 | Grad 0.1890 \n","[2023-12-09 07:29:02,667::train::INFO] [Train] Iter 0409 | Loss 0.071578 | Grad 0.3514 \n","[2023-12-09 07:29:02,752::train::INFO] [Train] Iter 0410 | Loss 0.071217 | Grad 0.3789 \n","[2023-12-09 07:29:02,835::train::INFO] [Train] Iter 0411 | Loss 0.070079 | Grad 0.2318 \n","[2023-12-09 07:29:02,919::train::INFO] [Train] Iter 0412 | Loss 0.071336 | Grad 0.2405 \n","[2023-12-09 07:29:03,005::train::INFO] [Train] Iter 0413 | Loss 0.071031 | Grad 0.2163 \n","[2023-12-09 07:29:03,089::train::INFO] [Train] Iter 0414 | Loss 0.070759 | Grad 0.2717 \n","[2023-12-09 07:29:03,172::train::INFO] [Train] Iter 0415 | Loss 0.070555 | Grad 0.2958 \n","[2023-12-09 07:29:03,256::train::INFO] [Train] Iter 0416 | Loss 0.070699 | Grad 0.2499 \n","[2023-12-09 07:29:03,340::train::INFO] [Train] Iter 0417 | Loss 0.071595 | Grad 0.2378 \n","[2023-12-09 07:29:03,423::train::INFO] [Train] Iter 0418 | Loss 0.069683 | Grad 0.1868 \n","[2023-12-09 07:29:03,509::train::INFO] [Train] Iter 0419 | Loss 0.070232 | Grad 0.2018 \n","[2023-12-09 07:29:03,592::train::INFO] [Train] Iter 0420 | Loss 0.068588 | Grad 0.1839 \n","[2023-12-09 07:29:03,676::train::INFO] [Train] Iter 0421 | Loss 0.070952 | Grad 0.3274 \n","[2023-12-09 07:29:03,759::train::INFO] [Train] Iter 0422 | Loss 0.068353 | Grad 0.1861 \n","[2023-12-09 07:29:03,842::train::INFO] [Train] Iter 0423 | Loss 0.067525 | Grad 0.1450 \n","[2023-12-09 07:29:03,925::train::INFO] [Train] Iter 0424 | Loss 0.070717 | Grad 0.2878 \n","[2023-12-09 07:29:04,008::train::INFO] [Train] Iter 0425 | Loss 0.072723 | Grad 0.2860 \n","[2023-12-09 07:29:04,092::train::INFO] [Train] Iter 0426 | Loss 0.070902 | Grad 0.1948 \n","[2023-12-09 07:29:04,175::train::INFO] [Train] Iter 0427 | Loss 0.068538 | Grad 0.1794 \n","[2023-12-09 07:29:04,260::train::INFO] [Train] Iter 0428 | Loss 0.067620 | Grad 0.1925 \n","[2023-12-09 07:29:04,343::train::INFO] [Train] Iter 0429 | Loss 0.069502 | Grad 0.2273 \n","[2023-12-09 07:29:04,427::train::INFO] [Train] Iter 0430 | Loss 0.073202 | Grad 0.2532 \n","[2023-12-09 07:29:04,512::train::INFO] [Train] Iter 0431 | Loss 0.068075 | Grad 0.2182 \n","[2023-12-09 07:29:04,595::train::INFO] [Train] Iter 0432 | Loss 0.067768 | Grad 0.1849 \n","[2023-12-09 07:29:04,679::train::INFO] [Train] Iter 0433 | Loss 0.068371 | Grad 0.1448 \n","[2023-12-09 07:29:04,763::train::INFO] [Train] Iter 0434 | Loss 0.068425 | Grad 0.1830 \n","[2023-12-09 07:29:04,849::train::INFO] [Train] Iter 0435 | Loss 0.068428 | Grad 0.2728 \n","[2023-12-09 07:29:04,948::train::INFO] [Train] Iter 0436 | Loss 0.065603 | Grad 0.2437 \n","[2023-12-09 07:29:05,042::train::INFO] [Train] Iter 0437 | Loss 0.066650 | Grad 0.2697 \n","[2023-12-09 07:29:05,133::train::INFO] [Train] Iter 0438 | Loss 0.066543 | Grad 0.1981 \n","[2023-12-09 07:29:05,227::train::INFO] [Train] Iter 0439 | Loss 0.067393 | Grad 0.2359 \n","[2023-12-09 07:29:05,318::train::INFO] [Train] Iter 0440 | Loss 0.069082 | Grad 0.2294 \n","[2023-12-09 07:29:05,418::train::INFO] [Train] Iter 0441 | Loss 0.068678 | Grad 0.2377 \n","[2023-12-09 07:29:05,509::train::INFO] [Train] Iter 0442 | Loss 0.068352 | Grad 0.2939 \n","[2023-12-09 07:29:05,601::train::INFO] [Train] Iter 0443 | Loss 0.067952 | Grad 0.2493 \n","[2023-12-09 07:29:05,698::train::INFO] [Train] Iter 0444 | Loss 0.066849 | Grad 0.3421 \n","[2023-12-09 07:29:05,791::train::INFO] [Train] Iter 0445 | Loss 0.066445 | Grad 0.2449 \n","[2023-12-09 07:29:05,882::train::INFO] [Train] Iter 0446 | Loss 0.066859 | Grad 0.1384 \n","[2023-12-09 07:29:05,973::train::INFO] [Train] Iter 0447 | Loss 0.068173 | Grad 0.2901 \n","[2023-12-09 07:29:06,064::train::INFO] [Train] Iter 0448 | Loss 0.066650 | Grad 0.2255 \n","[2023-12-09 07:29:06,155::train::INFO] [Train] Iter 0449 | Loss 0.068610 | Grad 0.2832 \n","[2023-12-09 07:29:06,248::train::INFO] [Train] Iter 0450 | Loss 0.066051 | Grad 0.1707 \n","[2023-12-09 07:29:06,341::train::INFO] [Train] Iter 0451 | Loss 0.066661 | Grad 0.1665 \n","[2023-12-09 07:29:06,432::train::INFO] [Train] Iter 0452 | Loss 0.067490 | Grad 0.3437 \n","[2023-12-09 07:29:06,524::train::INFO] [Train] Iter 0453 | Loss 0.067134 | Grad 0.2165 \n","[2023-12-09 07:29:06,616::train::INFO] [Train] Iter 0454 | Loss 0.066755 | Grad 0.3249 \n","[2023-12-09 07:29:06,715::train::INFO] [Train] Iter 0455 | Loss 0.065345 | Grad 0.2891 \n","[2023-12-09 07:29:06,805::train::INFO] [Train] Iter 0456 | Loss 0.067313 | Grad 0.1738 \n","[2023-12-09 07:29:06,898::train::INFO] [Train] Iter 0457 | Loss 0.065815 | Grad 0.6329 \n","[2023-12-09 07:29:06,989::train::INFO] [Train] Iter 0458 | Loss 0.064285 | Grad 0.1544 \n","[2023-12-09 07:29:07,080::train::INFO] [Train] Iter 0459 | Loss 0.063241 | Grad 0.2382 \n","[2023-12-09 07:29:07,176::train::INFO] [Train] Iter 0460 | Loss 0.065903 | Grad 0.3000 \n","[2023-12-09 07:29:07,268::train::INFO] [Train] Iter 0461 | Loss 0.066250 | Grad 0.1771 \n","[2023-12-09 07:29:07,359::train::INFO] [Train] Iter 0462 | Loss 0.067437 | Grad 0.3708 \n","[2023-12-09 07:29:07,451::train::INFO] [Train] Iter 0463 | Loss 0.063277 | Grad 0.2603 \n","[2023-12-09 07:29:07,542::train::INFO] [Train] Iter 0464 | Loss 0.065596 | Grad 0.3354 \n","[2023-12-09 07:29:07,635::train::INFO] [Train] Iter 0465 | Loss 0.065363 | Grad 0.2779 \n","[2023-12-09 07:29:07,727::train::INFO] [Train] Iter 0466 | Loss 0.064518 | Grad 0.1655 \n","[2023-12-09 07:29:07,818::train::INFO] [Train] Iter 0467 | Loss 0.064225 | Grad 0.3533 \n","[2023-12-09 07:29:07,909::train::INFO] [Train] Iter 0468 | Loss 0.066086 | Grad 0.6487 \n","[2023-12-09 07:29:08,006::train::INFO] [Train] Iter 0469 | Loss 0.064803 | Grad 0.1758 \n","[2023-12-09 07:29:08,098::train::INFO] [Train] Iter 0470 | Loss 0.064608 | Grad 0.3507 \n","[2023-12-09 07:29:08,189::train::INFO] [Train] Iter 0471 | Loss 0.069294 | Grad 0.6799 \n","[2023-12-09 07:29:08,287::train::INFO] [Train] Iter 0472 | Loss 0.065113 | Grad 0.3048 \n","[2023-12-09 07:29:08,380::train::INFO] [Train] Iter 0473 | Loss 0.065708 | Grad 0.5423 \n","[2023-12-09 07:29:08,472::train::INFO] [Train] Iter 0474 | Loss 0.064497 | Grad 0.2541 \n","[2023-12-09 07:29:08,562::train::INFO] [Train] Iter 0475 | Loss 0.062700 | Grad 0.1949 \n","[2023-12-09 07:29:08,650::train::INFO] [Train] Iter 0476 | Loss 0.066501 | Grad 0.3640 \n","[2023-12-09 07:29:08,740::train::INFO] [Train] Iter 0477 | Loss 0.065196 | Grad 0.4190 \n","[2023-12-09 07:29:08,834::train::INFO] [Train] Iter 0478 | Loss 0.062409 | Grad 0.2226 \n","[2023-12-09 07:29:08,924::train::INFO] [Train] Iter 0479 | Loss 0.067836 | Grad 0.2753 \n","[2023-12-09 07:29:09,014::train::INFO] [Train] Iter 0480 | Loss 0.064372 | Grad 0.3114 \n","[2023-12-09 07:29:09,103::train::INFO] [Train] Iter 0481 | Loss 0.063886 | Grad 0.1834 \n","[2023-12-09 07:29:09,199::train::INFO] [Train] Iter 0482 | Loss 0.063105 | Grad 0.3912 \n","[2023-12-09 07:29:09,290::train::INFO] [Train] Iter 0483 | Loss 0.066665 | Grad 0.2792 \n","[2023-12-09 07:29:09,380::train::INFO] [Train] Iter 0484 | Loss 0.066028 | Grad 0.2649 \n","[2023-12-09 07:29:09,471::train::INFO] [Train] Iter 0485 | Loss 0.064190 | Grad 0.2252 \n","[2023-12-09 07:29:09,561::train::INFO] [Train] Iter 0486 | Loss 0.063620 | Grad 0.2226 \n","[2023-12-09 07:29:09,652::train::INFO] [Train] Iter 0487 | Loss 0.062916 | Grad 0.1526 \n","[2023-12-09 07:29:09,742::train::INFO] [Train] Iter 0488 | Loss 0.061981 | Grad 0.1494 \n","[2023-12-09 07:29:09,840::train::INFO] [Train] Iter 0489 | Loss 0.065233 | Grad 0.4660 \n","[2023-12-09 07:29:09,930::train::INFO] [Train] Iter 0490 | Loss 0.063163 | Grad 0.1411 \n","[2023-12-09 07:29:10,023::train::INFO] [Train] Iter 0491 | Loss 0.063266 | Grad 0.2635 \n","[2023-12-09 07:29:10,117::train::INFO] [Train] Iter 0492 | Loss 0.064254 | Grad 0.1587 \n","[2023-12-09 07:29:10,211::train::INFO] [Train] Iter 0493 | Loss 0.061238 | Grad 0.0678 \n","[2023-12-09 07:29:10,310::train::INFO] [Train] Iter 0494 | Loss 0.061549 | Grad 0.2594 \n","[2023-12-09 07:29:10,402::train::INFO] [Train] Iter 0495 | Loss 0.061645 | Grad 0.2131 \n","[2023-12-09 07:29:10,492::train::INFO] [Train] Iter 0496 | Loss 0.061610 | Grad 0.1379 \n","[2023-12-09 07:29:10,580::train::INFO] [Train] Iter 0497 | Loss 0.062456 | Grad 0.2133 \n","[2023-12-09 07:29:10,669::train::INFO] [Train] Iter 0498 | Loss 0.060182 | Grad 0.1875 \n","[2023-12-09 07:29:10,758::train::INFO] [Train] Iter 0499 | Loss 0.061604 | Grad 0.1962 \n","[2023-12-09 07:29:10,850::train::INFO] [Train] Iter 0500 | Loss 0.060557 | Grad 0.1714 \n","Validate: 100% 241/241 [00:03<00:00, 62.53it/s]\n","val loss list [tensor(0.0623, device='cuda:0'), tensor(0.0621, device='cuda:0'), tensor(0.0615, device='cuda:0'), tensor(0.0601, device='cuda:0'), tensor(0.0595, device='cuda:0'), tensor(0.0586, device='cuda:0'), tensor(0.0618, device='cuda:0'), tensor(0.0623, device='cuda:0'), tensor(0.0615, device='cuda:0'), tensor(0.0595, device='cuda:0'), tensor(0.0599, device='cuda:0'), tensor(0.0594, device='cuda:0'), tensor(0.0606, device='cuda:0'), tensor(0.0588, device='cuda:0'), tensor(0.0608, device='cuda:0'), tensor(0.0617, device='cuda:0'), tensor(0.0601, device='cuda:0'), tensor(0.0617, device='cuda:0'), tensor(0.0604, device='cuda:0'), tensor(0.0622, device='cuda:0'), tensor(0.0614, device='cuda:0'), tensor(0.0599, device='cuda:0'), tensor(0.0611, device='cuda:0'), tensor(0.0594, device='cuda:0'), tensor(0.0595, device='cuda:0'), tensor(0.0598, device='cuda:0'), tensor(0.0623, device='cuda:0'), tensor(0.0608, device='cuda:0'), tensor(0.0604, device='cuda:0'), tensor(0.0615, device='cuda:0'), tensor(0.0602, device='cuda:0'), tensor(0.0615, device='cuda:0'), tensor(0.0620, device='cuda:0'), tensor(0.0600, device='cuda:0'), tensor(0.0609, device='cuda:0'), tensor(0.0612, device='cuda:0'), tensor(0.0596, device='cuda:0'), tensor(0.0595, device='cuda:0'), tensor(0.0585, device='cuda:0'), tensor(0.0598, device='cuda:0'), tensor(0.0603, device='cuda:0'), tensor(0.0589, device='cuda:0'), tensor(0.0610, device='cuda:0'), tensor(0.0635, device='cuda:0'), tensor(0.0621, device='cuda:0'), tensor(0.0599, device='cuda:0'), tensor(0.0580, device='cuda:0'), tensor(0.0624, device='cuda:0'), tensor(0.0599, device='cuda:0'), tensor(0.0619, device='cuda:0'), tensor(0.0602, device='cuda:0'), tensor(0.0611, device='cuda:0'), tensor(0.0604, device='cuda:0'), tensor(0.0599, device='cuda:0'), tensor(0.0618, device='cuda:0'), tensor(0.0607, device='cuda:0'), tensor(0.0609, device='cuda:0'), tensor(0.0609, device='cuda:0'), tensor(0.0618, device='cuda:0'), tensor(0.0616, device='cuda:0'), tensor(0.0591, device='cuda:0'), tensor(0.0629, device='cuda:0'), tensor(0.0612, device='cuda:0'), tensor(0.0603, device='cuda:0'), tensor(0.0605, device='cuda:0'), tensor(0.0593, device='cuda:0'), tensor(0.0603, device='cuda:0'), tensor(0.0597, device='cuda:0'), tensor(0.0600, device='cuda:0'), tensor(0.0597, device='cuda:0'), tensor(0.0616, device='cuda:0'), tensor(0.0602, device='cuda:0'), tensor(0.0600, device='cuda:0'), tensor(0.0622, device='cuda:0'), tensor(0.0609, device='cuda:0'), tensor(0.0609, device='cuda:0'), tensor(0.0612, device='cuda:0'), tensor(0.0610, device='cuda:0'), tensor(0.0621, device='cuda:0'), tensor(0.0605, device='cuda:0'), tensor(0.0614, device='cuda:0'), tensor(0.0595, device='cuda:0'), tensor(0.0605, device='cuda:0'), tensor(0.0610, device='cuda:0'), tensor(0.0609, device='cuda:0'), tensor(0.0622, device='cuda:0'), tensor(0.0597, device='cuda:0'), tensor(0.0601, device='cuda:0'), tensor(0.0608, device='cuda:0'), tensor(0.0618, device='cuda:0'), tensor(0.0604, device='cuda:0'), tensor(0.0615, device='cuda:0'), tensor(0.0599, device='cuda:0'), tensor(0.0617, device='cuda:0'), tensor(0.0617, device='cuda:0'), tensor(0.0596, device='cuda:0'), tensor(0.0609, device='cuda:0'), tensor(0.0589, device='cuda:0'), tensor(0.0616, device='cuda:0'), tensor(0.0601, device='cuda:0'), tensor(0.0609, device='cuda:0'), tensor(0.0594, device='cuda:0'), tensor(0.0608, device='cuda:0'), tensor(0.0613, device='cuda:0'), tensor(0.0593, device='cuda:0'), tensor(0.0594, device='cuda:0'), tensor(0.0595, device='cuda:0'), tensor(0.0594, device='cuda:0'), tensor(0.0603, device='cuda:0'), tensor(0.0594, device='cuda:0'), tensor(0.0596, device='cuda:0'), tensor(0.0603, device='cuda:0'), tensor(0.0594, device='cuda:0'), tensor(0.0611, device='cuda:0'), tensor(0.0612, device='cuda:0'), tensor(0.0590, device='cuda:0'), tensor(0.0608, device='cuda:0'), tensor(0.0604, device='cuda:0'), tensor(0.0598, device='cuda:0'), tensor(0.0615, device='cuda:0'), tensor(0.0592, device='cuda:0'), tensor(0.0609, device='cuda:0'), tensor(0.0612, device='cuda:0'), tensor(0.0598, device='cuda:0'), tensor(0.0604, device='cuda:0'), tensor(0.0610, device='cuda:0'), tensor(0.0606, device='cuda:0'), tensor(0.0608, device='cuda:0'), tensor(0.0591, device='cuda:0'), tensor(0.0587, device='cuda:0'), tensor(0.0587, device='cuda:0'), tensor(0.0617, device='cuda:0'), tensor(0.0579, device='cuda:0'), tensor(0.0614, device='cuda:0'), tensor(0.0596, device='cuda:0'), tensor(0.0617, device='cuda:0'), tensor(0.0610, device='cuda:0'), tensor(0.0608, device='cuda:0'), tensor(0.0589, device='cuda:0'), tensor(0.0605, device='cuda:0'), tensor(0.0605, device='cuda:0'), tensor(0.0610, device='cuda:0'), tensor(0.0600, device='cuda:0'), tensor(0.0615, device='cuda:0'), tensor(0.0597, device='cuda:0'), tensor(0.0604, device='cuda:0'), tensor(0.0601, device='cuda:0'), tensor(0.0601, device='cuda:0'), tensor(0.0592, device='cuda:0'), tensor(0.0607, device='cuda:0'), tensor(0.0621, device='cuda:0'), tensor(0.0603, device='cuda:0'), tensor(0.0641, device='cuda:0'), tensor(0.0598, device='cuda:0'), tensor(0.0586, device='cuda:0'), tensor(0.0600, device='cuda:0'), tensor(0.0606, device='cuda:0'), tensor(0.0629, device='cuda:0'), tensor(0.0614, device='cuda:0'), tensor(0.0623, device='cuda:0'), tensor(0.0613, device='cuda:0'), tensor(0.0598, device='cuda:0'), tensor(0.0601, device='cuda:0'), tensor(0.0610, device='cuda:0'), tensor(0.0608, device='cuda:0'), tensor(0.0609, device='cuda:0'), tensor(0.0621, device='cuda:0'), tensor(0.0598, device='cuda:0'), tensor(0.0596, device='cuda:0'), tensor(0.0621, device='cuda:0'), tensor(0.0594, device='cuda:0'), tensor(0.0618, device='cuda:0'), tensor(0.0611, device='cuda:0'), tensor(0.0609, device='cuda:0'), tensor(0.0616, device='cuda:0'), tensor(0.0615, device='cuda:0'), tensor(0.0603, device='cuda:0'), tensor(0.0601, device='cuda:0'), tensor(0.0617, device='cuda:0'), tensor(0.0592, device='cuda:0'), tensor(0.0582, device='cuda:0'), tensor(0.0623, device='cuda:0'), tensor(0.0606, device='cuda:0'), tensor(0.0627, device='cuda:0'), tensor(0.0599, device='cuda:0'), tensor(0.0601, device='cuda:0'), tensor(0.0611, device='cuda:0'), tensor(0.0607, device='cuda:0'), tensor(0.0619, device='cuda:0'), tensor(0.0606, device='cuda:0'), tensor(0.0609, device='cuda:0'), tensor(0.0606, device='cuda:0'), tensor(0.0594, device='cuda:0'), tensor(0.0599, device='cuda:0'), tensor(0.0602, device='cuda:0'), tensor(0.0596, device='cuda:0'), tensor(0.0597, device='cuda:0'), tensor(0.0629, device='cuda:0'), tensor(0.0616, device='cuda:0'), tensor(0.0597, device='cuda:0'), tensor(0.0613, device='cuda:0'), tensor(0.0628, device='cuda:0'), tensor(0.0613, device='cuda:0'), tensor(0.0582, device='cuda:0'), tensor(0.0604, device='cuda:0'), tensor(0.0634, device='cuda:0'), tensor(0.0594, device='cuda:0'), tensor(0.0625, device='cuda:0'), tensor(0.0613, device='cuda:0'), tensor(0.0610, device='cuda:0'), tensor(0.0609, device='cuda:0'), tensor(0.0593, device='cuda:0'), tensor(0.0602, device='cuda:0'), tensor(0.0603, device='cuda:0'), tensor(0.0624, device='cuda:0'), tensor(0.0586, device='cuda:0'), tensor(0.0598, device='cuda:0'), tensor(0.0615, device='cuda:0'), tensor(0.0617, device='cuda:0'), tensor(0.0601, device='cuda:0'), tensor(0.0599, device='cuda:0'), tensor(0.0622, device='cuda:0'), tensor(0.0616, device='cuda:0'), tensor(0.0611, device='cuda:0'), tensor(0.0616, device='cuda:0'), tensor(0.0603, device='cuda:0'), tensor(0.0611, device='cuda:0'), tensor(0.0598, device='cuda:0'), tensor(0.0601, device='cuda:0'), tensor(0.0589, device='cuda:0'), tensor(0.0591, device='cuda:0'), tensor(0.0611, device='cuda:0'), tensor(0.0631, device='cuda:0'), tensor(0.0626, device='cuda:0'), tensor(0.0608, device='cuda:0'), tensor(0.0586, device='cuda:0'), tensor(0.0604, device='cuda:0'), tensor(0.0596, device='cuda:0'), tensor(0.0609, device='cuda:0'), tensor(0.0601, device='cuda:0'), tensor(0.0609, device='cuda:0')]\n","[2023-12-09 07:29:15,057::train::INFO] [Train] Iter 0501 | Loss 0.059654 | Grad 0.1234 \n","[2023-12-09 07:29:15,140::train::INFO] [Train] Iter 0502 | Loss 0.059448 | Grad 0.1362 \n","[2023-12-09 07:29:15,223::train::INFO] [Train] Iter 0503 | Loss 0.061456 | Grad 0.1213 \n","[2023-12-09 07:29:15,307::train::INFO] [Train] Iter 0504 | Loss 0.062449 | Grad 0.1681 \n","[2023-12-09 07:29:15,390::train::INFO] [Train] Iter 0505 | Loss 0.061063 | Grad 0.3043 \n","[2023-12-09 07:29:15,475::train::INFO] [Train] Iter 0506 | Loss 0.060257 | Grad 0.1333 \n","[2023-12-09 07:29:15,558::train::INFO] [Train] Iter 0507 | Loss 0.059461 | Grad 0.1603 \n","[2023-12-09 07:29:15,641::train::INFO] [Train] Iter 0508 | Loss 0.059661 | Grad 0.2115 \n","[2023-12-09 07:29:15,725::train::INFO] [Train] Iter 0509 | Loss 0.058354 | Grad 0.2149 \n","[2023-12-09 07:29:15,808::train::INFO] [Train] Iter 0510 | Loss 0.061660 | Grad 0.1660 \n","[2023-12-09 07:29:15,891::train::INFO] [Train] Iter 0511 | Loss 0.058323 | Grad 0.0980 \n","[2023-12-09 07:29:15,976::train::INFO] [Train] Iter 0512 | Loss 0.060686 | Grad 0.1775 \n","[2023-12-09 07:29:16,059::train::INFO] [Train] Iter 0513 | Loss 0.063855 | Grad 0.2711 \n","[2023-12-09 07:29:16,144::train::INFO] [Train] Iter 0514 | Loss 0.061637 | Grad 0.1854 \n","[2023-12-09 07:29:16,227::train::INFO] [Train] Iter 0515 | Loss 0.058291 | Grad 0.1139 \n","[2023-12-09 07:29:16,310::train::INFO] [Train] Iter 0516 | Loss 0.058955 | Grad 0.1926 \n","[2023-12-09 07:29:16,393::train::INFO] [Train] Iter 0517 | Loss 0.057713 | Grad 0.1051 \n","[2023-12-09 07:29:16,476::train::INFO] [Train] Iter 0518 | Loss 0.057865 | Grad 0.1178 \n","[2023-12-09 07:29:16,559::train::INFO] [Train] Iter 0519 | Loss 0.057428 | Grad 0.1183 \n","[2023-12-09 07:29:16,643::train::INFO] [Train] Iter 0520 | Loss 0.058320 | Grad 0.1258 \n","[2023-12-09 07:29:16,726::train::INFO] [Train] Iter 0521 | Loss 0.061995 | Grad 0.2087 \n","[2023-12-09 07:29:16,810::train::INFO] [Train] Iter 0522 | Loss 0.057241 | Grad 0.1657 \n","[2023-12-09 07:29:16,897::train::INFO] [Train] Iter 0523 | Loss 0.057443 | Grad 0.1197 \n","[2023-12-09 07:29:16,982::train::INFO] [Train] Iter 0524 | Loss 0.059277 | Grad 0.1306 \n","[2023-12-09 07:29:17,067::train::INFO] [Train] Iter 0525 | Loss 0.059030 | Grad 0.1489 \n","[2023-12-09 07:29:17,153::train::INFO] [Train] Iter 0526 | Loss 0.058639 | Grad 0.1517 \n","[2023-12-09 07:29:17,237::train::INFO] [Train] Iter 0527 | Loss 0.056023 | Grad 0.0707 \n","[2023-12-09 07:29:17,321::train::INFO] [Train] Iter 0528 | Loss 0.057628 | Grad 0.2134 \n","[2023-12-09 07:29:17,406::train::INFO] [Train] Iter 0529 | Loss 0.058034 | Grad 0.2630 \n","[2023-12-09 07:29:17,490::train::INFO] [Train] Iter 0530 | Loss 0.058606 | Grad 0.1356 \n","[2023-12-09 07:29:17,575::train::INFO] [Train] Iter 0531 | Loss 0.060137 | Grad 0.2121 \n","[2023-12-09 07:29:17,659::train::INFO] [Train] Iter 0532 | Loss 0.060241 | Grad 0.2454 \n","[2023-12-09 07:29:17,744::train::INFO] [Train] Iter 0533 | Loss 0.057582 | Grad 0.1758 \n","[2023-12-09 07:29:17,831::train::INFO] [Train] Iter 0534 | Loss 0.057455 | Grad 0.1420 \n","[2023-12-09 07:29:17,916::train::INFO] [Train] Iter 0535 | Loss 0.058745 | Grad 0.1798 \n","[2023-12-09 07:29:18,002::train::INFO] [Train] Iter 0536 | Loss 0.058900 | Grad 0.2336 \n","[2023-12-09 07:29:18,086::train::INFO] [Train] Iter 0537 | Loss 0.056548 | Grad 0.1194 \n","[2023-12-09 07:29:18,172::train::INFO] [Train] Iter 0538 | Loss 0.055729 | Grad 0.1716 \n","[2023-12-09 07:29:18,255::train::INFO] [Train] Iter 0539 | Loss 0.057698 | Grad 0.1472 \n","[2023-12-09 07:29:18,343::train::INFO] [Train] Iter 0540 | Loss 0.056976 | Grad 0.1181 \n","[2023-12-09 07:29:18,427::train::INFO] [Train] Iter 0541 | Loss 0.056840 | Grad 0.1689 \n","[2023-12-09 07:29:18,510::train::INFO] [Train] Iter 0542 | Loss 0.057748 | Grad 0.1720 \n","[2023-12-09 07:29:18,594::train::INFO] [Train] Iter 0543 | Loss 0.056695 | Grad 0.0993 \n","[2023-12-09 07:29:18,678::train::INFO] [Train] Iter 0544 | Loss 0.057379 | Grad 0.2132 \n","[2023-12-09 07:29:18,763::train::INFO] [Train] Iter 0545 | Loss 0.059046 | Grad 0.1262 \n","[2023-12-09 07:29:18,847::train::INFO] [Train] Iter 0546 | Loss 0.056391 | Grad 0.1503 \n","[2023-12-09 07:29:18,930::train::INFO] [Train] Iter 0547 | Loss 0.056707 | Grad 0.1882 \n","[2023-12-09 07:29:19,014::train::INFO] [Train] Iter 0548 | Loss 0.057002 | Grad 0.2235 \n","[2023-12-09 07:29:19,098::train::INFO] [Train] Iter 0549 | Loss 0.054452 | Grad 0.1310 \n","[2023-12-09 07:29:19,182::train::INFO] [Train] Iter 0550 | Loss 0.060749 | Grad 0.2506 \n","[2023-12-09 07:29:19,266::train::INFO] [Train] Iter 0551 | Loss 0.057214 | Grad 0.1873 \n","[2023-12-09 07:29:19,350::train::INFO] [Train] Iter 0552 | Loss 0.056301 | Grad 0.2317 \n","[2023-12-09 07:29:19,434::train::INFO] [Train] Iter 0553 | Loss 0.055692 | Grad 0.1686 \n","[2023-12-09 07:29:19,517::train::INFO] [Train] Iter 0554 | Loss 0.058009 | Grad 0.2856 \n","[2023-12-09 07:29:19,600::train::INFO] [Train] Iter 0555 | Loss 0.056777 | Grad 0.1574 \n","[2023-12-09 07:29:19,683::train::INFO] [Train] Iter 0556 | Loss 0.055967 | Grad 0.1490 \n","[2023-12-09 07:29:19,767::train::INFO] [Train] Iter 0557 | Loss 0.058018 | Grad 0.1775 \n","[2023-12-09 07:29:19,855::train::INFO] [Train] Iter 0558 | Loss 0.056792 | Grad 0.1465 \n","[2023-12-09 07:29:19,939::train::INFO] [Train] Iter 0559 | Loss 0.055687 | Grad 0.1630 \n","[2023-12-09 07:29:20,022::train::INFO] [Train] Iter 0560 | Loss 0.057143 | Grad 0.1427 \n","[2023-12-09 07:29:20,109::train::INFO] [Train] Iter 0561 | Loss 0.054724 | Grad 0.1909 \n","[2023-12-09 07:29:20,193::train::INFO] [Train] Iter 0562 | Loss 0.054797 | Grad 0.2329 \n","[2023-12-09 07:29:20,276::train::INFO] [Train] Iter 0563 | Loss 0.055238 | Grad 0.1875 \n","[2023-12-09 07:29:20,362::train::INFO] [Train] Iter 0564 | Loss 0.055549 | Grad 0.1763 \n","[2023-12-09 07:29:20,450::train::INFO] [Train] Iter 0565 | Loss 0.054848 | Grad 0.1906 \n","[2023-12-09 07:29:20,533::train::INFO] [Train] Iter 0566 | Loss 0.057242 | Grad 0.2714 \n","[2023-12-09 07:29:20,617::train::INFO] [Train] Iter 0567 | Loss 0.055051 | Grad 0.1780 \n","[2023-12-09 07:29:20,700::train::INFO] [Train] Iter 0568 | Loss 0.053524 | Grad 0.2476 \n","[2023-12-09 07:29:20,783::train::INFO] [Train] Iter 0569 | Loss 0.056243 | Grad 0.1549 \n","[2023-12-09 07:29:20,867::train::INFO] [Train] Iter 0570 | Loss 0.054219 | Grad 0.1963 \n","[2023-12-09 07:29:20,951::train::INFO] [Train] Iter 0571 | Loss 0.055974 | Grad 0.2403 \n","[2023-12-09 07:29:21,035::train::INFO] [Train] Iter 0572 | Loss 0.055676 | Grad 0.1210 \n","[2023-12-09 07:29:21,121::train::INFO] [Train] Iter 0573 | Loss 0.056044 | Grad 0.2073 \n","[2023-12-09 07:29:21,213::train::INFO] [Train] Iter 0574 | Loss 0.054592 | Grad 0.2017 \n","[2023-12-09 07:29:21,304::train::INFO] [Train] Iter 0575 | Loss 0.055144 | Grad 0.1755 \n","[2023-12-09 07:29:21,397::train::INFO] [Train] Iter 0576 | Loss 0.054646 | Grad 0.1230 \n","[2023-12-09 07:29:21,488::train::INFO] [Train] Iter 0577 | Loss 0.055298 | Grad 0.2667 \n","[2023-12-09 07:29:21,578::train::INFO] [Train] Iter 0578 | Loss 0.054130 | Grad 0.1874 \n","[2023-12-09 07:29:21,668::train::INFO] [Train] Iter 0579 | Loss 0.054232 | Grad 0.1913 \n","[2023-12-09 07:29:21,758::train::INFO] [Train] Iter 0580 | Loss 0.053450 | Grad 0.1174 \n","[2023-12-09 07:29:21,849::train::INFO] [Train] Iter 0581 | Loss 0.056161 | Grad 0.1951 \n","[2023-12-09 07:29:21,940::train::INFO] [Train] Iter 0582 | Loss 0.052047 | Grad 0.1718 \n","[2023-12-09 07:29:22,030::train::INFO] [Train] Iter 0583 | Loss 0.054605 | Grad 0.2197 \n","[2023-12-09 07:29:22,124::train::INFO] [Train] Iter 0584 | Loss 0.055430 | Grad 0.1581 \n","[2023-12-09 07:29:22,226::train::INFO] [Train] Iter 0585 | Loss 0.054091 | Grad 0.1321 \n","[2023-12-09 07:29:22,317::train::INFO] [Train] Iter 0586 | Loss 0.053774 | Grad 0.1405 \n","[2023-12-09 07:29:22,409::train::INFO] [Train] Iter 0587 | Loss 0.052827 | Grad 0.1435 \n","[2023-12-09 07:29:22,499::train::INFO] [Train] Iter 0588 | Loss 0.054836 | Grad 0.1954 \n","[2023-12-09 07:29:22,590::train::INFO] [Train] Iter 0589 | Loss 0.053249 | Grad 0.1884 \n","[2023-12-09 07:29:22,680::train::INFO] [Train] Iter 0590 | Loss 0.055318 | Grad 0.1683 \n","[2023-12-09 07:29:22,772::train::INFO] [Train] Iter 0591 | Loss 0.053363 | Grad 0.1551 \n","[2023-12-09 07:29:22,865::train::INFO] [Train] Iter 0592 | Loss 0.053740 | Grad 0.2533 \n","[2023-12-09 07:29:22,955::train::INFO] [Train] Iter 0593 | Loss 0.053569 | Grad 0.1849 \n","[2023-12-09 07:29:23,046::train::INFO] [Train] Iter 0594 | Loss 0.053795 | Grad 0.1270 \n","[2023-12-09 07:29:23,138::train::INFO] [Train] Iter 0595 | Loss 0.052937 | Grad 0.1226 \n","[2023-12-09 07:29:23,229::train::INFO] [Train] Iter 0596 | Loss 0.053986 | Grad 0.1471 \n","[2023-12-09 07:29:23,319::train::INFO] [Train] Iter 0597 | Loss 0.054170 | Grad 0.2137 \n","[2023-12-09 07:29:23,412::train::INFO] [Train] Iter 0598 | Loss 0.053267 | Grad 0.2185 \n","[2023-12-09 07:29:23,506::train::INFO] [Train] Iter 0599 | Loss 0.053370 | Grad 0.1252 \n","[2023-12-09 07:29:23,598::train::INFO] [Train] Iter 0600 | Loss 0.056168 | Grad 0.2228 \n","[2023-12-09 07:29:23,689::train::INFO] [Train] Iter 0601 | Loss 0.053939 | Grad 0.2402 \n","[2023-12-09 07:29:23,782::train::INFO] [Train] Iter 0602 | Loss 0.053576 | Grad 0.1569 \n","[2023-12-09 07:29:23,875::train::INFO] [Train] Iter 0603 | Loss 0.052653 | Grad 0.1562 \n","[2023-12-09 07:29:23,969::train::INFO] [Train] Iter 0604 | Loss 0.053053 | Grad 0.2565 \n","[2023-12-09 07:29:24,060::train::INFO] [Train] Iter 0605 | Loss 0.053408 | Grad 0.2696 \n","[2023-12-09 07:29:24,152::train::INFO] [Train] Iter 0606 | Loss 0.053422 | Grad 0.1039 \n","[2023-12-09 07:29:24,251::train::INFO] [Train] Iter 0607 | Loss 0.053044 | Grad 0.1538 \n","[2023-12-09 07:29:24,348::train::INFO] [Train] Iter 0608 | Loss 0.052791 | Grad 0.1077 \n","[2023-12-09 07:29:24,444::train::INFO] [Train] Iter 0609 | Loss 0.052880 | Grad 0.1545 \n","[2023-12-09 07:29:24,536::train::INFO] [Train] Iter 0610 | Loss 0.054761 | Grad 0.1436 \n","[2023-12-09 07:29:24,627::train::INFO] [Train] Iter 0611 | Loss 0.053553 | Grad 0.1734 \n","[2023-12-09 07:29:24,718::train::INFO] [Train] Iter 0612 | Loss 0.051824 | Grad 0.0744 \n","[2023-12-09 07:29:24,810::train::INFO] [Train] Iter 0613 | Loss 0.052105 | Grad 0.1035 \n","[2023-12-09 07:29:24,903::train::INFO] [Train] Iter 0614 | Loss 0.052252 | Grad 0.1343 \n","[2023-12-09 07:29:24,994::train::INFO] [Train] Iter 0615 | Loss 0.052338 | Grad 0.1623 \n","[2023-12-09 07:29:25,085::train::INFO] [Train] Iter 0616 | Loss 0.051264 | Grad 0.1133 \n","[2023-12-09 07:29:25,180::train::INFO] [Train] Iter 0617 | Loss 0.051627 | Grad 0.1480 \n","[2023-12-09 07:29:25,275::train::INFO] [Train] Iter 0618 | Loss 0.053591 | Grad 0.1393 \n","[2023-12-09 07:29:25,368::train::INFO] [Train] Iter 0619 | Loss 0.051758 | Grad 0.1125 \n","[2023-12-09 07:29:25,460::train::INFO] [Train] Iter 0620 | Loss 0.050920 | Grad 0.0780 \n","[2023-12-09 07:29:25,552::train::INFO] [Train] Iter 0621 | Loss 0.052211 | Grad 0.1892 \n","[2023-12-09 07:29:25,644::train::INFO] [Train] Iter 0622 | Loss 0.051870 | Grad 0.0984 \n","[2023-12-09 07:29:25,737::train::INFO] [Train] Iter 0623 | Loss 0.051735 | Grad 0.0825 \n","[2023-12-09 07:29:25,831::train::INFO] [Train] Iter 0624 | Loss 0.052937 | Grad 0.0931 \n","[2023-12-09 07:29:25,923::train::INFO] [Train] Iter 0625 | Loss 0.053107 | Grad 0.0991 \n","[2023-12-09 07:29:26,014::train::INFO] [Train] Iter 0626 | Loss 0.050537 | Grad 0.1561 \n","[2023-12-09 07:29:26,106::train::INFO] [Train] Iter 0627 | Loss 0.050211 | Grad 0.1006 \n","[2023-12-09 07:29:26,196::train::INFO] [Train] Iter 0628 | Loss 0.052512 | Grad 0.1633 \n","[2023-12-09 07:29:26,285::train::INFO] [Train] Iter 0629 | Loss 0.052778 | Grad 0.1449 \n","[2023-12-09 07:29:26,377::train::INFO] [Train] Iter 0630 | Loss 0.051438 | Grad 0.2343 \n","[2023-12-09 07:29:26,467::train::INFO] [Train] Iter 0631 | Loss 0.051635 | Grad 0.2815 \n","[2023-12-09 07:29:26,556::train::INFO] [Train] Iter 0632 | Loss 0.051203 | Grad 0.1569 \n","[2023-12-09 07:29:26,647::train::INFO] [Train] Iter 0633 | Loss 0.051115 | Grad 0.1577 \n","[2023-12-09 07:29:26,737::train::INFO] [Train] Iter 0634 | Loss 0.051320 | Grad 0.1587 \n","[2023-12-09 07:29:26,829::train::INFO] [Train] Iter 0635 | Loss 0.051309 | Grad 0.2003 \n","[2023-12-09 07:29:26,921::train::INFO] [Train] Iter 0636 | Loss 0.053305 | Grad 0.2011 \n","[2023-12-09 07:29:27,013::train::INFO] [Train] Iter 0637 | Loss 0.050591 | Grad 0.1064 \n","[2023-12-09 07:29:27,105::train::INFO] [Train] Iter 0638 | Loss 0.051229 | Grad 0.2817 \n","[2023-12-09 07:29:27,196::train::INFO] [Train] Iter 0639 | Loss 0.052901 | Grad 0.1862 \n","[2023-12-09 07:29:27,289::train::INFO] [Train] Iter 0640 | Loss 0.051152 | Grad 0.1135 \n","[2023-12-09 07:29:27,382::train::INFO] [Train] Iter 0641 | Loss 0.050278 | Grad 0.1419 \n","[2023-12-09 07:29:27,467::train::INFO] [Train] Iter 0642 | Loss 0.050975 | Grad 0.1006 \n","[2023-12-09 07:29:27,550::train::INFO] [Train] Iter 0643 | Loss 0.050596 | Grad 0.2543 \n","[2023-12-09 07:29:27,634::train::INFO] [Train] Iter 0644 | Loss 0.051997 | Grad 0.3084 \n","[2023-12-09 07:29:27,718::train::INFO] [Train] Iter 0645 | Loss 0.051883 | Grad 0.1580 \n","[2023-12-09 07:29:27,802::train::INFO] [Train] Iter 0646 | Loss 0.051281 | Grad 0.2466 \n","[2023-12-09 07:29:27,887::train::INFO] [Train] Iter 0647 | Loss 0.050935 | Grad 0.3452 \n","[2023-12-09 07:29:27,972::train::INFO] [Train] Iter 0648 | Loss 0.050667 | Grad 0.1945 \n","[2023-12-09 07:29:28,056::train::INFO] [Train] Iter 0649 | Loss 0.050390 | Grad 0.1986 \n","[2023-12-09 07:29:28,141::train::INFO] [Train] Iter 0650 | Loss 0.051976 | Grad 0.2739 \n","[2023-12-09 07:29:28,226::train::INFO] [Train] Iter 0651 | Loss 0.050898 | Grad 0.2239 \n","[2023-12-09 07:29:28,310::train::INFO] [Train] Iter 0652 | Loss 0.051636 | Grad 0.2593 \n","[2023-12-09 07:29:28,394::train::INFO] [Train] Iter 0653 | Loss 0.053397 | Grad 0.2394 \n","[2023-12-09 07:29:28,477::train::INFO] [Train] Iter 0654 | Loss 0.050814 | Grad 0.1322 \n","[2023-12-09 07:29:28,560::train::INFO] [Train] Iter 0655 | Loss 0.050250 | Grad 0.1791 \n","[2023-12-09 07:29:28,642::train::INFO] [Train] Iter 0656 | Loss 0.050718 | Grad 0.1421 \n","[2023-12-09 07:29:28,725::train::INFO] [Train] Iter 0657 | Loss 0.052881 | Grad 0.4075 \n","[2023-12-09 07:29:28,808::train::INFO] [Train] Iter 0658 | Loss 0.051992 | Grad 0.1991 \n","[2023-12-09 07:29:28,891::train::INFO] [Train] Iter 0659 | Loss 0.048522 | Grad 0.0833 \n","[2023-12-09 07:29:28,975::train::INFO] [Train] Iter 0660 | Loss 0.052022 | Grad 0.2277 \n","[2023-12-09 07:29:29,059::train::INFO] [Train] Iter 0661 | Loss 0.049039 | Grad 0.1498 \n","[2023-12-09 07:29:29,144::train::INFO] [Train] Iter 0662 | Loss 0.051197 | Grad 0.1274 \n","[2023-12-09 07:29:29,228::train::INFO] [Train] Iter 0663 | Loss 0.049729 | Grad 0.1366 \n","[2023-12-09 07:29:29,314::train::INFO] [Train] Iter 0664 | Loss 0.048681 | Grad 0.1568 \n","[2023-12-09 07:29:29,402::train::INFO] [Train] Iter 0665 | Loss 0.049685 | Grad 0.1224 \n","[2023-12-09 07:29:29,486::train::INFO] [Train] Iter 0666 | Loss 0.053577 | Grad 0.2478 \n","[2023-12-09 07:29:29,570::train::INFO] [Train] Iter 0667 | Loss 0.049677 | Grad 0.1429 \n","[2023-12-09 07:29:29,654::train::INFO] [Train] Iter 0668 | Loss 0.048351 | Grad 0.1142 \n","[2023-12-09 07:29:29,739::train::INFO] [Train] Iter 0669 | Loss 0.051394 | Grad 0.1879 \n","[2023-12-09 07:29:29,823::train::INFO] [Train] Iter 0670 | Loss 0.049027 | Grad 0.1159 \n","[2023-12-09 07:29:29,907::train::INFO] [Train] Iter 0671 | Loss 0.048002 | Grad 0.1283 \n","[2023-12-09 07:29:29,992::train::INFO] [Train] Iter 0672 | Loss 0.049744 | Grad 0.1492 \n","[2023-12-09 07:29:30,078::train::INFO] [Train] Iter 0673 | Loss 0.050494 | Grad 0.1668 \n","[2023-12-09 07:29:30,163::train::INFO] [Train] Iter 0674 | Loss 0.050194 | Grad 0.1119 \n","[2023-12-09 07:29:30,246::train::INFO] [Train] Iter 0675 | Loss 0.048403 | Grad 0.2153 \n","[2023-12-09 07:29:30,334::train::INFO] [Train] Iter 0676 | Loss 0.049779 | Grad 0.1261 \n","[2023-12-09 07:29:30,417::train::INFO] [Train] Iter 0677 | Loss 0.049161 | Grad 0.0958 \n","[2023-12-09 07:29:30,500::train::INFO] [Train] Iter 0678 | Loss 0.047933 | Grad 0.1342 \n","[2023-12-09 07:29:30,583::train::INFO] [Train] Iter 0679 | Loss 0.049140 | Grad 0.1710 \n","[2023-12-09 07:29:30,617::train::INFO] [Train] Iter 0680 | Loss 0.048430 | Grad 0.2035 \n","[2023-12-09 07:29:30,700::train::INFO] [Train] Iter 0681 | Loss 0.050380 | Grad 0.1903 \n","[2023-12-09 07:29:30,784::train::INFO] [Train] Iter 0682 | Loss 0.052177 | Grad 0.2869 \n","[2023-12-09 07:29:30,867::train::INFO] [Train] Iter 0683 | Loss 0.050542 | Grad 0.1564 \n","[2023-12-09 07:29:30,950::train::INFO] [Train] Iter 0684 | Loss 0.050097 | Grad 0.1494 \n","[2023-12-09 07:29:31,035::train::INFO] [Train] Iter 0685 | Loss 0.049075 | Grad 0.1748 \n","[2023-12-09 07:29:31,118::train::INFO] [Train] Iter 0686 | Loss 0.049796 | Grad 0.1154 \n","[2023-12-09 07:29:31,204::train::INFO] [Train] Iter 0687 | Loss 0.049939 | Grad 0.1892 \n","[2023-12-09 07:29:31,287::train::INFO] [Train] Iter 0688 | Loss 0.050537 | Grad 0.1420 \n","[2023-12-09 07:29:31,371::train::INFO] [Train] Iter 0689 | Loss 0.048767 | Grad 0.1482 \n","[2023-12-09 07:29:31,456::train::INFO] [Train] Iter 0690 | Loss 0.050760 | Grad 0.2083 \n","[2023-12-09 07:29:31,541::train::INFO] [Train] Iter 0691 | Loss 0.049273 | Grad 0.3009 \n","[2023-12-09 07:29:31,624::train::INFO] [Train] Iter 0692 | Loss 0.049085 | Grad 0.1568 \n","[2023-12-09 07:29:31,707::train::INFO] [Train] Iter 0693 | Loss 0.049633 | Grad 0.3053 \n","[2023-12-09 07:29:31,790::train::INFO] [Train] Iter 0694 | Loss 0.049895 | Grad 0.2390 \n","[2023-12-09 07:29:31,873::train::INFO] [Train] Iter 0695 | Loss 0.049484 | Grad 0.1761 \n","[2023-12-09 07:29:31,956::train::INFO] [Train] Iter 0696 | Loss 0.049553 | Grad 0.2097 \n","[2023-12-09 07:29:32,040::train::INFO] [Train] Iter 0697 | Loss 0.049621 | Grad 0.2467 \n","[2023-12-09 07:29:32,125::train::INFO] [Train] Iter 0698 | Loss 0.048387 | Grad 0.0889 \n","[2023-12-09 07:29:32,207::train::INFO] [Train] Iter 0699 | Loss 0.050399 | Grad 0.2677 \n","[2023-12-09 07:29:32,290::train::INFO] [Train] Iter 0700 | Loss 0.048918 | Grad 0.2502 \n","[2023-12-09 07:29:32,373::train::INFO] [Train] Iter 0701 | Loss 0.047211 | Grad 0.2021 \n","[2023-12-09 07:29:32,457::train::INFO] [Train] Iter 0702 | Loss 0.049618 | Grad 0.1657 \n","[2023-12-09 07:29:32,541::train::INFO] [Train] Iter 0703 | Loss 0.050997 | Grad 0.2091 \n","[2023-12-09 07:29:32,625::train::INFO] [Train] Iter 0704 | Loss 0.049870 | Grad 0.1393 \n","[2023-12-09 07:29:32,707::train::INFO] [Train] Iter 0705 | Loss 0.048910 | Grad 0.1934 \n","[2023-12-09 07:29:32,790::train::INFO] [Train] Iter 0706 | Loss 0.048617 | Grad 0.1303 \n","[2023-12-09 07:29:32,873::train::INFO] [Train] Iter 0707 | Loss 0.050078 | Grad 0.1157 \n","[2023-12-09 07:29:32,956::train::INFO] [Train] Iter 0708 | Loss 0.048363 | Grad 0.1090 \n","[2023-12-09 07:29:33,040::train::INFO] [Train] Iter 0709 | Loss 0.048265 | Grad 0.0943 \n","[2023-12-09 07:29:33,123::train::INFO] [Train] Iter 0710 | Loss 0.048027 | Grad 0.1158 \n","[2023-12-09 07:29:33,206::train::INFO] [Train] Iter 0711 | Loss 0.048774 | Grad 0.0756 \n","[2023-12-09 07:29:33,290::train::INFO] [Train] Iter 0712 | Loss 0.046941 | Grad 0.0876 \n","[2023-12-09 07:29:33,373::train::INFO] [Train] Iter 0713 | Loss 0.048839 | Grad 0.1864 \n","[2023-12-09 07:29:33,456::train::INFO] [Train] Iter 0714 | Loss 0.048829 | Grad 0.1419 \n","[2023-12-09 07:29:33,543::train::INFO] [Train] Iter 0715 | Loss 0.046721 | Grad 0.1100 \n","[2023-12-09 07:29:33,626::train::INFO] [Train] Iter 0716 | Loss 0.048393 | Grad 0.1434 \n","[2023-12-09 07:29:33,709::train::INFO] [Train] Iter 0717 | Loss 0.048277 | Grad 0.1945 \n","[2023-12-09 07:29:33,797::train::INFO] [Train] Iter 0718 | Loss 0.049022 | Grad 0.1198 \n","[2023-12-09 07:29:33,879::train::INFO] [Train] Iter 0719 | Loss 0.047737 | Grad 0.0913 \n","[2023-12-09 07:29:33,963::train::INFO] [Train] Iter 0720 | Loss 0.049194 | Grad 0.2436 \n","[2023-12-09 07:29:34,046::train::INFO] [Train] Iter 0721 | Loss 0.047562 | Grad 0.2274 \n","[2023-12-09 07:29:34,130::train::INFO] [Train] Iter 0722 | Loss 0.047672 | Grad 0.0957 \n","[2023-12-09 07:29:34,212::train::INFO] [Train] Iter 0723 | Loss 0.048647 | Grad 0.1442 \n","[2023-12-09 07:29:34,297::train::INFO] [Train] Iter 0724 | Loss 0.046922 | Grad 0.0876 \n","[2023-12-09 07:29:34,380::train::INFO] [Train] Iter 0725 | Loss 0.047785 | Grad 0.1087 \n","[2023-12-09 07:29:34,463::train::INFO] [Train] Iter 0726 | Loss 0.048443 | Grad 0.1615 \n","[2023-12-09 07:29:34,552::train::INFO] [Train] Iter 0727 | Loss 0.046461 | Grad 0.1157 \n","[2023-12-09 07:29:34,637::train::INFO] [Train] Iter 0728 | Loss 0.046303 | Grad 0.1066 \n","[2023-12-09 07:29:34,720::train::INFO] [Train] Iter 0729 | Loss 0.049015 | Grad 0.1724 \n","[2023-12-09 07:29:34,805::train::INFO] [Train] Iter 0730 | Loss 0.046604 | Grad 0.1162 \n","[2023-12-09 07:29:34,888::train::INFO] [Train] Iter 0731 | Loss 0.050528 | Grad 0.1597 \n","[2023-12-09 07:29:34,971::train::INFO] [Train] Iter 0732 | Loss 0.046673 | Grad 0.1238 \n","[2023-12-09 07:29:35,054::train::INFO] [Train] Iter 0733 | Loss 0.047581 | Grad 0.3220 \n","[2023-12-09 07:29:35,137::train::INFO] [Train] Iter 0734 | Loss 0.046900 | Grad 0.1465 \n","[2023-12-09 07:29:35,220::train::INFO] [Train] Iter 0735 | Loss 0.047946 | Grad 0.1287 \n","[2023-12-09 07:29:35,303::train::INFO] [Train] Iter 0736 | Loss 0.050045 | Grad 0.2081 \n","[2023-12-09 07:29:35,387::train::INFO] [Train] Iter 0737 | Loss 0.046780 | Grad 0.1348 \n","[2023-12-09 07:29:35,471::train::INFO] [Train] Iter 0738 | Loss 0.047372 | Grad 0.1694 \n","[2023-12-09 07:29:35,563::train::INFO] [Train] Iter 0739 | Loss 0.046459 | Grad 0.1519 \n","[2023-12-09 07:29:35,647::train::INFO] [Train] Iter 0740 | Loss 0.045836 | Grad 0.0954 \n","[2023-12-09 07:29:35,732::train::INFO] [Train] Iter 0741 | Loss 0.047820 | Grad 0.1757 \n","[2023-12-09 07:29:35,816::train::INFO] [Train] Iter 0742 | Loss 0.050113 | Grad 0.1862 \n","[2023-12-09 07:29:35,903::train::INFO] [Train] Iter 0743 | Loss 0.047371 | Grad 0.1458 \n","[2023-12-09 07:29:35,986::train::INFO] [Train] Iter 0744 | Loss 0.047530 | Grad 0.1863 \n","[2023-12-09 07:29:36,071::train::INFO] [Train] Iter 0745 | Loss 0.047836 | Grad 0.1626 \n","[2023-12-09 07:29:36,156::train::INFO] [Train] Iter 0746 | Loss 0.047724 | Grad 0.2655 \n","[2023-12-09 07:29:36,239::train::INFO] [Train] Iter 0747 | Loss 0.047147 | Grad 0.0854 \n","[2023-12-09 07:29:36,322::train::INFO] [Train] Iter 0748 | Loss 0.046379 | Grad 0.1687 \n","[2023-12-09 07:29:36,405::train::INFO] [Train] Iter 0749 | Loss 0.046704 | Grad 0.1752 \n","[2023-12-09 07:29:36,489::train::INFO] [Train] Iter 0750 | Loss 0.046425 | Grad 0.1127 \n","[2023-12-09 07:29:36,571::train::INFO] [Train] Iter 0751 | Loss 0.046536 | Grad 0.1145 \n","[2023-12-09 07:29:36,653::train::INFO] [Train] Iter 0752 | Loss 0.046437 | Grad 0.1467 \n","[2023-12-09 07:29:36,738::train::INFO] [Train] Iter 0753 | Loss 0.046659 | Grad 0.0984 \n","[2023-12-09 07:29:36,822::train::INFO] [Train] Iter 0754 | Loss 0.046509 | Grad 0.1402 \n","[2023-12-09 07:29:36,906::train::INFO] [Train] Iter 0755 | Loss 0.047111 | Grad 0.1174 \n","[2023-12-09 07:29:36,990::train::INFO] [Train] Iter 0756 | Loss 0.045900 | Grad 0.1702 \n","[2023-12-09 07:29:37,073::train::INFO] [Train] Iter 0757 | Loss 0.046417 | Grad 0.0660 \n","[2023-12-09 07:29:37,159::train::INFO] [Train] Iter 0758 | Loss 0.045545 | Grad 0.1032 \n","[2023-12-09 07:29:37,242::train::INFO] [Train] Iter 0759 | Loss 0.046484 | Grad 0.1592 \n","[2023-12-09 07:29:37,325::train::INFO] [Train] Iter 0760 | Loss 0.045119 | Grad 0.0935 \n","[2023-12-09 07:29:37,416::train::INFO] [Train] Iter 0761 | Loss 0.046451 | Grad 0.0782 \n","[2023-12-09 07:29:37,506::train::INFO] [Train] Iter 0762 | Loss 0.044847 | Grad 0.0814 \n","[2023-12-09 07:29:37,599::train::INFO] [Train] Iter 0763 | Loss 0.044752 | Grad 0.0937 \n","[2023-12-09 07:29:37,690::train::INFO] [Train] Iter 0764 | Loss 0.047120 | Grad 0.0793 \n","[2023-12-09 07:29:37,780::train::INFO] [Train] Iter 0765 | Loss 0.048518 | Grad 0.1659 \n","[2023-12-09 07:29:37,870::train::INFO] [Train] Iter 0766 | Loss 0.046941 | Grad 0.1217 \n","[2023-12-09 07:29:37,967::train::INFO] [Train] Iter 0767 | Loss 0.046272 | Grad 0.0708 \n","[2023-12-09 07:29:38,059::train::INFO] [Train] Iter 0768 | Loss 0.045376 | Grad 0.0609 \n","[2023-12-09 07:29:38,152::train::INFO] [Train] Iter 0769 | Loss 0.046149 | Grad 0.1170 \n","[2023-12-09 07:29:38,249::train::INFO] [Train] Iter 0770 | Loss 0.048522 | Grad 0.2351 \n","[2023-12-09 07:29:38,342::train::INFO] [Train] Iter 0771 | Loss 0.045320 | Grad 0.1064 \n","[2023-12-09 07:29:38,433::train::INFO] [Train] Iter 0772 | Loss 0.045440 | Grad 0.1057 \n","[2023-12-09 07:29:38,525::train::INFO] [Train] Iter 0773 | Loss 0.045891 | Grad 0.0914 \n","[2023-12-09 07:29:38,615::train::INFO] [Train] Iter 0774 | Loss 0.046350 | Grad 0.1729 \n","[2023-12-09 07:29:38,705::train::INFO] [Train] Iter 0775 | Loss 0.047266 | Grad 0.1055 \n","[2023-12-09 07:29:38,795::train::INFO] [Train] Iter 0776 | Loss 0.043682 | Grad 0.1143 \n","[2023-12-09 07:29:38,893::train::INFO] [Train] Iter 0777 | Loss 0.045159 | Grad 0.0897 \n","[2023-12-09 07:29:38,992::train::INFO] [Train] Iter 0778 | Loss 0.045961 | Grad 0.2225 \n","[2023-12-09 07:29:39,085::train::INFO] [Train] Iter 0779 | Loss 0.045147 | Grad 0.1481 \n","[2023-12-09 07:29:39,180::train::INFO] [Train] Iter 0780 | Loss 0.047353 | Grad 0.1216 \n","[2023-12-09 07:29:39,269::train::INFO] [Train] Iter 0781 | Loss 0.046254 | Grad 0.0784 \n","[2023-12-09 07:29:39,362::train::INFO] [Train] Iter 0782 | Loss 0.045864 | Grad 0.1468 \n","[2023-12-09 07:29:39,461::train::INFO] [Train] Iter 0783 | Loss 0.046113 | Grad 0.1542 \n","[2023-12-09 07:29:39,552::train::INFO] [Train] Iter 0784 | Loss 0.045546 | Grad 0.1035 \n","[2023-12-09 07:29:39,642::train::INFO] [Train] Iter 0785 | Loss 0.045711 | Grad 0.1018 \n","[2023-12-09 07:29:39,734::train::INFO] [Train] Iter 0786 | Loss 0.045625 | Grad 0.1365 \n","[2023-12-09 07:29:39,825::train::INFO] [Train] Iter 0787 | Loss 0.045115 | Grad 0.1212 \n","[2023-12-09 07:29:39,917::train::INFO] [Train] Iter 0788 | Loss 0.045665 | Grad 0.1211 \n","[2023-12-09 07:29:40,007::train::INFO] [Train] Iter 0789 | Loss 0.047653 | Grad 0.1391 \n","[2023-12-09 07:29:40,103::train::INFO] [Train] Iter 0790 | Loss 0.045258 | Grad 0.1055 \n","[2023-12-09 07:29:40,196::train::INFO] [Train] Iter 0791 | Loss 0.045874 | Grad 0.0780 \n","[2023-12-09 07:29:40,287::train::INFO] [Train] Iter 0792 | Loss 0.045064 | Grad 0.1029 \n","[2023-12-09 07:29:40,379::train::INFO] [Train] Iter 0793 | Loss 0.045247 | Grad 0.1402 \n","[2023-12-09 07:29:40,478::train::INFO] [Train] Iter 0794 | Loss 0.045594 | Grad 0.1337 \n","[2023-12-09 07:29:40,570::train::INFO] [Train] Iter 0795 | Loss 0.044852 | Grad 0.1055 \n","[2023-12-09 07:29:40,661::train::INFO] [Train] Iter 0796 | Loss 0.046157 | Grad 0.0988 \n","[2023-12-09 07:29:40,757::train::INFO] [Train] Iter 0797 | Loss 0.045219 | Grad 0.1325 \n","[2023-12-09 07:29:40,848::train::INFO] [Train] Iter 0798 | Loss 0.044411 | Grad 0.0939 \n","[2023-12-09 07:29:40,939::train::INFO] [Train] Iter 0799 | Loss 0.042844 | Grad 0.0909 \n","[2023-12-09 07:29:41,029::train::INFO] [Train] Iter 0800 | Loss 0.045751 | Grad 0.1122 \n","[2023-12-09 07:29:41,121::train::INFO] [Train] Iter 0801 | Loss 0.044930 | Grad 0.0732 \n","[2023-12-09 07:29:41,213::train::INFO] [Train] Iter 0802 | Loss 0.044834 | Grad 0.1066 \n","[2023-12-09 07:29:41,303::train::INFO] [Train] Iter 0803 | Loss 0.043321 | Grad 0.0577 \n","[2023-12-09 07:29:41,399::train::INFO] [Train] Iter 0804 | Loss 0.045063 | Grad 0.1183 \n","[2023-12-09 07:29:41,490::train::INFO] [Train] Iter 0805 | Loss 0.045399 | Grad 0.0988 \n","[2023-12-09 07:29:41,580::train::INFO] [Train] Iter 0806 | Loss 0.044689 | Grad 0.1130 \n","[2023-12-09 07:29:41,677::train::INFO] [Train] Iter 0807 | Loss 0.044000 | Grad 0.0624 \n","[2023-12-09 07:29:41,779::train::INFO] [Train] Iter 0808 | Loss 0.045732 | Grad 0.0611 \n","[2023-12-09 07:29:41,873::train::INFO] [Train] Iter 0809 | Loss 0.045259 | Grad 0.1153 \n","[2023-12-09 07:29:41,964::train::INFO] [Train] Iter 0810 | Loss 0.043440 | Grad 0.1013 \n","[2023-12-09 07:29:42,056::train::INFO] [Train] Iter 0811 | Loss 0.045640 | Grad 0.0703 \n","[2023-12-09 07:29:42,147::train::INFO] [Train] Iter 0812 | Loss 0.045108 | Grad 0.1163 \n","[2023-12-09 07:29:42,238::train::INFO] [Train] Iter 0813 | Loss 0.044250 | Grad 0.0877 \n","[2023-12-09 07:29:42,330::train::INFO] [Train] Iter 0814 | Loss 0.043965 | Grad 0.1299 \n","[2023-12-09 07:29:42,419::train::INFO] [Train] Iter 0815 | Loss 0.043468 | Grad 0.1504 \n","[2023-12-09 07:29:42,510::train::INFO] [Train] Iter 0816 | Loss 0.043883 | Grad 0.0999 \n","[2023-12-09 07:29:42,601::train::INFO] [Train] Iter 0817 | Loss 0.043913 | Grad 0.1454 \n","[2023-12-09 07:29:42,694::train::INFO] [Train] Iter 0818 | Loss 0.043328 | Grad 0.1279 \n","[2023-12-09 07:29:42,784::train::INFO] [Train] Iter 0819 | Loss 0.045742 | Grad 0.1155 \n","[2023-12-09 07:29:42,886::train::INFO] [Train] Iter 0820 | Loss 0.045064 | Grad 0.1694 \n","[2023-12-09 07:29:42,977::train::INFO] [Train] Iter 0821 | Loss 0.045245 | Grad 0.1755 \n","[2023-12-09 07:29:43,069::train::INFO] [Train] Iter 0822 | Loss 0.043815 | Grad 0.1432 \n","[2023-12-09 07:29:43,160::train::INFO] [Train] Iter 0823 | Loss 0.046329 | Grad 0.1161 \n","[2023-12-09 07:29:43,252::train::INFO] [Train] Iter 0824 | Loss 0.046017 | Grad 0.2270 \n","[2023-12-09 07:29:43,344::train::INFO] [Train] Iter 0825 | Loss 0.046001 | Grad 0.1254 \n","[2023-12-09 07:29:43,436::train::INFO] [Train] Iter 0826 | Loss 0.044667 | Grad 0.1122 \n","[2023-12-09 07:29:43,527::train::INFO] [Train] Iter 0827 | Loss 0.044150 | Grad 0.0846 \n","[2023-12-09 07:29:43,620::train::INFO] [Train] Iter 0828 | Loss 0.044562 | Grad 0.1450 \n","[2023-12-09 07:29:43,704::train::INFO] [Train] Iter 0829 | Loss 0.045560 | Grad 0.1573 \n","[2023-12-09 07:29:43,791::train::INFO] [Train] Iter 0830 | Loss 0.045393 | Grad 0.1308 \n","[2023-12-09 07:29:43,877::train::INFO] [Train] Iter 0831 | Loss 0.045669 | Grad 0.1162 \n","[2023-12-09 07:29:43,960::train::INFO] [Train] Iter 0832 | Loss 0.045719 | Grad 0.1570 \n","[2023-12-09 07:29:44,043::train::INFO] [Train] Iter 0833 | Loss 0.043382 | Grad 0.0918 \n","[2023-12-09 07:29:44,127::train::INFO] [Train] Iter 0834 | Loss 0.043096 | Grad 0.1760 \n","[2023-12-09 07:29:44,213::train::INFO] [Train] Iter 0835 | Loss 0.043779 | Grad 0.1425 \n","[2023-12-09 07:29:44,295::train::INFO] [Train] Iter 0836 | Loss 0.043805 | Grad 0.0823 \n","[2023-12-09 07:29:44,378::train::INFO] [Train] Iter 0837 | Loss 0.043155 | Grad 0.1029 \n","[2023-12-09 07:29:44,461::train::INFO] [Train] Iter 0838 | Loss 0.043054 | Grad 0.1568 \n","[2023-12-09 07:29:44,546::train::INFO] [Train] Iter 0839 | Loss 0.043333 | Grad 0.1708 \n","[2023-12-09 07:29:44,634::train::INFO] [Train] Iter 0840 | Loss 0.043310 | Grad 0.1049 \n","[2023-12-09 07:29:44,719::train::INFO] [Train] Iter 0841 | Loss 0.043215 | Grad 0.0992 \n","[2023-12-09 07:29:44,801::train::INFO] [Train] Iter 0842 | Loss 0.043055 | Grad 0.0696 \n","[2023-12-09 07:29:44,885::train::INFO] [Train] Iter 0843 | Loss 0.045073 | Grad 0.0911 \n","[2023-12-09 07:29:44,969::train::INFO] [Train] Iter 0844 | Loss 0.044608 | Grad 0.1080 \n","[2023-12-09 07:29:45,052::train::INFO] [Train] Iter 0845 | Loss 0.043603 | Grad 0.1564 \n","[2023-12-09 07:29:45,135::train::INFO] [Train] Iter 0846 | Loss 0.043923 | Grad 0.1126 \n","[2023-12-09 07:29:45,218::train::INFO] [Train] Iter 0847 | Loss 0.043046 | Grad 0.0873 \n","[2023-12-09 07:29:45,301::train::INFO] [Train] Iter 0848 | Loss 0.044123 | Grad 0.1747 \n","[2023-12-09 07:29:45,385::train::INFO] [Train] Iter 0849 | Loss 0.041723 | Grad 0.0855 \n","[2023-12-09 07:29:45,468::train::INFO] [Train] Iter 0850 | Loss 0.043460 | Grad 0.1152 \n","[2023-12-09 07:29:45,552::train::INFO] [Train] Iter 0851 | Loss 0.042633 | Grad 0.1624 \n","[2023-12-09 07:29:45,636::train::INFO] [Train] Iter 0852 | Loss 0.045106 | Grad 0.1081 \n","[2023-12-09 07:29:45,721::train::INFO] [Train] Iter 0853 | Loss 0.045781 | Grad 0.1295 \n","[2023-12-09 07:29:45,804::train::INFO] [Train] Iter 0854 | Loss 0.044368 | Grad 0.1012 \n","[2023-12-09 07:29:45,887::train::INFO] [Train] Iter 0855 | Loss 0.042776 | Grad 0.0716 \n","[2023-12-09 07:29:45,970::train::INFO] [Train] Iter 0856 | Loss 0.042148 | Grad 0.1047 \n","[2023-12-09 07:29:46,053::train::INFO] [Train] Iter 0857 | Loss 0.041914 | Grad 0.0617 \n","[2023-12-09 07:29:46,138::train::INFO] [Train] Iter 0858 | Loss 0.042065 | Grad 0.1165 \n","[2023-12-09 07:29:46,224::train::INFO] [Train] Iter 0859 | Loss 0.041372 | Grad 0.0897 \n","[2023-12-09 07:29:46,307::train::INFO] [Train] Iter 0860 | Loss 0.043062 | Grad 0.1034 \n","[2023-12-09 07:29:46,391::train::INFO] [Train] Iter 0861 | Loss 0.045016 | Grad 0.1102 \n","[2023-12-09 07:29:46,475::train::INFO] [Train] Iter 0862 | Loss 0.042489 | Grad 0.2032 \n","[2023-12-09 07:29:46,558::train::INFO] [Train] Iter 0863 | Loss 0.041493 | Grad 0.1334 \n","[2023-12-09 07:29:46,641::train::INFO] [Train] Iter 0864 | Loss 0.043823 | Grad 0.0977 \n","[2023-12-09 07:29:46,724::train::INFO] [Train] Iter 0865 | Loss 0.042773 | Grad 0.1702 \n","[2023-12-09 07:29:46,809::train::INFO] [Train] Iter 0866 | Loss 0.044246 | Grad 0.1327 \n","[2023-12-09 07:29:46,891::train::INFO] [Train] Iter 0867 | Loss 0.041152 | Grad 0.0564 \n","[2023-12-09 07:29:46,977::train::INFO] [Train] Iter 0868 | Loss 0.043235 | Grad 0.0927 \n","[2023-12-09 07:29:47,061::train::INFO] [Train] Iter 0869 | Loss 0.043064 | Grad 0.1621 \n","[2023-12-09 07:29:47,144::train::INFO] [Train] Iter 0870 | Loss 0.043576 | Grad 0.0870 \n","[2023-12-09 07:29:47,228::train::INFO] [Train] Iter 0871 | Loss 0.044745 | Grad 0.1170 \n","[2023-12-09 07:29:47,311::train::INFO] [Train] Iter 0872 | Loss 0.043449 | Grad 0.1727 \n","[2023-12-09 07:29:47,398::train::INFO] [Train] Iter 0873 | Loss 0.042758 | Grad 0.1302 \n","[2023-12-09 07:29:47,481::train::INFO] [Train] Iter 0874 | Loss 0.042268 | Grad 0.0721 \n","[2023-12-09 07:29:47,567::train::INFO] [Train] Iter 0875 | Loss 0.044028 | Grad 0.1040 \n","[2023-12-09 07:29:47,651::train::INFO] [Train] Iter 0876 | Loss 0.043840 | Grad 0.0870 \n","[2023-12-09 07:29:47,734::train::INFO] [Train] Iter 0877 | Loss 0.042052 | Grad 0.1140 \n","[2023-12-09 07:29:47,816::train::INFO] [Train] Iter 0878 | Loss 0.041210 | Grad 0.0751 \n","[2023-12-09 07:29:47,900::train::INFO] [Train] Iter 0879 | Loss 0.043188 | Grad 0.0730 \n","[2023-12-09 07:29:47,988::train::INFO] [Train] Iter 0880 | Loss 0.041901 | Grad 0.1003 \n","[2023-12-09 07:29:48,073::train::INFO] [Train] Iter 0881 | Loss 0.042065 | Grad 0.1082 \n","[2023-12-09 07:29:48,159::train::INFO] [Train] Iter 0882 | Loss 0.042816 | Grad 0.0989 \n","[2023-12-09 07:29:48,244::train::INFO] [Train] Iter 0883 | Loss 0.043017 | Grad 0.0778 \n","[2023-12-09 07:29:48,328::train::INFO] [Train] Iter 0884 | Loss 0.042540 | Grad 0.1783 \n","[2023-12-09 07:29:48,412::train::INFO] [Train] Iter 0885 | Loss 0.043458 | Grad 0.1118 \n","[2023-12-09 07:29:48,495::train::INFO] [Train] Iter 0886 | Loss 0.042248 | Grad 0.1081 \n","[2023-12-09 07:29:48,581::train::INFO] [Train] Iter 0887 | Loss 0.042415 | Grad 0.1223 \n","[2023-12-09 07:29:48,668::train::INFO] [Train] Iter 0888 | Loss 0.042727 | Grad 0.1158 \n","[2023-12-09 07:29:48,751::train::INFO] [Train] Iter 0889 | Loss 0.040915 | Grad 0.0704 \n","[2023-12-09 07:29:48,834::train::INFO] [Train] Iter 0890 | Loss 0.045890 | Grad 0.1551 \n","[2023-12-09 07:29:48,918::train::INFO] [Train] Iter 0891 | Loss 0.044140 | Grad 0.1231 \n","[2023-12-09 07:29:49,007::train::INFO] [Train] Iter 0892 | Loss 0.042074 | Grad 0.1155 \n","[2023-12-09 07:29:49,092::train::INFO] [Train] Iter 0893 | Loss 0.042281 | Grad 0.1025 \n","[2023-12-09 07:29:49,175::train::INFO] [Train] Iter 0894 | Loss 0.044000 | Grad 0.1677 \n","[2023-12-09 07:29:49,259::train::INFO] [Train] Iter 0895 | Loss 0.042048 | Grad 0.1048 \n","[2023-12-09 07:29:49,342::train::INFO] [Train] Iter 0896 | Loss 0.042807 | Grad 0.0959 \n","[2023-12-09 07:29:49,425::train::INFO] [Train] Iter 0897 | Loss 0.042859 | Grad 0.0791 \n","[2023-12-09 07:29:49,513::train::INFO] [Train] Iter 0898 | Loss 0.043929 | Grad 0.1181 \n","[2023-12-09 07:29:49,597::train::INFO] [Train] Iter 0899 | Loss 0.041833 | Grad 0.0680 \n","[2023-12-09 07:29:49,679::train::INFO] [Train] Iter 0900 | Loss 0.043431 | Grad 0.0669 \n","[2023-12-09 07:29:49,762::train::INFO] [Train] Iter 0901 | Loss 0.041706 | Grad 0.1736 \n","[2023-12-09 07:29:49,846::train::INFO] [Train] Iter 0902 | Loss 0.041434 | Grad 0.1026 \n","[2023-12-09 07:29:49,929::train::INFO] [Train] Iter 0903 | Loss 0.041765 | Grad 0.0590 \n","[2023-12-09 07:29:50,018::train::INFO] [Train] Iter 0904 | Loss 0.042376 | Grad 0.1924 \n","[2023-12-09 07:29:50,102::train::INFO] [Train] Iter 0905 | Loss 0.041709 | Grad 0.0804 \n","[2023-12-09 07:29:50,187::train::INFO] [Train] Iter 0906 | Loss 0.043330 | Grad 0.1534 \n","[2023-12-09 07:29:50,270::train::INFO] [Train] Iter 0907 | Loss 0.042192 | Grad 0.0702 \n","[2023-12-09 07:29:50,354::train::INFO] [Train] Iter 0908 | Loss 0.040027 | Grad 0.0849 \n","[2023-12-09 07:29:50,438::train::INFO] [Train] Iter 0909 | Loss 0.043132 | Grad 0.1243 \n","[2023-12-09 07:29:50,521::train::INFO] [Train] Iter 0910 | Loss 0.040502 | Grad 0.0819 \n","[2023-12-09 07:29:50,606::train::INFO] [Train] Iter 0911 | Loss 0.042742 | Grad 0.0680 \n","[2023-12-09 07:29:50,689::train::INFO] [Train] Iter 0912 | Loss 0.042175 | Grad 0.0782 \n","[2023-12-09 07:29:50,773::train::INFO] [Train] Iter 0913 | Loss 0.043342 | Grad 0.1615 \n","[2023-12-09 07:29:50,856::train::INFO] [Train] Iter 0914 | Loss 0.041403 | Grad 0.0664 \n","[2023-12-09 07:29:50,939::train::INFO] [Train] Iter 0915 | Loss 0.041740 | Grad 0.1000 \n","[2023-12-09 07:29:51,024::train::INFO] [Train] Iter 0916 | Loss 0.042357 | Grad 0.1036 \n","[2023-12-09 07:29:51,109::train::INFO] [Train] Iter 0917 | Loss 0.042105 | Grad 0.1743 \n","[2023-12-09 07:29:51,193::train::INFO] [Train] Iter 0918 | Loss 0.041057 | Grad 0.0568 \n","[2023-12-09 07:29:51,276::train::INFO] [Train] Iter 0919 | Loss 0.041376 | Grad 0.0584 \n","[2023-12-09 07:29:51,361::train::INFO] [Train] Iter 0920 | Loss 0.040982 | Grad 0.0727 \n","[2023-12-09 07:29:51,445::train::INFO] [Train] Iter 0921 | Loss 0.043137 | Grad 0.1571 \n","[2023-12-09 07:29:51,530::train::INFO] [Train] Iter 0922 | Loss 0.040200 | Grad 0.1602 \n","[2023-12-09 07:29:51,614::train::INFO] [Train] Iter 0923 | Loss 0.042082 | Grad 0.1105 \n","[2023-12-09 07:29:51,696::train::INFO] [Train] Iter 0924 | Loss 0.043226 | Grad 0.0907 \n","[2023-12-09 07:29:51,779::train::INFO] [Train] Iter 0925 | Loss 0.042225 | Grad 0.0984 \n","[2023-12-09 07:29:51,863::train::INFO] [Train] Iter 0926 | Loss 0.041117 | Grad 0.0774 \n","[2023-12-09 07:29:51,947::train::INFO] [Train] Iter 0927 | Loss 0.040177 | Grad 0.1215 \n","[2023-12-09 07:29:52,033::train::INFO] [Train] Iter 0928 | Loss 0.042214 | Grad 0.1631 \n","[2023-12-09 07:29:52,116::train::INFO] [Train] Iter 0929 | Loss 0.040364 | Grad 0.1503 \n","[2023-12-09 07:29:52,199::train::INFO] [Train] Iter 0930 | Loss 0.041029 | Grad 0.1205 \n","[2023-12-09 07:29:52,283::train::INFO] [Train] Iter 0931 | Loss 0.041263 | Grad 0.1477 \n","[2023-12-09 07:29:52,368::train::INFO] [Train] Iter 0932 | Loss 0.041383 | Grad 0.1883 \n","[2023-12-09 07:29:52,453::train::INFO] [Train] Iter 0933 | Loss 0.042145 | Grad 0.0893 \n","[2023-12-09 07:29:52,538::train::INFO] [Train] Iter 0934 | Loss 0.041409 | Grad 0.1093 \n","[2023-12-09 07:29:52,622::train::INFO] [Train] Iter 0935 | Loss 0.040745 | Grad 0.0593 \n","[2023-12-09 07:29:52,707::train::INFO] [Train] Iter 0936 | Loss 0.041202 | Grad 0.1273 \n","[2023-12-09 07:29:52,790::train::INFO] [Train] Iter 0937 | Loss 0.042286 | Grad 0.1055 \n","[2023-12-09 07:29:52,873::train::INFO] [Train] Iter 0938 | Loss 0.041535 | Grad 0.1123 \n","[2023-12-09 07:29:52,957::train::INFO] [Train] Iter 0939 | Loss 0.042054 | Grad 0.0854 \n","[2023-12-09 07:29:53,042::train::INFO] [Train] Iter 0940 | Loss 0.043719 | Grad 0.1097 \n","[2023-12-09 07:29:53,126::train::INFO] [Train] Iter 0941 | Loss 0.042016 | Grad 0.1809 \n","[2023-12-09 07:29:53,209::train::INFO] [Train] Iter 0942 | Loss 0.042518 | Grad 0.1349 \n","[2023-12-09 07:29:53,293::train::INFO] [Train] Iter 0943 | Loss 0.040317 | Grad 0.0896 \n","[2023-12-09 07:29:53,376::train::INFO] [Train] Iter 0944 | Loss 0.040895 | Grad 0.0764 \n","[2023-12-09 07:29:53,459::train::INFO] [Train] Iter 0945 | Loss 0.041507 | Grad 0.1642 \n","[2023-12-09 07:29:53,547::train::INFO] [Train] Iter 0946 | Loss 0.042114 | Grad 0.0986 \n","[2023-12-09 07:29:53,639::train::INFO] [Train] Iter 0947 | Loss 0.041814 | Grad 0.0731 \n","[2023-12-09 07:29:53,731::train::INFO] [Train] Iter 0948 | Loss 0.041576 | Grad 0.0730 \n","[2023-12-09 07:29:53,823::train::INFO] [Train] Iter 0949 | Loss 0.040848 | Grad 0.1109 \n","[2023-12-09 07:29:53,914::train::INFO] [Train] Iter 0950 | Loss 0.042975 | Grad 0.0881 \n","[2023-12-09 07:29:54,006::train::INFO] [Train] Iter 0951 | Loss 0.042609 | Grad 0.1638 \n","[2023-12-09 07:29:54,102::train::INFO] [Train] Iter 0952 | Loss 0.040074 | Grad 0.0630 \n","[2023-12-09 07:29:54,194::train::INFO] [Train] Iter 0953 | Loss 0.040115 | Grad 0.1319 \n","[2023-12-09 07:29:54,285::train::INFO] [Train] Iter 0954 | Loss 0.040762 | Grad 0.1232 \n","[2023-12-09 07:29:54,377::train::INFO] [Train] Iter 0955 | Loss 0.039992 | Grad 0.0764 \n","[2023-12-09 07:29:54,473::train::INFO] [Train] Iter 0956 | Loss 0.040263 | Grad 0.0769 \n","[2023-12-09 07:29:54,566::train::INFO] [Train] Iter 0957 | Loss 0.040655 | Grad 0.0905 \n","[2023-12-09 07:29:54,657::train::INFO] [Train] Iter 0958 | Loss 0.041718 | Grad 0.0909 \n","[2023-12-09 07:29:54,751::train::INFO] [Train] Iter 0959 | Loss 0.041204 | Grad 0.0693 \n","[2023-12-09 07:29:54,840::train::INFO] [Train] Iter 0960 | Loss 0.040025 | Grad 0.1008 \n","[2023-12-09 07:29:54,935::train::INFO] [Train] Iter 0961 | Loss 0.040754 | Grad 0.1260 \n","[2023-12-09 07:29:55,026::train::INFO] [Train] Iter 0962 | Loss 0.040277 | Grad 0.0458 \n","[2023-12-09 07:29:55,117::train::INFO] [Train] Iter 0963 | Loss 0.039895 | Grad 0.0737 \n","[2023-12-09 07:29:55,209::train::INFO] [Train] Iter 0964 | Loss 0.042139 | Grad 0.0859 \n","[2023-12-09 07:29:55,301::train::INFO] [Train] Iter 0965 | Loss 0.041227 | Grad 0.0673 \n","[2023-12-09 07:29:55,394::train::INFO] [Train] Iter 0966 | Loss 0.039516 | Grad 0.0809 \n","[2023-12-09 07:29:55,485::train::INFO] [Train] Iter 0967 | Loss 0.039276 | Grad 0.0796 \n","[2023-12-09 07:29:55,576::train::INFO] [Train] Iter 0968 | Loss 0.041663 | Grad 0.0802 \n","[2023-12-09 07:29:55,667::train::INFO] [Train] Iter 0969 | Loss 0.040886 | Grad 0.0950 \n","[2023-12-09 07:29:55,758::train::INFO] [Train] Iter 0970 | Loss 0.040865 | Grad 0.1404 \n","[2023-12-09 07:29:55,849::train::INFO] [Train] Iter 0971 | Loss 0.039978 | Grad 0.0684 \n","[2023-12-09 07:29:55,941::train::INFO] [Train] Iter 0972 | Loss 0.040742 | Grad 0.1236 \n","[2023-12-09 07:29:56,031::train::INFO] [Train] Iter 0973 | Loss 0.040434 | Grad 0.0888 \n","[2023-12-09 07:29:56,124::train::INFO] [Train] Iter 0974 | Loss 0.041271 | Grad 0.1659 \n","[2023-12-09 07:29:56,218::train::INFO] [Train] Iter 0975 | Loss 0.040512 | Grad 0.0893 \n","[2023-12-09 07:29:56,312::train::INFO] [Train] Iter 0976 | Loss 0.043454 | Grad 0.1061 \n","[2023-12-09 07:29:56,403::train::INFO] [Train] Iter 0977 | Loss 0.040738 | Grad 0.1084 \n","[2023-12-09 07:29:56,494::train::INFO] [Train] Iter 0978 | Loss 0.039161 | Grad 0.1418 \n","[2023-12-09 07:29:56,594::train::INFO] [Train] Iter 0979 | Loss 0.042610 | Grad 0.1153 \n","[2023-12-09 07:29:56,685::train::INFO] [Train] Iter 0980 | Loss 0.040969 | Grad 0.0836 \n","[2023-12-09 07:29:56,776::train::INFO] [Train] Iter 0981 | Loss 0.039277 | Grad 0.0813 \n","[2023-12-09 07:29:56,875::train::INFO] [Train] Iter 0982 | Loss 0.040890 | Grad 0.1192 \n","[2023-12-09 07:29:56,967::train::INFO] [Train] Iter 0983 | Loss 0.040124 | Grad 0.1850 \n","[2023-12-09 07:29:57,059::train::INFO] [Train] Iter 0984 | Loss 0.040588 | Grad 0.0895 \n","[2023-12-09 07:29:57,164::train::INFO] [Train] Iter 0985 | Loss 0.040967 | Grad 0.1112 \n","[2023-12-09 07:29:57,260::train::INFO] [Train] Iter 0986 | Loss 0.040988 | Grad 0.1101 \n","[2023-12-09 07:29:57,352::train::INFO] [Train] Iter 0987 | Loss 0.040554 | Grad 0.1639 \n","[2023-12-09 07:29:57,443::train::INFO] [Train] Iter 0988 | Loss 0.038791 | Grad 0.0991 \n","[2023-12-09 07:29:57,533::train::INFO] [Train] Iter 0989 | Loss 0.040959 | Grad 0.1116 \n","[2023-12-09 07:29:57,623::train::INFO] [Train] Iter 0990 | Loss 0.041470 | Grad 0.1095 \n","[2023-12-09 07:29:57,712::train::INFO] [Train] Iter 0991 | Loss 0.040161 | Grad 0.0783 \n","[2023-12-09 07:29:57,801::train::INFO] [Train] Iter 0992 | Loss 0.041207 | Grad 0.1616 \n","[2023-12-09 07:29:57,892::train::INFO] [Train] Iter 0993 | Loss 0.042490 | Grad 0.1387 \n","[2023-12-09 07:29:57,982::train::INFO] [Train] Iter 0994 | Loss 0.040963 | Grad 0.0783 \n","[2023-12-09 07:29:58,078::train::INFO] [Train] Iter 0995 | Loss 0.039988 | Grad 0.1106 \n","[2023-12-09 07:29:58,169::train::INFO] [Train] Iter 0996 | Loss 0.040096 | Grad 0.0780 \n","[2023-12-09 07:29:58,259::train::INFO] [Train] Iter 0997 | Loss 0.042452 | Grad 0.1777 \n","[2023-12-09 07:29:58,360::train::INFO] [Train] Iter 0998 | Loss 0.041315 | Grad 0.1649 \n","[2023-12-09 07:29:58,452::train::INFO] [Train] Iter 0999 | Loss 0.039257 | Grad 0.1192 \n","[2023-12-09 07:29:58,543::train::INFO] [Train] Iter 1000 | Loss 0.041596 | Grad 0.1361 \n","Validate: 100% 241/241 [00:04<00:00, 58.61it/s]\n","val loss list [tensor(0.0424, device='cuda:0'), tensor(0.0396, device='cuda:0'), tensor(0.0410, device='cuda:0'), tensor(0.0390, device='cuda:0'), tensor(0.0379, device='cuda:0'), tensor(0.0366, device='cuda:0'), tensor(0.0405, device='cuda:0'), tensor(0.0420, device='cuda:0'), tensor(0.0415, device='cuda:0'), tensor(0.0384, device='cuda:0'), tensor(0.0403, device='cuda:0'), tensor(0.0386, device='cuda:0'), tensor(0.0395, device='cuda:0'), tensor(0.0389, device='cuda:0'), tensor(0.0411, device='cuda:0'), tensor(0.0420, device='cuda:0'), tensor(0.0389, device='cuda:0'), tensor(0.0416, device='cuda:0'), tensor(0.0411, device='cuda:0'), tensor(0.0420, device='cuda:0'), tensor(0.0410, device='cuda:0'), tensor(0.0397, device='cuda:0'), tensor(0.0413, device='cuda:0'), tensor(0.0394, device='cuda:0'), tensor(0.0382, device='cuda:0'), tensor(0.0379, device='cuda:0'), tensor(0.0411, device='cuda:0'), tensor(0.0402, device='cuda:0'), tensor(0.0387, device='cuda:0'), tensor(0.0423, device='cuda:0'), tensor(0.0398, device='cuda:0'), tensor(0.0385, device='cuda:0'), tensor(0.0425, device='cuda:0'), tensor(0.0393, device='cuda:0'), tensor(0.0408, device='cuda:0'), tensor(0.0406, device='cuda:0'), tensor(0.0396, device='cuda:0'), tensor(0.0405, device='cuda:0'), tensor(0.0379, device='cuda:0'), tensor(0.0387, device='cuda:0'), tensor(0.0402, device='cuda:0'), tensor(0.0389, device='cuda:0'), tensor(0.0400, device='cuda:0'), tensor(0.0438, device='cuda:0'), tensor(0.0429, device='cuda:0'), tensor(0.0400, device='cuda:0'), tensor(0.0363, device='cuda:0'), tensor(0.0432, device='cuda:0'), tensor(0.0398, device='cuda:0'), tensor(0.0417, device='cuda:0'), tensor(0.0403, device='cuda:0'), tensor(0.0414, device='cuda:0'), tensor(0.0397, device='cuda:0'), tensor(0.0388, device='cuda:0'), tensor(0.0424, device='cuda:0'), tensor(0.0417, device='cuda:0'), tensor(0.0407, device='cuda:0'), tensor(0.0409, device='cuda:0'), tensor(0.0419, device='cuda:0'), tensor(0.0428, device='cuda:0'), tensor(0.0403, device='cuda:0'), tensor(0.0432, device='cuda:0'), tensor(0.0427, device='cuda:0'), tensor(0.0405, device='cuda:0'), tensor(0.0403, device='cuda:0'), tensor(0.0381, device='cuda:0'), tensor(0.0395, device='cuda:0'), tensor(0.0389, device='cuda:0'), tensor(0.0407, device='cuda:0'), tensor(0.0402, device='cuda:0'), tensor(0.0422, device='cuda:0'), tensor(0.0399, device='cuda:0'), tensor(0.0395, device='cuda:0'), tensor(0.0403, device='cuda:0'), tensor(0.0411, device='cuda:0'), tensor(0.0413, device='cuda:0'), tensor(0.0408, device='cuda:0'), tensor(0.0419, device='cuda:0'), tensor(0.0428, device='cuda:0'), tensor(0.0400, device='cuda:0'), tensor(0.0414, device='cuda:0'), tensor(0.0402, device='cuda:0'), tensor(0.0399, device='cuda:0'), tensor(0.0405, device='cuda:0'), tensor(0.0405, device='cuda:0'), tensor(0.0444, device='cuda:0'), tensor(0.0396, device='cuda:0'), tensor(0.0405, device='cuda:0'), tensor(0.0404, device='cuda:0'), tensor(0.0420, device='cuda:0'), tensor(0.0395, device='cuda:0'), tensor(0.0421, device='cuda:0'), tensor(0.0388, device='cuda:0'), tensor(0.0405, device='cuda:0'), tensor(0.0420, device='cuda:0'), tensor(0.0382, device='cuda:0'), tensor(0.0411, device='cuda:0'), tensor(0.0374, device='cuda:0'), tensor(0.0419, device='cuda:0'), tensor(0.0384, device='cuda:0'), tensor(0.0407, device='cuda:0'), tensor(0.0400, device='cuda:0'), tensor(0.0393, device='cuda:0'), tensor(0.0412, device='cuda:0'), tensor(0.0379, device='cuda:0'), tensor(0.0379, device='cuda:0'), tensor(0.0387, device='cuda:0'), tensor(0.0393, device='cuda:0'), tensor(0.0412, device='cuda:0'), tensor(0.0383, device='cuda:0'), tensor(0.0382, device='cuda:0'), tensor(0.0401, device='cuda:0'), tensor(0.0378, device='cuda:0'), tensor(0.0407, device='cuda:0'), tensor(0.0408, device='cuda:0'), tensor(0.0388, device='cuda:0'), tensor(0.0412, device='cuda:0'), tensor(0.0396, device='cuda:0'), tensor(0.0393, device='cuda:0'), tensor(0.0429, device='cuda:0'), tensor(0.0385, device='cuda:0'), tensor(0.0400, device='cuda:0'), tensor(0.0409, device='cuda:0'), tensor(0.0384, device='cuda:0'), tensor(0.0400, device='cuda:0'), tensor(0.0403, device='cuda:0'), tensor(0.0393, device='cuda:0'), tensor(0.0400, device='cuda:0'), tensor(0.0389, device='cuda:0'), tensor(0.0365, device='cuda:0'), tensor(0.0386, device='cuda:0'), tensor(0.0422, device='cuda:0'), tensor(0.0360, device='cuda:0'), tensor(0.0434, device='cuda:0'), tensor(0.0385, device='cuda:0'), tensor(0.0409, device='cuda:0'), tensor(0.0416, device='cuda:0'), tensor(0.0403, device='cuda:0'), tensor(0.0378, device='cuda:0'), tensor(0.0406, device='cuda:0'), tensor(0.0382, device='cuda:0'), tensor(0.0411, device='cuda:0'), tensor(0.0390, device='cuda:0'), tensor(0.0412, device='cuda:0'), tensor(0.0398, device='cuda:0'), tensor(0.0408, device='cuda:0'), tensor(0.0393, device='cuda:0'), tensor(0.0384, device='cuda:0'), tensor(0.0392, device='cuda:0'), tensor(0.0412, device='cuda:0'), tensor(0.0413, device='cuda:0'), tensor(0.0408, device='cuda:0'), tensor(0.0446, device='cuda:0'), tensor(0.0394, device='cuda:0'), tensor(0.0378, device='cuda:0'), tensor(0.0388, device='cuda:0'), tensor(0.0384, device='cuda:0'), tensor(0.0427, device='cuda:0'), tensor(0.0426, device='cuda:0'), tensor(0.0429, device='cuda:0'), tensor(0.0422, device='cuda:0'), tensor(0.0403, device='cuda:0'), tensor(0.0406, device='cuda:0'), tensor(0.0383, device='cuda:0'), tensor(0.0410, device='cuda:0'), tensor(0.0401, device='cuda:0'), tensor(0.0431, device='cuda:0'), tensor(0.0397, device='cuda:0'), tensor(0.0389, device='cuda:0'), tensor(0.0424, device='cuda:0'), tensor(0.0396, device='cuda:0'), tensor(0.0409, device='cuda:0'), tensor(0.0401, device='cuda:0'), tensor(0.0404, device='cuda:0'), tensor(0.0428, device='cuda:0'), tensor(0.0414, device='cuda:0'), tensor(0.0387, device='cuda:0'), tensor(0.0394, device='cuda:0'), tensor(0.0422, device='cuda:0'), tensor(0.0384, device='cuda:0'), tensor(0.0376, device='cuda:0'), tensor(0.0422, device='cuda:0'), tensor(0.0400, device='cuda:0'), tensor(0.0441, device='cuda:0'), tensor(0.0398, device='cuda:0'), tensor(0.0377, device='cuda:0'), tensor(0.0422, device='cuda:0'), tensor(0.0392, device='cuda:0'), tensor(0.0428, device='cuda:0'), tensor(0.0400, device='cuda:0'), tensor(0.0401, device='cuda:0'), tensor(0.0409, device='cuda:0'), tensor(0.0389, device='cuda:0'), tensor(0.0387, device='cuda:0'), tensor(0.0410, device='cuda:0'), tensor(0.0393, device='cuda:0'), tensor(0.0397, device='cuda:0'), tensor(0.0441, device='cuda:0'), tensor(0.0398, device='cuda:0'), tensor(0.0383, device='cuda:0'), tensor(0.0405, device='cuda:0'), tensor(0.0440, device='cuda:0'), tensor(0.0418, device='cuda:0'), tensor(0.0375, device='cuda:0'), tensor(0.0386, device='cuda:0'), tensor(0.0435, device='cuda:0'), tensor(0.0374, device='cuda:0'), tensor(0.0402, device='cuda:0'), tensor(0.0412, device='cuda:0'), tensor(0.0412, device='cuda:0'), tensor(0.0400, device='cuda:0'), tensor(0.0390, device='cuda:0'), tensor(0.0397, device='cuda:0'), tensor(0.0394, device='cuda:0'), tensor(0.0407, device='cuda:0'), tensor(0.0381, device='cuda:0'), tensor(0.0393, device='cuda:0'), tensor(0.0422, device='cuda:0'), tensor(0.0417, device='cuda:0'), tensor(0.0394, device='cuda:0'), tensor(0.0397, device='cuda:0'), tensor(0.0425, device='cuda:0'), tensor(0.0403, device='cuda:0'), tensor(0.0419, device='cuda:0'), tensor(0.0421, device='cuda:0'), tensor(0.0398, device='cuda:0'), tensor(0.0427, device='cuda:0'), tensor(0.0391, device='cuda:0'), tensor(0.0398, device='cuda:0'), tensor(0.0353, device='cuda:0'), tensor(0.0381, device='cuda:0'), tensor(0.0405, device='cuda:0'), tensor(0.0413, device='cuda:0'), tensor(0.0426, device='cuda:0'), tensor(0.0413, device='cuda:0'), tensor(0.0356, device='cuda:0'), tensor(0.0383, device='cuda:0'), tensor(0.0383, device='cuda:0'), tensor(0.0410, device='cuda:0'), tensor(0.0398, device='cuda:0'), tensor(0.0415, device='cuda:0')]\n","[2023-12-09 07:30:02,935::train::INFO] [Train] Iter 1001 | Loss 0.038775 | Grad 0.0829 \n","[2023-12-09 07:30:03,020::train::INFO] [Train] Iter 1002 | Loss 0.041721 | Grad 0.1285 \n","[2023-12-09 07:30:03,109::train::INFO] [Train] Iter 1003 | Loss 0.040200 | Grad 0.1145 \n","[2023-12-09 07:30:03,192::train::INFO] [Train] Iter 1004 | Loss 0.038630 | Grad 0.0777 \n","[2023-12-09 07:30:03,276::train::INFO] [Train] Iter 1005 | Loss 0.039833 | Grad 0.0994 \n","[2023-12-09 07:30:03,362::train::INFO] [Train] Iter 1006 | Loss 0.043532 | Grad 0.2619 \n","[2023-12-09 07:30:03,446::train::INFO] [Train] Iter 1007 | Loss 0.039678 | Grad 0.0807 \n","[2023-12-09 07:30:03,530::train::INFO] [Train] Iter 1008 | Loss 0.039546 | Grad 0.0935 \n","[2023-12-09 07:30:03,615::train::INFO] [Train] Iter 1009 | Loss 0.041574 | Grad 0.0928 \n","[2023-12-09 07:30:03,702::train::INFO] [Train] Iter 1010 | Loss 0.040115 | Grad 0.1190 \n","[2023-12-09 07:30:03,786::train::INFO] [Train] Iter 1011 | Loss 0.038382 | Grad 0.0904 \n","[2023-12-09 07:30:03,870::train::INFO] [Train] Iter 1012 | Loss 0.040012 | Grad 0.0909 \n","[2023-12-09 07:30:03,954::train::INFO] [Train] Iter 1013 | Loss 0.041105 | Grad 0.1428 \n","[2023-12-09 07:30:04,038::train::INFO] [Train] Iter 1014 | Loss 0.041046 | Grad 0.0966 \n","[2023-12-09 07:30:04,123::train::INFO] [Train] Iter 1015 | Loss 0.038719 | Grad 0.1470 \n","[2023-12-09 07:30:04,207::train::INFO] [Train] Iter 1016 | Loss 0.040922 | Grad 0.1021 \n","[2023-12-09 07:30:04,291::train::INFO] [Train] Iter 1017 | Loss 0.040840 | Grad 0.0705 \n","[2023-12-09 07:30:04,374::train::INFO] [Train] Iter 1018 | Loss 0.038247 | Grad 0.0929 \n","[2023-12-09 07:30:04,459::train::INFO] [Train] Iter 1019 | Loss 0.039361 | Grad 0.1118 \n","[2023-12-09 07:30:04,495::train::INFO] [Train] Iter 1020 | Loss 0.038835 | Grad 0.1549 \n","[2023-12-09 07:30:04,580::train::INFO] [Train] Iter 1021 | Loss 0.039787 | Grad 0.1053 \n","[2023-12-09 07:30:04,664::train::INFO] [Train] Iter 1022 | Loss 0.041492 | Grad 0.1028 \n","[2023-12-09 07:30:04,748::train::INFO] [Train] Iter 1023 | Loss 0.040717 | Grad 0.1084 \n","[2023-12-09 07:30:04,832::train::INFO] [Train] Iter 1024 | Loss 0.040979 | Grad 0.0999 \n","[2023-12-09 07:30:04,916::train::INFO] [Train] Iter 1025 | Loss 0.039778 | Grad 0.1080 \n","[2023-12-09 07:30:05,000::train::INFO] [Train] Iter 1026 | Loss 0.040817 | Grad 0.0824 \n","[2023-12-09 07:30:05,085::train::INFO] [Train] Iter 1027 | Loss 0.040643 | Grad 0.1915 \n","[2023-12-09 07:30:05,169::train::INFO] [Train] Iter 1028 | Loss 0.041504 | Grad 0.0941 \n","[2023-12-09 07:30:05,252::train::INFO] [Train] Iter 1029 | Loss 0.040074 | Grad 0.0549 \n","[2023-12-09 07:30:05,337::train::INFO] [Train] Iter 1030 | Loss 0.041198 | Grad 0.1297 \n","[2023-12-09 07:30:05,421::train::INFO] [Train] Iter 1031 | Loss 0.039744 | Grad 0.1382 \n","[2023-12-09 07:30:05,504::train::INFO] [Train] Iter 1032 | Loss 0.040718 | Grad 0.0973 \n","[2023-12-09 07:30:05,593::train::INFO] [Train] Iter 1033 | Loss 0.040109 | Grad 0.1506 \n","[2023-12-09 07:30:05,676::train::INFO] [Train] Iter 1034 | Loss 0.039984 | Grad 0.1670 \n","[2023-12-09 07:30:05,761::train::INFO] [Train] Iter 1035 | Loss 0.040191 | Grad 0.0498 \n","[2023-12-09 07:30:05,844::train::INFO] [Train] Iter 1036 | Loss 0.040239 | Grad 0.1106 \n","[2023-12-09 07:30:05,929::train::INFO] [Train] Iter 1037 | Loss 0.040258 | Grad 0.1266 \n","[2023-12-09 07:30:06,012::train::INFO] [Train] Iter 1038 | Loss 0.039024 | Grad 0.0587 \n","[2023-12-09 07:30:06,095::train::INFO] [Train] Iter 1039 | Loss 0.041490 | Grad 0.0901 \n","[2023-12-09 07:30:06,179::train::INFO] [Train] Iter 1040 | Loss 0.039390 | Grad 0.1493 \n","[2023-12-09 07:30:06,263::train::INFO] [Train] Iter 1041 | Loss 0.038222 | Grad 0.1382 \n","[2023-12-09 07:30:06,348::train::INFO] [Train] Iter 1042 | Loss 0.040731 | Grad 0.1245 \n","[2023-12-09 07:30:06,432::train::INFO] [Train] Iter 1043 | Loss 0.040800 | Grad 0.1896 \n","[2023-12-09 07:30:06,516::train::INFO] [Train] Iter 1044 | Loss 0.040659 | Grad 0.1131 \n","[2023-12-09 07:30:06,606::train::INFO] [Train] Iter 1045 | Loss 0.039515 | Grad 0.1127 \n","[2023-12-09 07:30:06,689::train::INFO] [Train] Iter 1046 | Loss 0.040010 | Grad 0.1170 \n","[2023-12-09 07:30:06,772::train::INFO] [Train] Iter 1047 | Loss 0.041221 | Grad 0.0667 \n","[2023-12-09 07:30:06,856::train::INFO] [Train] Iter 1048 | Loss 0.040025 | Grad 0.0913 \n","[2023-12-09 07:30:06,939::train::INFO] [Train] Iter 1049 | Loss 0.039484 | Grad 0.0914 \n","[2023-12-09 07:30:07,024::train::INFO] [Train] Iter 1050 | Loss 0.039870 | Grad 0.1399 \n","[2023-12-09 07:30:07,108::train::INFO] [Train] Iter 1051 | Loss 0.040742 | Grad 0.0617 \n","[2023-12-09 07:30:07,192::train::INFO] [Train] Iter 1052 | Loss 0.038425 | Grad 0.0956 \n","[2023-12-09 07:30:07,275::train::INFO] [Train] Iter 1053 | Loss 0.040502 | Grad 0.1272 \n","[2023-12-09 07:30:07,360::train::INFO] [Train] Iter 1054 | Loss 0.039961 | Grad 0.1523 \n","[2023-12-09 07:30:07,443::train::INFO] [Train] Iter 1055 | Loss 0.038185 | Grad 0.1296 \n","[2023-12-09 07:30:07,528::train::INFO] [Train] Iter 1056 | Loss 0.041060 | Grad 0.1249 \n","[2023-12-09 07:30:07,612::train::INFO] [Train] Iter 1057 | Loss 0.039834 | Grad 0.1203 \n","[2023-12-09 07:30:07,698::train::INFO] [Train] Iter 1058 | Loss 0.041035 | Grad 0.0783 \n","[2023-12-09 07:30:07,781::train::INFO] [Train] Iter 1059 | Loss 0.039315 | Grad 0.1183 \n","[2023-12-09 07:30:07,871::train::INFO] [Train] Iter 1060 | Loss 0.040019 | Grad 0.1052 \n","[2023-12-09 07:30:07,955::train::INFO] [Train] Iter 1061 | Loss 0.039241 | Grad 0.0880 \n","[2023-12-09 07:30:08,040::train::INFO] [Train] Iter 1062 | Loss 0.039515 | Grad 0.0919 \n","[2023-12-09 07:30:08,124::train::INFO] [Train] Iter 1063 | Loss 0.039818 | Grad 0.0902 \n","[2023-12-09 07:30:08,207::train::INFO] [Train] Iter 1064 | Loss 0.038187 | Grad 0.0718 \n","[2023-12-09 07:30:08,292::train::INFO] [Train] Iter 1065 | Loss 0.039434 | Grad 0.0600 \n","[2023-12-09 07:30:08,377::train::INFO] [Train] Iter 1066 | Loss 0.039895 | Grad 0.1208 \n","[2023-12-09 07:30:08,460::train::INFO] [Train] Iter 1067 | Loss 0.038005 | Grad 0.1004 \n","[2023-12-09 07:30:08,546::train::INFO] [Train] Iter 1068 | Loss 0.038042 | Grad 0.0964 \n","[2023-12-09 07:30:08,629::train::INFO] [Train] Iter 1069 | Loss 0.040606 | Grad 0.1387 \n","[2023-12-09 07:30:08,714::train::INFO] [Train] Iter 1070 | Loss 0.038624 | Grad 0.0834 \n","[2023-12-09 07:30:08,797::train::INFO] [Train] Iter 1071 | Loss 0.042004 | Grad 0.1339 \n","[2023-12-09 07:30:08,881::train::INFO] [Train] Iter 1072 | Loss 0.038791 | Grad 0.0669 \n","[2023-12-09 07:30:08,965::train::INFO] [Train] Iter 1073 | Loss 0.039052 | Grad 0.1127 \n","[2023-12-09 07:30:09,049::train::INFO] [Train] Iter 1074 | Loss 0.038394 | Grad 0.0994 \n","[2023-12-09 07:30:09,133::train::INFO] [Train] Iter 1075 | Loss 0.039695 | Grad 0.0856 \n","[2023-12-09 07:30:09,216::train::INFO] [Train] Iter 1076 | Loss 0.041611 | Grad 0.0814 \n","[2023-12-09 07:30:09,299::train::INFO] [Train] Iter 1077 | Loss 0.038665 | Grad 0.0628 \n","[2023-12-09 07:30:09,382::train::INFO] [Train] Iter 1078 | Loss 0.038713 | Grad 0.0672 \n","[2023-12-09 07:30:09,466::train::INFO] [Train] Iter 1079 | Loss 0.038110 | Grad 0.0618 \n","[2023-12-09 07:30:09,552::train::INFO] [Train] Iter 1080 | Loss 0.037464 | Grad 0.0526 \n","[2023-12-09 07:30:09,636::train::INFO] [Train] Iter 1081 | Loss 0.039881 | Grad 0.1087 \n","[2023-12-09 07:30:09,723::train::INFO] [Train] Iter 1082 | Loss 0.041756 | Grad 0.0940 \n","[2023-12-09 07:30:09,806::train::INFO] [Train] Iter 1083 | Loss 0.039111 | Grad 0.0521 \n","[2023-12-09 07:30:09,890::train::INFO] [Train] Iter 1084 | Loss 0.040352 | Grad 0.2011 \n","[2023-12-09 07:30:09,975::train::INFO] [Train] Iter 1085 | Loss 0.040248 | Grad 0.1024 \n","[2023-12-09 07:30:10,069::train::INFO] [Train] Iter 1086 | Loss 0.038983 | Grad 0.1464 \n","[2023-12-09 07:30:10,161::train::INFO] [Train] Iter 1087 | Loss 0.039632 | Grad 0.1152 \n","[2023-12-09 07:30:10,255::train::INFO] [Train] Iter 1088 | Loss 0.037895 | Grad 0.1076 \n","[2023-12-09 07:30:10,345::train::INFO] [Train] Iter 1089 | Loss 0.038716 | Grad 0.1091 \n","[2023-12-09 07:30:10,435::train::INFO] [Train] Iter 1090 | Loss 0.038910 | Grad 0.1305 \n","[2023-12-09 07:30:10,527::train::INFO] [Train] Iter 1091 | Loss 0.039108 | Grad 0.1122 \n","[2023-12-09 07:30:10,617::train::INFO] [Train] Iter 1092 | Loss 0.038434 | Grad 0.0709 \n","[2023-12-09 07:30:10,711::train::INFO] [Train] Iter 1093 | Loss 0.039435 | Grad 0.1362 \n","[2023-12-09 07:30:10,802::train::INFO] [Train] Iter 1094 | Loss 0.038736 | Grad 0.0933 \n","[2023-12-09 07:30:10,896::train::INFO] [Train] Iter 1095 | Loss 0.039539 | Grad 0.0866 \n","[2023-12-09 07:30:10,990::train::INFO] [Train] Iter 1096 | Loss 0.038367 | Grad 0.1559 \n","[2023-12-09 07:30:11,081::train::INFO] [Train] Iter 1097 | Loss 0.038535 | Grad 0.0722 \n","[2023-12-09 07:30:11,171::train::INFO] [Train] Iter 1098 | Loss 0.038072 | Grad 0.0614 \n","[2023-12-09 07:30:11,262::train::INFO] [Train] Iter 1099 | Loss 0.038919 | Grad 0.0887 \n","[2023-12-09 07:30:11,359::train::INFO] [Train] Iter 1100 | Loss 0.037958 | Grad 0.0976 \n","[2023-12-09 07:30:11,451::train::INFO] [Train] Iter 1101 | Loss 0.039018 | Grad 0.0658 \n","[2023-12-09 07:30:11,541::train::INFO] [Train] Iter 1102 | Loss 0.037349 | Grad 0.0775 \n","[2023-12-09 07:30:11,637::train::INFO] [Train] Iter 1103 | Loss 0.037491 | Grad 0.0704 \n","[2023-12-09 07:30:11,732::train::INFO] [Train] Iter 1104 | Loss 0.039826 | Grad 0.0881 \n","[2023-12-09 07:30:11,827::train::INFO] [Train] Iter 1105 | Loss 0.040364 | Grad 0.1110 \n","[2023-12-09 07:30:11,919::train::INFO] [Train] Iter 1106 | Loss 0.039236 | Grad 0.0844 \n","[2023-12-09 07:30:12,013::train::INFO] [Train] Iter 1107 | Loss 0.039118 | Grad 0.0835 \n","[2023-12-09 07:30:12,109::train::INFO] [Train] Iter 1108 | Loss 0.038638 | Grad 0.0516 \n","[2023-12-09 07:30:12,227::train::INFO] [Train] Iter 1109 | Loss 0.038625 | Grad 0.0607 \n","[2023-12-09 07:30:12,319::train::INFO] [Train] Iter 1110 | Loss 0.040790 | Grad 0.1648 \n","[2023-12-09 07:30:12,411::train::INFO] [Train] Iter 1111 | Loss 0.037822 | Grad 0.0626 \n","[2023-12-09 07:30:12,505::train::INFO] [Train] Iter 1112 | Loss 0.038496 | Grad 0.1154 \n","[2023-12-09 07:30:12,598::train::INFO] [Train] Iter 1113 | Loss 0.038455 | Grad 0.0608 \n","[2023-12-09 07:30:12,687::train::INFO] [Train] Iter 1114 | Loss 0.038549 | Grad 0.1062 \n","[2023-12-09 07:30:12,778::train::INFO] [Train] Iter 1115 | Loss 0.040496 | Grad 0.0838 \n","[2023-12-09 07:30:12,874::train::INFO] [Train] Iter 1116 | Loss 0.035924 | Grad 0.1061 \n","[2023-12-09 07:30:12,967::train::INFO] [Train] Iter 1117 | Loss 0.038193 | Grad 0.0461 \n","[2023-12-09 07:30:13,058::train::INFO] [Train] Iter 1118 | Loss 0.038152 | Grad 0.1204 \n","[2023-12-09 07:30:13,148::train::INFO] [Train] Iter 1119 | Loss 0.037559 | Grad 0.1038 \n","[2023-12-09 07:30:13,240::train::INFO] [Train] Iter 1120 | Loss 0.039820 | Grad 0.0827 \n","[2023-12-09 07:30:13,331::train::INFO] [Train] Iter 1121 | Loss 0.038836 | Grad 0.0679 \n","[2023-12-09 07:30:13,423::train::INFO] [Train] Iter 1122 | Loss 0.038571 | Grad 0.0742 \n","[2023-12-09 07:30:13,516::train::INFO] [Train] Iter 1123 | Loss 0.038557 | Grad 0.0779 \n","[2023-12-09 07:30:13,608::train::INFO] [Train] Iter 1124 | Loss 0.038161 | Grad 0.0572 \n","[2023-12-09 07:30:13,701::train::INFO] [Train] Iter 1125 | Loss 0.038678 | Grad 0.0825 \n","[2023-12-09 07:30:13,792::train::INFO] [Train] Iter 1126 | Loss 0.038726 | Grad 0.0531 \n","[2023-12-09 07:30:13,884::train::INFO] [Train] Iter 1127 | Loss 0.037093 | Grad 0.0552 \n","[2023-12-09 07:30:13,975::train::INFO] [Train] Iter 1128 | Loss 0.038762 | Grad 0.0764 \n","[2023-12-09 07:30:14,067::train::INFO] [Train] Iter 1129 | Loss 0.040883 | Grad 0.1456 \n","[2023-12-09 07:30:14,157::train::INFO] [Train] Iter 1130 | Loss 0.038135 | Grad 0.0819 \n","[2023-12-09 07:30:14,248::train::INFO] [Train] Iter 1131 | Loss 0.039243 | Grad 0.0593 \n","[2023-12-09 07:30:14,345::train::INFO] [Train] Iter 1132 | Loss 0.037757 | Grad 0.1192 \n","[2023-12-09 07:30:14,438::train::INFO] [Train] Iter 1133 | Loss 0.037891 | Grad 0.0711 \n","[2023-12-09 07:30:14,529::train::INFO] [Train] Iter 1134 | Loss 0.038668 | Grad 0.0849 \n","[2023-12-09 07:30:14,621::train::INFO] [Train] Iter 1135 | Loss 0.038011 | Grad 0.0905 \n","[2023-12-09 07:30:14,714::train::INFO] [Train] Iter 1136 | Loss 0.038932 | Grad 0.0836 \n","[2023-12-09 07:30:14,806::train::INFO] [Train] Iter 1137 | Loss 0.038548 | Grad 0.0674 \n","[2023-12-09 07:30:14,897::train::INFO] [Train] Iter 1138 | Loss 0.037607 | Grad 0.0801 \n","[2023-12-09 07:30:14,991::train::INFO] [Train] Iter 1139 | Loss 0.035824 | Grad 0.1981 \n","[2023-12-09 07:30:15,081::train::INFO] [Train] Iter 1140 | Loss 0.039140 | Grad 0.1311 \n","[2023-12-09 07:30:15,173::train::INFO] [Train] Iter 1141 | Loss 0.037815 | Grad 0.0425 \n","[2023-12-09 07:30:15,264::train::INFO] [Train] Iter 1142 | Loss 0.037378 | Grad 0.1071 \n","[2023-12-09 07:30:15,357::train::INFO] [Train] Iter 1143 | Loss 0.036610 | Grad 0.0985 \n","[2023-12-09 07:30:15,447::train::INFO] [Train] Iter 1144 | Loss 0.038198 | Grad 0.0721 \n","[2023-12-09 07:30:15,538::train::INFO] [Train] Iter 1145 | Loss 0.038788 | Grad 0.0886 \n","[2023-12-09 07:30:15,633::train::INFO] [Train] Iter 1146 | Loss 0.038089 | Grad 0.0866 \n","[2023-12-09 07:30:15,725::train::INFO] [Train] Iter 1147 | Loss 0.037182 | Grad 0.0542 \n","[2023-12-09 07:30:15,815::train::INFO] [Train] Iter 1148 | Loss 0.038929 | Grad 0.0769 \n","[2023-12-09 07:30:15,909::train::INFO] [Train] Iter 1149 | Loss 0.038622 | Grad 0.0750 \n","[2023-12-09 07:30:16,003::train::INFO] [Train] Iter 1150 | Loss 0.036507 | Grad 0.0922 \n","[2023-12-09 07:30:16,096::train::INFO] [Train] Iter 1151 | Loss 0.039020 | Grad 0.0871 \n","[2023-12-09 07:30:16,190::train::INFO] [Train] Iter 1152 | Loss 0.038567 | Grad 0.0979 \n","[2023-12-09 07:30:16,282::train::INFO] [Train] Iter 1153 | Loss 0.037585 | Grad 0.0825 \n","[2023-12-09 07:30:16,369::train::INFO] [Train] Iter 1154 | Loss 0.037062 | Grad 0.0905 \n","[2023-12-09 07:30:16,453::train::INFO] [Train] Iter 1155 | Loss 0.037034 | Grad 0.1200 \n","[2023-12-09 07:30:16,537::train::INFO] [Train] Iter 1156 | Loss 0.036994 | Grad 0.0968 \n","[2023-12-09 07:30:16,621::train::INFO] [Train] Iter 1157 | Loss 0.037205 | Grad 0.1042 \n","[2023-12-09 07:30:16,706::train::INFO] [Train] Iter 1158 | Loss 0.036818 | Grad 0.0780 \n","[2023-12-09 07:30:16,794::train::INFO] [Train] Iter 1159 | Loss 0.038534 | Grad 0.1306 \n","[2023-12-09 07:30:16,878::train::INFO] [Train] Iter 1160 | Loss 0.038426 | Grad 0.1537 \n","[2023-12-09 07:30:16,963::train::INFO] [Train] Iter 1161 | Loss 0.039012 | Grad 0.1252 \n","[2023-12-09 07:30:17,049::train::INFO] [Train] Iter 1162 | Loss 0.037506 | Grad 0.0857 \n","[2023-12-09 07:30:17,134::train::INFO] [Train] Iter 1163 | Loss 0.039843 | Grad 0.0914 \n","[2023-12-09 07:30:17,219::train::INFO] [Train] Iter 1164 | Loss 0.038896 | Grad 0.1095 \n","[2023-12-09 07:30:17,304::train::INFO] [Train] Iter 1165 | Loss 0.040192 | Grad 0.1050 \n","[2023-12-09 07:30:17,393::train::INFO] [Train] Iter 1166 | Loss 0.038845 | Grad 0.1461 \n","[2023-12-09 07:30:17,477::train::INFO] [Train] Iter 1167 | Loss 0.037725 | Grad 0.0559 \n","[2023-12-09 07:30:17,563::train::INFO] [Train] Iter 1168 | Loss 0.038381 | Grad 0.1136 \n","[2023-12-09 07:30:17,647::train::INFO] [Train] Iter 1169 | Loss 0.039060 | Grad 0.1264 \n","[2023-12-09 07:30:17,732::train::INFO] [Train] Iter 1170 | Loss 0.039578 | Grad 0.1223 \n","[2023-12-09 07:30:17,816::train::INFO] [Train] Iter 1171 | Loss 0.039575 | Grad 0.0493 \n","[2023-12-09 07:30:17,899::train::INFO] [Train] Iter 1172 | Loss 0.039366 | Grad 0.1360 \n","[2023-12-09 07:30:17,984::train::INFO] [Train] Iter 1173 | Loss 0.037093 | Grad 0.0967 \n","[2023-12-09 07:30:18,071::train::INFO] [Train] Iter 1174 | Loss 0.037061 | Grad 0.0991 \n","[2023-12-09 07:30:18,165::train::INFO] [Train] Iter 1175 | Loss 0.037691 | Grad 0.0788 \n","[2023-12-09 07:30:18,249::train::INFO] [Train] Iter 1176 | Loss 0.037873 | Grad 0.0591 \n","[2023-12-09 07:30:18,337::train::INFO] [Train] Iter 1177 | Loss 0.036401 | Grad 0.1037 \n","[2023-12-09 07:30:18,421::train::INFO] [Train] Iter 1178 | Loss 0.037345 | Grad 0.1297 \n","[2023-12-09 07:30:18,508::train::INFO] [Train] Iter 1179 | Loss 0.036587 | Grad 0.0950 \n","[2023-12-09 07:30:18,593::train::INFO] [Train] Iter 1180 | Loss 0.037232 | Grad 0.1002 \n","[2023-12-09 07:30:18,677::train::INFO] [Train] Iter 1181 | Loss 0.037343 | Grad 0.1361 \n","[2023-12-09 07:30:18,763::train::INFO] [Train] Iter 1182 | Loss 0.037399 | Grad 0.0763 \n","[2023-12-09 07:30:18,849::train::INFO] [Train] Iter 1183 | Loss 0.039402 | Grad 0.1146 \n","[2023-12-09 07:30:18,934::train::INFO] [Train] Iter 1184 | Loss 0.038484 | Grad 0.0680 \n","[2023-12-09 07:30:19,018::train::INFO] [Train] Iter 1185 | Loss 0.037439 | Grad 0.1177 \n","[2023-12-09 07:30:19,104::train::INFO] [Train] Iter 1186 | Loss 0.038280 | Grad 0.1506 \n","[2023-12-09 07:30:19,187::train::INFO] [Train] Iter 1187 | Loss 0.037013 | Grad 0.0539 \n","[2023-12-09 07:30:19,270::train::INFO] [Train] Iter 1188 | Loss 0.038128 | Grad 0.1208 \n","[2023-12-09 07:30:19,353::train::INFO] [Train] Iter 1189 | Loss 0.035912 | Grad 0.1442 \n","[2023-12-09 07:30:19,440::train::INFO] [Train] Iter 1190 | Loss 0.036997 | Grad 0.1242 \n","[2023-12-09 07:30:19,523::train::INFO] [Train] Iter 1191 | Loss 0.036483 | Grad 0.0787 \n","[2023-12-09 07:30:19,607::train::INFO] [Train] Iter 1192 | Loss 0.039470 | Grad 0.0722 \n","[2023-12-09 07:30:19,692::train::INFO] [Train] Iter 1193 | Loss 0.040011 | Grad 0.1766 \n","[2023-12-09 07:30:19,776::train::INFO] [Train] Iter 1194 | Loss 0.037880 | Grad 0.0602 \n","[2023-12-09 07:30:19,860::train::INFO] [Train] Iter 1195 | Loss 0.037180 | Grad 0.0738 \n","[2023-12-09 07:30:19,946::train::INFO] [Train] Iter 1196 | Loss 0.036211 | Grad 0.0928 \n","[2023-12-09 07:30:20,030::train::INFO] [Train] Iter 1197 | Loss 0.036096 | Grad 0.0850 \n","[2023-12-09 07:30:20,118::train::INFO] [Train] Iter 1198 | Loss 0.035936 | Grad 0.1014 \n","[2023-12-09 07:30:20,205::train::INFO] [Train] Iter 1199 | Loss 0.035479 | Grad 0.0747 \n","[2023-12-09 07:30:20,289::train::INFO] [Train] Iter 1200 | Loss 0.037623 | Grad 0.1077 \n","[2023-12-09 07:30:20,372::train::INFO] [Train] Iter 1201 | Loss 0.039277 | Grad 0.0881 \n","[2023-12-09 07:30:20,456::train::INFO] [Train] Iter 1202 | Loss 0.036466 | Grad 0.0558 \n","[2023-12-09 07:30:20,540::train::INFO] [Train] Iter 1203 | Loss 0.035910 | Grad 0.1345 \n","[2023-12-09 07:30:20,624::train::INFO] [Train] Iter 1204 | Loss 0.038547 | Grad 0.1419 \n","[2023-12-09 07:30:20,709::train::INFO] [Train] Iter 1205 | Loss 0.036235 | Grad 0.0760 \n","[2023-12-09 07:30:20,793::train::INFO] [Train] Iter 1206 | Loss 0.038584 | Grad 0.0927 \n","[2023-12-09 07:30:20,882::train::INFO] [Train] Iter 1207 | Loss 0.035568 | Grad 0.0900 \n","[2023-12-09 07:30:20,967::train::INFO] [Train] Iter 1208 | Loss 0.037710 | Grad 0.0735 \n","[2023-12-09 07:30:21,053::train::INFO] [Train] Iter 1209 | Loss 0.037317 | Grad 0.1241 \n","[2023-12-09 07:30:21,138::train::INFO] [Train] Iter 1210 | Loss 0.037734 | Grad 0.0713 \n","[2023-12-09 07:30:21,223::train::INFO] [Train] Iter 1211 | Loss 0.038769 | Grad 0.0900 \n","[2023-12-09 07:30:21,307::train::INFO] [Train] Iter 1212 | Loss 0.037273 | Grad 0.1297 \n","[2023-12-09 07:30:21,390::train::INFO] [Train] Iter 1213 | Loss 0.037056 | Grad 0.0858 \n","[2023-12-09 07:30:21,474::train::INFO] [Train] Iter 1214 | Loss 0.036587 | Grad 0.0492 \n","[2023-12-09 07:30:21,558::train::INFO] [Train] Iter 1215 | Loss 0.038542 | Grad 0.0664 \n","[2023-12-09 07:30:21,642::train::INFO] [Train] Iter 1216 | Loss 0.038389 | Grad 0.0653 \n","[2023-12-09 07:30:21,729::train::INFO] [Train] Iter 1217 | Loss 0.036459 | Grad 0.0606 \n","[2023-12-09 07:30:21,814::train::INFO] [Train] Iter 1218 | Loss 0.035712 | Grad 0.0622 \n","[2023-12-09 07:30:21,899::train::INFO] [Train] Iter 1219 | Loss 0.037628 | Grad 0.0534 \n","[2023-12-09 07:30:21,986::train::INFO] [Train] Iter 1220 | Loss 0.035848 | Grad 0.0661 \n","[2023-12-09 07:30:22,071::train::INFO] [Train] Iter 1221 | Loss 0.036156 | Grad 0.0709 \n","[2023-12-09 07:30:22,157::train::INFO] [Train] Iter 1222 | Loss 0.037267 | Grad 0.0615 \n","[2023-12-09 07:30:22,241::train::INFO] [Train] Iter 1223 | Loss 0.037686 | Grad 0.0502 \n","[2023-12-09 07:30:22,325::train::INFO] [Train] Iter 1224 | Loss 0.036621 | Grad 0.0896 \n","[2023-12-09 07:30:22,410::train::INFO] [Train] Iter 1225 | Loss 0.037407 | Grad 0.0802 \n","[2023-12-09 07:30:22,495::train::INFO] [Train] Iter 1226 | Loss 0.036426 | Grad 0.0866 \n","[2023-12-09 07:30:22,578::train::INFO] [Train] Iter 1227 | Loss 0.036596 | Grad 0.0622 \n","[2023-12-09 07:30:22,661::train::INFO] [Train] Iter 1228 | Loss 0.037122 | Grad 0.0838 \n","[2023-12-09 07:30:22,746::train::INFO] [Train] Iter 1229 | Loss 0.035533 | Grad 0.0904 \n","[2023-12-09 07:30:22,829::train::INFO] [Train] Iter 1230 | Loss 0.039942 | Grad 0.0931 \n","[2023-12-09 07:30:22,914::train::INFO] [Train] Iter 1231 | Loss 0.038738 | Grad 0.0866 \n","[2023-12-09 07:30:22,997::train::INFO] [Train] Iter 1232 | Loss 0.036225 | Grad 0.0661 \n","[2023-12-09 07:30:23,081::train::INFO] [Train] Iter 1233 | Loss 0.036961 | Grad 0.1008 \n","[2023-12-09 07:30:23,170::train::INFO] [Train] Iter 1234 | Loss 0.038269 | Grad 0.0825 \n","[2023-12-09 07:30:23,253::train::INFO] [Train] Iter 1235 | Loss 0.035940 | Grad 0.0556 \n","[2023-12-09 07:30:23,336::train::INFO] [Train] Iter 1236 | Loss 0.037626 | Grad 0.0755 \n","[2023-12-09 07:30:23,420::train::INFO] [Train] Iter 1237 | Loss 0.036872 | Grad 0.0530 \n","[2023-12-09 07:30:23,505::train::INFO] [Train] Iter 1238 | Loss 0.038746 | Grad 0.0666 \n","[2023-12-09 07:30:23,588::train::INFO] [Train] Iter 1239 | Loss 0.036220 | Grad 0.0690 \n","[2023-12-09 07:30:23,672::train::INFO] [Train] Iter 1240 | Loss 0.038026 | Grad 0.1126 \n","[2023-12-09 07:30:23,757::train::INFO] [Train] Iter 1241 | Loss 0.035939 | Grad 0.0742 \n","[2023-12-09 07:30:23,841::train::INFO] [Train] Iter 1242 | Loss 0.035807 | Grad 0.0855 \n","[2023-12-09 07:30:23,924::train::INFO] [Train] Iter 1243 | Loss 0.036503 | Grad 0.0747 \n","[2023-12-09 07:30:24,008::train::INFO] [Train] Iter 1244 | Loss 0.037533 | Grad 0.1233 \n","[2023-12-09 07:30:24,092::train::INFO] [Train] Iter 1245 | Loss 0.036525 | Grad 0.0744 \n","[2023-12-09 07:30:24,179::train::INFO] [Train] Iter 1246 | Loss 0.037620 | Grad 0.0573 \n","[2023-12-09 07:30:24,263::train::INFO] [Train] Iter 1247 | Loss 0.036969 | Grad 0.0522 \n","[2023-12-09 07:30:24,347::train::INFO] [Train] Iter 1248 | Loss 0.034717 | Grad 0.0468 \n","[2023-12-09 07:30:24,430::train::INFO] [Train] Iter 1249 | Loss 0.037868 | Grad 0.0839 \n","[2023-12-09 07:30:24,513::train::INFO] [Train] Iter 1250 | Loss 0.035005 | Grad 0.0565 \n","[2023-12-09 07:30:24,597::train::INFO] [Train] Iter 1251 | Loss 0.037459 | Grad 0.0670 \n","[2023-12-09 07:30:24,681::train::INFO] [Train] Iter 1252 | Loss 0.036652 | Grad 0.0562 \n","[2023-12-09 07:30:24,766::train::INFO] [Train] Iter 1253 | Loss 0.038218 | Grad 0.0695 \n","[2023-12-09 07:30:24,850::train::INFO] [Train] Iter 1254 | Loss 0.036180 | Grad 0.0511 \n","[2023-12-09 07:30:24,934::train::INFO] [Train] Iter 1255 | Loss 0.036523 | Grad 0.0799 \n","[2023-12-09 07:30:25,019::train::INFO] [Train] Iter 1256 | Loss 0.037200 | Grad 0.0849 \n","[2023-12-09 07:30:25,104::train::INFO] [Train] Iter 1257 | Loss 0.036454 | Grad 0.0901 \n","[2023-12-09 07:30:25,190::train::INFO] [Train] Iter 1258 | Loss 0.035655 | Grad 0.0573 \n","[2023-12-09 07:30:25,275::train::INFO] [Train] Iter 1259 | Loss 0.036236 | Grad 0.0567 \n","[2023-12-09 07:30:25,362::train::INFO] [Train] Iter 1260 | Loss 0.035833 | Grad 0.0608 \n","[2023-12-09 07:30:25,445::train::INFO] [Train] Iter 1261 | Loss 0.037508 | Grad 0.0872 \n","[2023-12-09 07:30:25,528::train::INFO] [Train] Iter 1262 | Loss 0.035098 | Grad 0.0520 \n","[2023-12-09 07:30:25,612::train::INFO] [Train] Iter 1263 | Loss 0.036633 | Grad 0.0734 \n","[2023-12-09 07:30:25,701::train::INFO] [Train] Iter 1264 | Loss 0.038298 | Grad 0.0626 \n","[2023-12-09 07:30:25,787::train::INFO] [Train] Iter 1265 | Loss 0.037515 | Grad 0.0734 \n","[2023-12-09 07:30:25,871::train::INFO] [Train] Iter 1266 | Loss 0.035911 | Grad 0.0908 \n","[2023-12-09 07:30:25,956::train::INFO] [Train] Iter 1267 | Loss 0.034454 | Grad 0.0824 \n","[2023-12-09 07:30:26,039::train::INFO] [Train] Iter 1268 | Loss 0.036837 | Grad 0.0726 \n","[2023-12-09 07:30:26,123::train::INFO] [Train] Iter 1269 | Loss 0.034910 | Grad 0.0953 \n","[2023-12-09 07:30:26,211::train::INFO] [Train] Iter 1270 | Loss 0.035322 | Grad 0.0984 \n","[2023-12-09 07:30:26,297::train::INFO] [Train] Iter 1271 | Loss 0.036099 | Grad 0.0673 \n","[2023-12-09 07:30:26,409::train::INFO] [Train] Iter 1272 | Loss 0.036170 | Grad 0.0784 \n","[2023-12-09 07:30:26,502::train::INFO] [Train] Iter 1273 | Loss 0.037554 | Grad 0.0885 \n","[2023-12-09 07:30:26,602::train::INFO] [Train] Iter 1274 | Loss 0.036293 | Grad 0.1398 \n","[2023-12-09 07:30:26,711::train::INFO] [Train] Iter 1275 | Loss 0.035496 | Grad 0.0547 \n","[2023-12-09 07:30:26,810::train::INFO] [Train] Iter 1276 | Loss 0.035737 | Grad 0.1294 \n","[2023-12-09 07:30:26,916::train::INFO] [Train] Iter 1277 | Loss 0.037324 | Grad 0.0777 \n","[2023-12-09 07:30:27,023::train::INFO] [Train] Iter 1278 | Loss 0.036309 | Grad 0.0502 \n","[2023-12-09 07:30:27,122::train::INFO] [Train] Iter 1279 | Loss 0.037558 | Grad 0.0830 \n","[2023-12-09 07:30:27,229::train::INFO] [Train] Iter 1280 | Loss 0.038679 | Grad 0.0889 \n","[2023-12-09 07:30:27,327::train::INFO] [Train] Iter 1281 | Loss 0.036778 | Grad 0.0865 \n","[2023-12-09 07:30:27,421::train::INFO] [Train] Iter 1282 | Loss 0.037518 | Grad 0.0534 \n","[2023-12-09 07:30:27,518::train::INFO] [Train] Iter 1283 | Loss 0.034957 | Grad 0.0683 \n","[2023-12-09 07:30:27,611::train::INFO] [Train] Iter 1284 | Loss 0.035996 | Grad 0.1022 \n","[2023-12-09 07:30:27,702::train::INFO] [Train] Iter 1285 | Loss 0.036293 | Grad 0.0977 \n","[2023-12-09 07:30:27,795::train::INFO] [Train] Iter 1286 | Loss 0.037330 | Grad 0.0581 \n","[2023-12-09 07:30:27,887::train::INFO] [Train] Iter 1287 | Loss 0.037052 | Grad 0.0632 \n","[2023-12-09 07:30:27,977::train::INFO] [Train] Iter 1288 | Loss 0.036835 | Grad 0.1110 \n","[2023-12-09 07:30:28,073::train::INFO] [Train] Iter 1289 | Loss 0.035966 | Grad 0.1251 \n","[2023-12-09 07:30:28,166::train::INFO] [Train] Iter 1290 | Loss 0.038057 | Grad 0.0753 \n","[2023-12-09 07:30:28,258::train::INFO] [Train] Iter 1291 | Loss 0.037896 | Grad 0.1332 \n","[2023-12-09 07:30:28,363::train::INFO] [Train] Iter 1292 | Loss 0.034929 | Grad 0.0575 \n","[2023-12-09 07:30:28,455::train::INFO] [Train] Iter 1293 | Loss 0.034729 | Grad 0.0630 \n","[2023-12-09 07:30:28,546::train::INFO] [Train] Iter 1294 | Loss 0.035675 | Grad 0.0877 \n","[2023-12-09 07:30:28,648::train::INFO] [Train] Iter 1295 | Loss 0.034967 | Grad 0.0869 \n","[2023-12-09 07:30:28,744::train::INFO] [Train] Iter 1296 | Loss 0.035399 | Grad 0.0722 \n","[2023-12-09 07:30:28,837::train::INFO] [Train] Iter 1297 | Loss 0.035813 | Grad 0.0485 \n","[2023-12-09 07:30:28,934::train::INFO] [Train] Iter 1298 | Loss 0.036414 | Grad 0.0733 \n","[2023-12-09 07:30:29,029::train::INFO] [Train] Iter 1299 | Loss 0.036770 | Grad 0.0867 \n","[2023-12-09 07:30:29,135::train::INFO] [Train] Iter 1300 | Loss 0.035112 | Grad 0.0741 \n","[2023-12-09 07:30:29,227::train::INFO] [Train] Iter 1301 | Loss 0.035980 | Grad 0.1421 \n","[2023-12-09 07:30:29,321::train::INFO] [Train] Iter 1302 | Loss 0.035420 | Grad 0.0706 \n","[2023-12-09 07:30:29,425::train::INFO] [Train] Iter 1303 | Loss 0.034791 | Grad 0.0882 \n","[2023-12-09 07:30:29,528::train::INFO] [Train] Iter 1304 | Loss 0.037438 | Grad 0.0707 \n","[2023-12-09 07:30:29,624::train::INFO] [Train] Iter 1305 | Loss 0.035881 | Grad 0.0671 \n","[2023-12-09 07:30:29,729::train::INFO] [Train] Iter 1306 | Loss 0.034864 | Grad 0.0917 \n","[2023-12-09 07:30:29,826::train::INFO] [Train] Iter 1307 | Loss 0.034341 | Grad 0.0638 \n","[2023-12-09 07:30:29,932::train::INFO] [Train] Iter 1308 | Loss 0.037036 | Grad 0.0609 \n","[2023-12-09 07:30:30,027::train::INFO] [Train] Iter 1309 | Loss 0.035818 | Grad 0.1018 \n","[2023-12-09 07:30:30,117::train::INFO] [Train] Iter 1310 | Loss 0.036519 | Grad 0.1262 \n","[2023-12-09 07:30:30,211::train::INFO] [Train] Iter 1311 | Loss 0.035013 | Grad 0.0742 \n","[2023-12-09 07:30:30,302::train::INFO] [Train] Iter 1312 | Loss 0.036182 | Grad 0.1296 \n","[2023-12-09 07:30:30,417::train::INFO] [Train] Iter 1313 | Loss 0.035810 | Grad 0.0794 \n","[2023-12-09 07:30:30,512::train::INFO] [Train] Iter 1314 | Loss 0.037146 | Grad 0.1363 \n","[2023-12-09 07:30:30,602::train::INFO] [Train] Iter 1315 | Loss 0.035935 | Grad 0.0686 \n","[2023-12-09 07:30:30,696::train::INFO] [Train] Iter 1316 | Loss 0.039523 | Grad 0.1096 \n","[2023-12-09 07:30:30,788::train::INFO] [Train] Iter 1317 | Loss 0.036592 | Grad 0.1078 \n","[2023-12-09 07:30:30,887::train::INFO] [Train] Iter 1318 | Loss 0.034116 | Grad 0.1606 \n","[2023-12-09 07:30:30,985::train::INFO] [Train] Iter 1319 | Loss 0.038020 | Grad 0.0572 \n","[2023-12-09 07:30:31,088::train::INFO] [Train] Iter 1320 | Loss 0.036524 | Grad 0.0706 \n","[2023-12-09 07:30:31,193::train::INFO] [Train] Iter 1321 | Loss 0.034470 | Grad 0.1038 \n","[2023-12-09 07:30:31,287::train::INFO] [Train] Iter 1322 | Loss 0.036448 | Grad 0.0500 \n","[2023-12-09 07:30:31,396::train::INFO] [Train] Iter 1323 | Loss 0.035372 | Grad 0.1112 \n","[2023-12-09 07:30:31,489::train::INFO] [Train] Iter 1324 | Loss 0.036031 | Grad 0.0917 \n","[2023-12-09 07:30:31,585::train::INFO] [Train] Iter 1325 | Loss 0.036198 | Grad 0.0700 \n","[2023-12-09 07:30:31,677::train::INFO] [Train] Iter 1326 | Loss 0.036830 | Grad 0.0880 \n","[2023-12-09 07:30:31,773::train::INFO] [Train] Iter 1327 | Loss 0.036216 | Grad 0.0908 \n","[2023-12-09 07:30:31,878::train::INFO] [Train] Iter 1328 | Loss 0.033590 | Grad 0.0740 \n","[2023-12-09 07:30:31,991::train::INFO] [Train] Iter 1329 | Loss 0.036517 | Grad 0.0771 \n","[2023-12-09 07:30:32,103::train::INFO] [Train] Iter 1330 | Loss 0.036861 | Grad 0.0583 \n","[2023-12-09 07:30:32,199::train::INFO] [Train] Iter 1331 | Loss 0.035364 | Grad 0.0647 \n","[2023-12-09 07:30:32,292::train::INFO] [Train] Iter 1332 | Loss 0.036332 | Grad 0.1024 \n","[2023-12-09 07:30:32,386::train::INFO] [Train] Iter 1333 | Loss 0.037401 | Grad 0.1086 \n","[2023-12-09 07:30:32,477::train::INFO] [Train] Iter 1334 | Loss 0.036493 | Grad 0.0544 \n","[2023-12-09 07:30:32,569::train::INFO] [Train] Iter 1335 | Loss 0.035619 | Grad 0.1214 \n","[2023-12-09 07:30:32,667::train::INFO] [Train] Iter 1336 | Loss 0.035583 | Grad 0.1008 \n","[2023-12-09 07:30:32,776::train::INFO] [Train] Iter 1337 | Loss 0.037782 | Grad 0.0905 \n","[2023-12-09 07:30:32,887::train::INFO] [Train] Iter 1338 | Loss 0.036230 | Grad 0.1244 \n","[2023-12-09 07:30:32,993::train::INFO] [Train] Iter 1339 | Loss 0.035133 | Grad 0.1000 \n","[2023-12-09 07:30:33,100::train::INFO] [Train] Iter 1340 | Loss 0.036906 | Grad 0.0589 \n","[2023-12-09 07:30:33,202::train::INFO] [Train] Iter 1341 | Loss 0.033958 | Grad 0.0487 \n","[2023-12-09 07:30:33,306::train::INFO] [Train] Iter 1342 | Loss 0.037235 | Grad 0.0730 \n","[2023-12-09 07:30:33,408::train::INFO] [Train] Iter 1343 | Loss 0.035715 | Grad 0.0644 \n","[2023-12-09 07:30:33,511::train::INFO] [Train] Iter 1344 | Loss 0.034179 | Grad 0.0671 \n","[2023-12-09 07:30:33,615::train::INFO] [Train] Iter 1345 | Loss 0.035647 | Grad 0.0823 \n","[2023-12-09 07:30:33,717::train::INFO] [Train] Iter 1346 | Loss 0.038238 | Grad 0.1571 \n","[2023-12-09 07:30:33,813::train::INFO] [Train] Iter 1347 | Loss 0.035053 | Grad 0.0493 \n","[2023-12-09 07:30:33,913::train::INFO] [Train] Iter 1348 | Loss 0.035503 | Grad 0.0661 \n","[2023-12-09 07:30:34,004::train::INFO] [Train] Iter 1349 | Loss 0.036896 | Grad 0.0765 \n","[2023-12-09 07:30:34,096::train::INFO] [Train] Iter 1350 | Loss 0.035784 | Grad 0.0624 \n","[2023-12-09 07:30:34,187::train::INFO] [Train] Iter 1351 | Loss 0.033847 | Grad 0.0836 \n","[2023-12-09 07:30:34,281::train::INFO] [Train] Iter 1352 | Loss 0.035737 | Grad 0.0862 \n","[2023-12-09 07:30:34,374::train::INFO] [Train] Iter 1353 | Loss 0.036431 | Grad 0.0958 \n","[2023-12-09 07:30:34,465::train::INFO] [Train] Iter 1354 | Loss 0.036736 | Grad 0.0827 \n","[2023-12-09 07:30:34,556::train::INFO] [Train] Iter 1355 | Loss 0.034024 | Grad 0.0666 \n","[2023-12-09 07:30:34,646::train::INFO] [Train] Iter 1356 | Loss 0.036863 | Grad 0.0725 \n","[2023-12-09 07:30:34,737::train::INFO] [Train] Iter 1357 | Loss 0.036977 | Grad 0.0584 \n","[2023-12-09 07:30:34,836::train::INFO] [Train] Iter 1358 | Loss 0.033815 | Grad 0.0986 \n","[2023-12-09 07:30:34,927::train::INFO] [Train] Iter 1359 | Loss 0.034569 | Grad 0.1191 \n","[2023-12-09 07:30:34,987::train::INFO] [Train] Iter 1360 | Loss 0.034148 | Grad 0.1184 \n","[2023-12-09 07:30:35,087::train::INFO] [Train] Iter 1361 | Loss 0.034787 | Grad 0.0515 \n","[2023-12-09 07:30:35,194::train::INFO] [Train] Iter 1362 | Loss 0.037253 | Grad 0.0941 \n","[2023-12-09 07:30:35,306::train::INFO] [Train] Iter 1363 | Loss 0.035985 | Grad 0.0683 \n","[2023-12-09 07:30:35,411::train::INFO] [Train] Iter 1364 | Loss 0.036587 | Grad 0.0606 \n","[2023-12-09 07:30:35,512::train::INFO] [Train] Iter 1365 | Loss 0.035253 | Grad 0.0964 \n","[2023-12-09 07:30:35,624::train::INFO] [Train] Iter 1366 | Loss 0.036621 | Grad 0.0728 \n","[2023-12-09 07:30:35,720::train::INFO] [Train] Iter 1367 | Loss 0.035530 | Grad 0.0997 \n","[2023-12-09 07:30:35,814::train::INFO] [Train] Iter 1368 | Loss 0.036994 | Grad 0.0606 \n","[2023-12-09 07:30:35,917::train::INFO] [Train] Iter 1369 | Loss 0.035845 | Grad 0.0738 \n","[2023-12-09 07:30:36,015::train::INFO] [Train] Iter 1370 | Loss 0.036551 | Grad 0.0762 \n","[2023-12-09 07:30:36,113::train::INFO] [Train] Iter 1371 | Loss 0.035062 | Grad 0.0542 \n","[2023-12-09 07:30:36,210::train::INFO] [Train] Iter 1372 | Loss 0.036630 | Grad 0.0642 \n","[2023-12-09 07:30:36,310::train::INFO] [Train] Iter 1373 | Loss 0.035795 | Grad 0.1155 \n","[2023-12-09 07:30:36,417::train::INFO] [Train] Iter 1374 | Loss 0.035438 | Grad 0.0815 \n","[2023-12-09 07:30:36,515::train::INFO] [Train] Iter 1375 | Loss 0.035861 | Grad 0.0387 \n","[2023-12-09 07:30:36,615::train::INFO] [Train] Iter 1376 | Loss 0.035627 | Grad 0.0634 \n","[2023-12-09 07:30:36,716::train::INFO] [Train] Iter 1377 | Loss 0.035752 | Grad 0.0892 \n","[2023-12-09 07:30:36,814::train::INFO] [Train] Iter 1378 | Loss 0.034662 | Grad 0.0533 \n","[2023-12-09 07:30:36,909::train::INFO] [Train] Iter 1379 | Loss 0.037267 | Grad 0.0374 \n","[2023-12-09 07:30:37,000::train::INFO] [Train] Iter 1380 | Loss 0.034929 | Grad 0.0696 \n","[2023-12-09 07:30:37,096::train::INFO] [Train] Iter 1381 | Loss 0.033513 | Grad 0.0602 \n","[2023-12-09 07:30:37,193::train::INFO] [Train] Iter 1382 | Loss 0.036265 | Grad 0.0516 \n","[2023-12-09 07:30:37,284::train::INFO] [Train] Iter 1383 | Loss 0.035552 | Grad 0.0696 \n","[2023-12-09 07:30:37,376::train::INFO] [Train] Iter 1384 | Loss 0.036071 | Grad 0.0934 \n","[2023-12-09 07:30:37,469::train::INFO] [Train] Iter 1385 | Loss 0.034977 | Grad 0.0586 \n","[2023-12-09 07:30:37,563::train::INFO] [Train] Iter 1386 | Loss 0.035444 | Grad 0.0535 \n","[2023-12-09 07:30:37,658::train::INFO] [Train] Iter 1387 | Loss 0.037053 | Grad 0.0635 \n","[2023-12-09 07:30:37,748::train::INFO] [Train] Iter 1388 | Loss 0.035791 | Grad 0.0665 \n","[2023-12-09 07:30:37,832::train::INFO] [Train] Iter 1389 | Loss 0.034949 | Grad 0.0669 \n","[2023-12-09 07:30:37,916::train::INFO] [Train] Iter 1390 | Loss 0.035585 | Grad 0.0625 \n","[2023-12-09 07:30:38,000::train::INFO] [Train] Iter 1391 | Loss 0.036810 | Grad 0.0619 \n","[2023-12-09 07:30:38,085::train::INFO] [Train] Iter 1392 | Loss 0.034108 | Grad 0.0546 \n","[2023-12-09 07:30:38,168::train::INFO] [Train] Iter 1393 | Loss 0.036404 | Grad 0.0937 \n","[2023-12-09 07:30:38,254::train::INFO] [Train] Iter 1394 | Loss 0.035244 | Grad 0.0533 \n","[2023-12-09 07:30:38,337::train::INFO] [Train] Iter 1395 | Loss 0.033806 | Grad 0.0870 \n","[2023-12-09 07:30:38,421::train::INFO] [Train] Iter 1396 | Loss 0.036883 | Grad 0.0577 \n","[2023-12-09 07:30:38,510::train::INFO] [Train] Iter 1397 | Loss 0.035354 | Grad 0.0599 \n","[2023-12-09 07:30:38,594::train::INFO] [Train] Iter 1398 | Loss 0.036797 | Grad 0.0548 \n","[2023-12-09 07:30:38,677::train::INFO] [Train] Iter 1399 | Loss 0.034484 | Grad 0.0701 \n","[2023-12-09 07:30:38,760::train::INFO] [Train] Iter 1400 | Loss 0.035564 | Grad 0.0719 \n","[2023-12-09 07:30:38,842::train::INFO] [Train] Iter 1401 | Loss 0.035487 | Grad 0.0806 \n","[2023-12-09 07:30:38,929::train::INFO] [Train] Iter 1402 | Loss 0.035126 | Grad 0.0629 \n","[2023-12-09 07:30:39,013::train::INFO] [Train] Iter 1403 | Loss 0.035590 | Grad 0.0879 \n","[2023-12-09 07:30:39,097::train::INFO] [Train] Iter 1404 | Loss 0.033991 | Grad 0.0417 \n","[2023-12-09 07:30:39,182::train::INFO] [Train] Iter 1405 | Loss 0.035428 | Grad 0.0567 \n","[2023-12-09 07:30:39,265::train::INFO] [Train] Iter 1406 | Loss 0.035752 | Grad 0.0926 \n","[2023-12-09 07:30:39,349::train::INFO] [Train] Iter 1407 | Loss 0.033756 | Grad 0.0842 \n","[2023-12-09 07:30:39,442::train::INFO] [Train] Iter 1408 | Loss 0.033991 | Grad 0.0983 \n","[2023-12-09 07:30:39,529::train::INFO] [Train] Iter 1409 | Loss 0.036451 | Grad 0.1054 \n","[2023-12-09 07:30:39,613::train::INFO] [Train] Iter 1410 | Loss 0.034537 | Grad 0.0865 \n","[2023-12-09 07:30:39,696::train::INFO] [Train] Iter 1411 | Loss 0.037914 | Grad 0.1010 \n","[2023-12-09 07:30:39,780::train::INFO] [Train] Iter 1412 | Loss 0.034834 | Grad 0.0777 \n","[2023-12-09 07:30:39,863::train::INFO] [Train] Iter 1413 | Loss 0.035019 | Grad 0.0925 \n","[2023-12-09 07:30:39,947::train::INFO] [Train] Iter 1414 | Loss 0.034253 | Grad 0.0748 \n","[2023-12-09 07:30:40,031::train::INFO] [Train] Iter 1415 | Loss 0.035636 | Grad 0.0617 \n","[2023-12-09 07:30:40,116::train::INFO] [Train] Iter 1416 | Loss 0.037510 | Grad 0.0454 \n","[2023-12-09 07:30:40,199::train::INFO] [Train] Iter 1417 | Loss 0.034842 | Grad 0.0567 \n","[2023-12-09 07:30:40,284::train::INFO] [Train] Iter 1418 | Loss 0.034951 | Grad 0.0582 \n","[2023-12-09 07:30:40,367::train::INFO] [Train] Iter 1419 | Loss 0.034148 | Grad 0.0502 \n","[2023-12-09 07:30:40,450::train::INFO] [Train] Iter 1420 | Loss 0.033341 | Grad 0.0566 \n","[2023-12-09 07:30:40,533::train::INFO] [Train] Iter 1421 | Loss 0.035847 | Grad 0.0775 \n","[2023-12-09 07:30:40,620::train::INFO] [Train] Iter 1422 | Loss 0.037626 | Grad 0.0648 \n","[2023-12-09 07:30:40,704::train::INFO] [Train] Iter 1423 | Loss 0.035040 | Grad 0.0468 \n","[2023-12-09 07:30:40,788::train::INFO] [Train] Iter 1424 | Loss 0.036321 | Grad 0.0790 \n","[2023-12-09 07:30:40,871::train::INFO] [Train] Iter 1425 | Loss 0.036551 | Grad 0.0644 \n","[2023-12-09 07:30:40,956::train::INFO] [Train] Iter 1426 | Loss 0.034710 | Grad 0.0803 \n","[2023-12-09 07:30:41,040::train::INFO] [Train] Iter 1427 | Loss 0.035523 | Grad 0.0512 \n","[2023-12-09 07:30:41,124::train::INFO] [Train] Iter 1428 | Loss 0.033593 | Grad 0.0687 \n","[2023-12-09 07:30:41,216::train::INFO] [Train] Iter 1429 | Loss 0.034623 | Grad 0.0493 \n","[2023-12-09 07:30:41,299::train::INFO] [Train] Iter 1430 | Loss 0.034664 | Grad 0.0694 \n","[2023-12-09 07:30:41,383::train::INFO] [Train] Iter 1431 | Loss 0.035128 | Grad 0.0682 \n","[2023-12-09 07:30:41,466::train::INFO] [Train] Iter 1432 | Loss 0.034435 | Grad 0.0678 \n","[2023-12-09 07:30:41,549::train::INFO] [Train] Iter 1433 | Loss 0.035306 | Grad 0.0706 \n","[2023-12-09 07:30:41,633::train::INFO] [Train] Iter 1434 | Loss 0.034559 | Grad 0.0733 \n","[2023-12-09 07:30:41,719::train::INFO] [Train] Iter 1435 | Loss 0.035475 | Grad 0.0723 \n","[2023-12-09 07:30:41,803::train::INFO] [Train] Iter 1436 | Loss 0.034041 | Grad 0.0734 \n","[2023-12-09 07:30:41,887::train::INFO] [Train] Iter 1437 | Loss 0.034377 | Grad 0.0734 \n","[2023-12-09 07:30:41,971::train::INFO] [Train] Iter 1438 | Loss 0.034123 | Grad 0.0998 \n","[2023-12-09 07:30:42,057::train::INFO] [Train] Iter 1439 | Loss 0.035131 | Grad 0.0672 \n","[2023-12-09 07:30:42,140::train::INFO] [Train] Iter 1440 | Loss 0.034123 | Grad 0.0978 \n","[2023-12-09 07:30:42,227::train::INFO] [Train] Iter 1441 | Loss 0.035060 | Grad 0.0583 \n","[2023-12-09 07:30:42,311::train::INFO] [Train] Iter 1442 | Loss 0.033251 | Grad 0.0513 \n","[2023-12-09 07:30:42,396::train::INFO] [Train] Iter 1443 | Loss 0.033770 | Grad 0.0699 \n","[2023-12-09 07:30:42,479::train::INFO] [Train] Iter 1444 | Loss 0.035848 | Grad 0.0645 \n","[2023-12-09 07:30:42,563::train::INFO] [Train] Iter 1445 | Loss 0.036127 | Grad 0.0927 \n","[2023-12-09 07:30:42,646::train::INFO] [Train] Iter 1446 | Loss 0.035208 | Grad 0.0599 \n","[2023-12-09 07:30:42,730::train::INFO] [Train] Iter 1447 | Loss 0.035193 | Grad 0.0659 \n","[2023-12-09 07:30:42,813::train::INFO] [Train] Iter 1448 | Loss 0.035164 | Grad 0.0600 \n","[2023-12-09 07:30:42,897::train::INFO] [Train] Iter 1449 | Loss 0.034656 | Grad 0.0576 \n","[2023-12-09 07:30:42,981::train::INFO] [Train] Iter 1450 | Loss 0.036374 | Grad 0.1082 \n","[2023-12-09 07:30:43,067::train::INFO] [Train] Iter 1451 | Loss 0.033947 | Grad 0.0587 \n","[2023-12-09 07:30:43,151::train::INFO] [Train] Iter 1452 | Loss 0.034540 | Grad 0.0593 \n","[2023-12-09 07:30:43,244::train::INFO] [Train] Iter 1453 | Loss 0.034527 | Grad 0.0392 \n","[2023-12-09 07:30:43,328::train::INFO] [Train] Iter 1454 | Loss 0.034642 | Grad 0.0772 \n","[2023-12-09 07:30:43,412::train::INFO] [Train] Iter 1455 | Loss 0.036825 | Grad 0.0731 \n","[2023-12-09 07:30:43,497::train::INFO] [Train] Iter 1456 | Loss 0.031897 | Grad 0.0847 \n","[2023-12-09 07:30:43,581::train::INFO] [Train] Iter 1457 | Loss 0.034694 | Grad 0.0471 \n","[2023-12-09 07:30:43,667::train::INFO] [Train] Iter 1458 | Loss 0.034330 | Grad 0.0636 \n","[2023-12-09 07:30:43,750::train::INFO] [Train] Iter 1459 | Loss 0.033567 | Grad 0.0819 \n","[2023-12-09 07:30:43,838::train::INFO] [Train] Iter 1460 | Loss 0.036139 | Grad 0.0622 \n","[2023-12-09 07:30:43,923::train::INFO] [Train] Iter 1461 | Loss 0.034802 | Grad 0.0432 \n","[2023-12-09 07:30:44,006::train::INFO] [Train] Iter 1462 | Loss 0.034560 | Grad 0.0425 \n","[2023-12-09 07:30:44,093::train::INFO] [Train] Iter 1463 | Loss 0.034673 | Grad 0.0578 \n","[2023-12-09 07:30:44,176::train::INFO] [Train] Iter 1464 | Loss 0.034326 | Grad 0.0415 \n","[2023-12-09 07:30:44,265::train::INFO] [Train] Iter 1465 | Loss 0.034835 | Grad 0.0586 \n","[2023-12-09 07:30:44,349::train::INFO] [Train] Iter 1466 | Loss 0.035267 | Grad 0.0592 \n","[2023-12-09 07:30:44,438::train::INFO] [Train] Iter 1467 | Loss 0.032926 | Grad 0.0764 \n","[2023-12-09 07:30:44,522::train::INFO] [Train] Iter 1468 | Loss 0.035070 | Grad 0.0527 \n","[2023-12-09 07:30:44,607::train::INFO] [Train] Iter 1469 | Loss 0.037101 | Grad 0.0705 \n","[2023-12-09 07:30:44,694::train::INFO] [Train] Iter 1470 | Loss 0.034267 | Grad 0.0514 \n","[2023-12-09 07:30:44,778::train::INFO] [Train] Iter 1471 | Loss 0.035764 | Grad 0.0446 \n","[2023-12-09 07:30:44,863::train::INFO] [Train] Iter 1472 | Loss 0.034002 | Grad 0.0613 \n","[2023-12-09 07:30:44,948::train::INFO] [Train] Iter 1473 | Loss 0.034082 | Grad 0.0607 \n","[2023-12-09 07:30:45,032::train::INFO] [Train] Iter 1474 | Loss 0.035054 | Grad 0.0635 \n","[2023-12-09 07:30:45,116::train::INFO] [Train] Iter 1475 | Loss 0.034006 | Grad 0.0644 \n","[2023-12-09 07:30:45,200::train::INFO] [Train] Iter 1476 | Loss 0.034951 | Grad 0.0529 \n","[2023-12-09 07:30:45,292::train::INFO] [Train] Iter 1477 | Loss 0.034917 | Grad 0.0372 \n","[2023-12-09 07:30:45,377::train::INFO] [Train] Iter 1478 | Loss 0.034001 | Grad 0.0725 \n","[2023-12-09 07:30:45,463::train::INFO] [Train] Iter 1479 | Loss 0.031683 | Grad 0.0840 \n","[2023-12-09 07:30:45,548::train::INFO] [Train] Iter 1480 | Loss 0.035339 | Grad 0.0497 \n","[2023-12-09 07:30:45,633::train::INFO] [Train] Iter 1481 | Loss 0.033931 | Grad 0.0493 \n","[2023-12-09 07:30:45,717::train::INFO] [Train] Iter 1482 | Loss 0.032899 | Grad 0.0676 \n","[2023-12-09 07:30:45,802::train::INFO] [Train] Iter 1483 | Loss 0.032700 | Grad 0.0609 \n","[2023-12-09 07:30:45,886::train::INFO] [Train] Iter 1484 | Loss 0.034666 | Grad 0.0845 \n","[2023-12-09 07:30:45,969::train::INFO] [Train] Iter 1485 | Loss 0.034692 | Grad 0.0543 \n","[2023-12-09 07:30:46,052::train::INFO] [Train] Iter 1486 | Loss 0.034284 | Grad 0.0745 \n","[2023-12-09 07:30:46,136::train::INFO] [Train] Iter 1487 | Loss 0.033179 | Grad 0.0391 \n","[2023-12-09 07:30:46,219::train::INFO] [Train] Iter 1488 | Loss 0.034834 | Grad 0.0446 \n","[2023-12-09 07:30:46,307::train::INFO] [Train] Iter 1489 | Loss 0.035123 | Grad 0.0675 \n","[2023-12-09 07:30:46,394::train::INFO] [Train] Iter 1490 | Loss 0.032633 | Grad 0.0678 \n","[2023-12-09 07:30:46,477::train::INFO] [Train] Iter 1491 | Loss 0.035181 | Grad 0.0533 \n","[2023-12-09 07:30:46,561::train::INFO] [Train] Iter 1492 | Loss 0.034947 | Grad 0.0657 \n","[2023-12-09 07:30:46,645::train::INFO] [Train] Iter 1493 | Loss 0.033865 | Grad 0.0477 \n","[2023-12-09 07:30:46,729::train::INFO] [Train] Iter 1494 | Loss 0.033271 | Grad 0.0927 \n","[2023-12-09 07:30:46,816::train::INFO] [Train] Iter 1495 | Loss 0.033313 | Grad 0.0673 \n","[2023-12-09 07:30:46,902::train::INFO] [Train] Iter 1496 | Loss 0.033193 | Grad 0.1073 \n","[2023-12-09 07:30:46,986::train::INFO] [Train] Iter 1497 | Loss 0.033771 | Grad 0.1088 \n","[2023-12-09 07:30:47,070::train::INFO] [Train] Iter 1498 | Loss 0.033422 | Grad 0.0723 \n","[2023-12-09 07:30:47,155::train::INFO] [Train] Iter 1499 | Loss 0.034675 | Grad 0.0851 \n","[2023-12-09 07:30:47,242::train::INFO] [Train] Iter 1500 | Loss 0.034630 | Grad 0.1161 \n","Validate: 100% 241/241 [00:04<00:00, 48.70it/s]\n","val loss list [tensor(0.0364, device='cuda:0'), tensor(0.0335, device='cuda:0'), tensor(0.0350, device='cuda:0'), tensor(0.0327, device='cuda:0'), tensor(0.0313, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0339, device='cuda:0'), tensor(0.0376, device='cuda:0'), tensor(0.0351, device='cuda:0'), tensor(0.0317, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0329, device='cuda:0'), tensor(0.0327, device='cuda:0'), tensor(0.0339, device='cuda:0'), tensor(0.0353, device='cuda:0'), tensor(0.0361, device='cuda:0'), tensor(0.0321, device='cuda:0'), tensor(0.0358, device='cuda:0'), tensor(0.0367, device='cuda:0'), tensor(0.0367, device='cuda:0'), tensor(0.0345, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0361, device='cuda:0'), tensor(0.0338, device='cuda:0'), tensor(0.0313, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0348, device='cuda:0'), tensor(0.0348, device='cuda:0'), tensor(0.0319, device='cuda:0'), tensor(0.0372, device='cuda:0'), tensor(0.0347, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0378, device='cuda:0'), tensor(0.0331, device='cuda:0'), tensor(0.0349, device='cuda:0'), tensor(0.0344, device='cuda:0'), tensor(0.0337, device='cuda:0'), tensor(0.0347, device='cuda:0'), tensor(0.0325, device='cuda:0'), tensor(0.0331, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0328, device='cuda:0'), tensor(0.0337, device='cuda:0'), tensor(0.0372, device='cuda:0'), tensor(0.0379, device='cuda:0'), tensor(0.0345, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0373, device='cuda:0'), tensor(0.0344, device='cuda:0'), tensor(0.0356, device='cuda:0'), tensor(0.0340, device='cuda:0'), tensor(0.0358, device='cuda:0'), tensor(0.0336, device='cuda:0'), tensor(0.0330, device='cuda:0'), tensor(0.0376, device='cuda:0'), tensor(0.0353, device='cuda:0'), tensor(0.0344, device='cuda:0'), tensor(0.0350, device='cuda:0'), tensor(0.0360, device='cuda:0'), tensor(0.0375, device='cuda:0'), tensor(0.0352, device='cuda:0'), tensor(0.0386, device='cuda:0'), tensor(0.0387, device='cuda:0'), tensor(0.0357, device='cuda:0'), tensor(0.0347, device='cuda:0'), tensor(0.0312, device='cuda:0'), tensor(0.0331, device='cuda:0'), tensor(0.0331, device='cuda:0'), tensor(0.0358, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0363, device='cuda:0'), tensor(0.0334, device='cuda:0'), tensor(0.0340, device='cuda:0'), tensor(0.0339, device='cuda:0'), tensor(0.0353, device='cuda:0'), tensor(0.0355, device='cuda:0'), tensor(0.0356, device='cuda:0'), tensor(0.0358, device='cuda:0'), tensor(0.0370, device='cuda:0'), tensor(0.0340, device='cuda:0'), tensor(0.0361, device='cuda:0'), tensor(0.0343, device='cuda:0'), tensor(0.0343, device='cuda:0'), tensor(0.0337, device='cuda:0'), tensor(0.0347, device='cuda:0'), tensor(0.0397, device='cuda:0'), tensor(0.0334, device='cuda:0'), tensor(0.0359, device='cuda:0'), tensor(0.0343, device='cuda:0'), tensor(0.0370, device='cuda:0'), tensor(0.0331, device='cuda:0'), tensor(0.0379, device='cuda:0'), tensor(0.0335, device='cuda:0'), tensor(0.0341, device='cuda:0'), tensor(0.0366, device='cuda:0'), tensor(0.0322, device='cuda:0'), tensor(0.0349, device='cuda:0'), tensor(0.0311, device='cuda:0'), tensor(0.0354, device='cuda:0'), tensor(0.0317, device='cuda:0'), tensor(0.0345, device='cuda:0'), tensor(0.0345, device='cuda:0'), tensor(0.0331, device='cuda:0'), tensor(0.0354, device='cuda:0'), tensor(0.0320, device='cuda:0'), tensor(0.0312, device='cuda:0'), tensor(0.0328, device='cuda:0'), tensor(0.0339, device='cuda:0'), tensor(0.0357, device='cuda:0'), tensor(0.0321, device='cuda:0'), tensor(0.0331, device='cuda:0'), tensor(0.0331, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0347, device='cuda:0'), tensor(0.0346, device='cuda:0'), tensor(0.0329, device='cuda:0'), tensor(0.0358, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0333, device='cuda:0'), tensor(0.0375, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0335, device='cuda:0'), tensor(0.0355, device='cuda:0'), tensor(0.0319, device='cuda:0'), tensor(0.0343, device='cuda:0'), tensor(0.0343, device='cuda:0'), tensor(0.0330, device='cuda:0'), tensor(0.0346, device='cuda:0'), tensor(0.0332, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0365, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0383, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0339, device='cuda:0'), tensor(0.0357, device='cuda:0'), tensor(0.0345, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0343, device='cuda:0'), tensor(0.0320, device='cuda:0'), tensor(0.0357, device='cuda:0'), tensor(0.0330, device='cuda:0'), tensor(0.0349, device='cuda:0'), tensor(0.0341, device='cuda:0'), tensor(0.0356, device='cuda:0'), tensor(0.0346, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0337, device='cuda:0'), tensor(0.0354, device='cuda:0'), tensor(0.0350, device='cuda:0'), tensor(0.0343, device='cuda:0'), tensor(0.0394, device='cuda:0'), tensor(0.0344, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0329, device='cuda:0'), tensor(0.0325, device='cuda:0'), tensor(0.0369, device='cuda:0'), tensor(0.0375, device='cuda:0'), tensor(0.0383, device='cuda:0'), tensor(0.0366, device='cuda:0'), tensor(0.0355, device='cuda:0'), tensor(0.0357, device='cuda:0'), tensor(0.0313, device='cuda:0'), tensor(0.0355, device='cuda:0'), tensor(0.0340, device='cuda:0'), tensor(0.0380, device='cuda:0'), tensor(0.0333, device='cuda:0'), tensor(0.0325, device='cuda:0'), tensor(0.0361, device='cuda:0'), tensor(0.0346, device='cuda:0'), tensor(0.0349, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0338, device='cuda:0'), tensor(0.0381, device='cuda:0'), tensor(0.0365, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0341, device='cuda:0'), tensor(0.0357, device='cuda:0'), tensor(0.0319, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0367, device='cuda:0'), tensor(0.0339, device='cuda:0'), tensor(0.0393, device='cuda:0'), tensor(0.0340, device='cuda:0'), tensor(0.0320, device='cuda:0'), tensor(0.0375, device='cuda:0'), tensor(0.0333, device='cuda:0'), tensor(0.0365, device='cuda:0'), tensor(0.0346, device='cuda:0'), tensor(0.0340, device='cuda:0'), tensor(0.0344, device='cuda:0'), tensor(0.0330, device='cuda:0'), tensor(0.0325, device='cuda:0'), tensor(0.0354, device='cuda:0'), tensor(0.0331, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0389, device='cuda:0'), tensor(0.0331, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0348, device='cuda:0'), tensor(0.0386, device='cuda:0'), tensor(0.0367, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0372, device='cuda:0'), tensor(0.0315, device='cuda:0'), tensor(0.0335, device='cuda:0'), tensor(0.0354, device='cuda:0'), tensor(0.0353, device='cuda:0'), tensor(0.0337, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0332, device='cuda:0'), tensor(0.0349, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0337, device='cuda:0'), tensor(0.0374, device='cuda:0'), tensor(0.0374, device='cuda:0'), tensor(0.0334, device='cuda:0'), tensor(0.0337, device='cuda:0'), tensor(0.0357, device='cuda:0'), tensor(0.0336, device='cuda:0'), tensor(0.0358, device='cuda:0'), tensor(0.0363, device='cuda:0'), tensor(0.0338, device='cuda:0'), tensor(0.0364, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0339, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0325, device='cuda:0'), tensor(0.0349, device='cuda:0'), tensor(0.0359, device='cuda:0'), tensor(0.0380, device='cuda:0'), tensor(0.0367, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0320, device='cuda:0'), tensor(0.0322, device='cuda:0'), tensor(0.0354, device='cuda:0'), tensor(0.0336, device='cuda:0'), tensor(0.0366, device='cuda:0')]\n","[2023-12-09 07:30:52,500::train::INFO] [Train] Iter 1501 | Loss 0.035352 | Grad 0.1032 \n","[2023-12-09 07:30:52,593::train::INFO] [Train] Iter 1502 | Loss 0.033782 | Grad 0.0481 \n","[2023-12-09 07:30:52,684::train::INFO] [Train] Iter 1503 | Loss 0.036481 | Grad 0.0820 \n","[2023-12-09 07:30:52,775::train::INFO] [Train] Iter 1504 | Loss 0.035214 | Grad 0.1029 \n","[2023-12-09 07:30:52,866::train::INFO] [Train] Iter 1505 | Loss 0.037036 | Grad 0.0915 \n","[2023-12-09 07:30:52,960::train::INFO] [Train] Iter 1506 | Loss 0.035380 | Grad 0.0964 \n","[2023-12-09 07:30:53,054::train::INFO] [Train] Iter 1507 | Loss 0.034272 | Grad 0.0571 \n","[2023-12-09 07:30:53,147::train::INFO] [Train] Iter 1508 | Loss 0.035085 | Grad 0.1026 \n","[2023-12-09 07:30:53,239::train::INFO] [Train] Iter 1509 | Loss 0.035506 | Grad 0.1041 \n","[2023-12-09 07:30:53,331::train::INFO] [Train] Iter 1510 | Loss 0.036339 | Grad 0.0891 \n","[2023-12-09 07:30:53,422::train::INFO] [Train] Iter 1511 | Loss 0.036310 | Grad 0.0604 \n","[2023-12-09 07:30:53,513::train::INFO] [Train] Iter 1512 | Loss 0.035685 | Grad 0.0725 \n","[2023-12-09 07:30:53,604::train::INFO] [Train] Iter 1513 | Loss 0.033641 | Grad 0.0758 \n","[2023-12-09 07:30:53,700::train::INFO] [Train] Iter 1514 | Loss 0.033798 | Grad 0.1138 \n","[2023-12-09 07:30:53,789::train::INFO] [Train] Iter 1515 | Loss 0.034328 | Grad 0.0569 \n","[2023-12-09 07:30:53,882::train::INFO] [Train] Iter 1516 | Loss 0.034717 | Grad 0.0605 \n","[2023-12-09 07:30:53,974::train::INFO] [Train] Iter 1517 | Loss 0.032686 | Grad 0.0978 \n","[2023-12-09 07:30:54,063::train::INFO] [Train] Iter 1518 | Loss 0.034117 | Grad 0.1189 \n","[2023-12-09 07:30:54,152::train::INFO] [Train] Iter 1519 | Loss 0.032988 | Grad 0.0778 \n","[2023-12-09 07:30:54,261::train::INFO] [Train] Iter 1520 | Loss 0.033609 | Grad 0.0552 \n","[2023-12-09 07:30:54,353::train::INFO] [Train] Iter 1521 | Loss 0.033901 | Grad 0.1255 \n","[2023-12-09 07:30:54,446::train::INFO] [Train] Iter 1522 | Loss 0.034278 | Grad 0.0911 \n","[2023-12-09 07:30:54,530::train::INFO] [Train] Iter 1523 | Loss 0.036176 | Grad 0.1033 \n","[2023-12-09 07:30:54,615::train::INFO] [Train] Iter 1524 | Loss 0.035225 | Grad 0.0688 \n","[2023-12-09 07:30:54,698::train::INFO] [Train] Iter 1525 | Loss 0.033793 | Grad 0.0985 \n","[2023-12-09 07:30:54,782::train::INFO] [Train] Iter 1526 | Loss 0.034842 | Grad 0.1071 \n","[2023-12-09 07:30:54,866::train::INFO] [Train] Iter 1527 | Loss 0.033656 | Grad 0.0651 \n","[2023-12-09 07:30:54,952::train::INFO] [Train] Iter 1528 | Loss 0.034585 | Grad 0.0572 \n","[2023-12-09 07:30:55,037::train::INFO] [Train] Iter 1529 | Loss 0.032056 | Grad 0.0759 \n","[2023-12-09 07:30:55,120::train::INFO] [Train] Iter 1530 | Loss 0.032945 | Grad 0.0750 \n","[2023-12-09 07:30:55,204::train::INFO] [Train] Iter 1531 | Loss 0.033252 | Grad 0.0760 \n","[2023-12-09 07:30:55,288::train::INFO] [Train] Iter 1532 | Loss 0.036326 | Grad 0.0541 \n","[2023-12-09 07:30:55,374::train::INFO] [Train] Iter 1533 | Loss 0.036224 | Grad 0.0884 \n","[2023-12-09 07:30:55,458::train::INFO] [Train] Iter 1534 | Loss 0.034202 | Grad 0.0595 \n","[2023-12-09 07:30:55,541::train::INFO] [Train] Iter 1535 | Loss 0.033925 | Grad 0.0459 \n","[2023-12-09 07:30:55,625::train::INFO] [Train] Iter 1536 | Loss 0.032659 | Grad 0.0589 \n","[2023-12-09 07:30:55,712::train::INFO] [Train] Iter 1537 | Loss 0.032564 | Grad 0.0345 \n","[2023-12-09 07:30:55,799::train::INFO] [Train] Iter 1538 | Loss 0.032152 | Grad 0.0780 \n","[2023-12-09 07:30:55,884::train::INFO] [Train] Iter 1539 | Loss 0.031869 | Grad 0.0484 \n","[2023-12-09 07:30:55,969::train::INFO] [Train] Iter 1540 | Loss 0.034211 | Grad 0.0587 \n","[2023-12-09 07:30:56,053::train::INFO] [Train] Iter 1541 | Loss 0.035947 | Grad 0.0803 \n","[2023-12-09 07:30:56,141::train::INFO] [Train] Iter 1542 | Loss 0.032897 | Grad 0.0554 \n","[2023-12-09 07:30:56,224::train::INFO] [Train] Iter 1543 | Loss 0.032071 | Grad 0.0681 \n","[2023-12-09 07:30:56,309::train::INFO] [Train] Iter 1544 | Loss 0.034950 | Grad 0.0842 \n","[2023-12-09 07:30:56,393::train::INFO] [Train] Iter 1545 | Loss 0.032774 | Grad 0.0516 \n","[2023-12-09 07:30:56,476::train::INFO] [Train] Iter 1546 | Loss 0.034890 | Grad 0.0486 \n","[2023-12-09 07:30:56,560::train::INFO] [Train] Iter 1547 | Loss 0.032195 | Grad 0.0376 \n","[2023-12-09 07:30:56,644::train::INFO] [Train] Iter 1548 | Loss 0.034428 | Grad 0.0392 \n","[2023-12-09 07:30:56,727::train::INFO] [Train] Iter 1549 | Loss 0.033824 | Grad 0.0685 \n","[2023-12-09 07:30:56,811::train::INFO] [Train] Iter 1550 | Loss 0.034458 | Grad 0.0576 \n","[2023-12-09 07:30:56,897::train::INFO] [Train] Iter 1551 | Loss 0.035223 | Grad 0.0810 \n","[2023-12-09 07:30:56,983::train::INFO] [Train] Iter 1552 | Loss 0.033591 | Grad 0.0828 \n","[2023-12-09 07:30:57,068::train::INFO] [Train] Iter 1553 | Loss 0.033342 | Grad 0.0530 \n","[2023-12-09 07:30:57,152::train::INFO] [Train] Iter 1554 | Loss 0.033170 | Grad 0.0351 \n","[2023-12-09 07:30:57,235::train::INFO] [Train] Iter 1555 | Loss 0.035102 | Grad 0.0546 \n","[2023-12-09 07:30:57,319::train::INFO] [Train] Iter 1556 | Loss 0.035100 | Grad 0.0535 \n","[2023-12-09 07:30:57,405::train::INFO] [Train] Iter 1557 | Loss 0.033193 | Grad 0.0628 \n","[2023-12-09 07:30:57,489::train::INFO] [Train] Iter 1558 | Loss 0.032554 | Grad 0.0855 \n","[2023-12-09 07:30:57,573::train::INFO] [Train] Iter 1559 | Loss 0.034413 | Grad 0.0651 \n","[2023-12-09 07:30:57,658::train::INFO] [Train] Iter 1560 | Loss 0.032114 | Grad 0.0529 \n","[2023-12-09 07:30:57,741::train::INFO] [Train] Iter 1561 | Loss 0.032730 | Grad 0.0649 \n","[2023-12-09 07:30:57,827::train::INFO] [Train] Iter 1562 | Loss 0.034052 | Grad 0.0591 \n","[2023-12-09 07:30:57,912::train::INFO] [Train] Iter 1563 | Loss 0.034685 | Grad 0.0621 \n","[2023-12-09 07:30:57,996::train::INFO] [Train] Iter 1564 | Loss 0.033221 | Grad 0.0747 \n","[2023-12-09 07:30:58,080::train::INFO] [Train] Iter 1565 | Loss 0.033683 | Grad 0.0569 \n","[2023-12-09 07:30:58,165::train::INFO] [Train] Iter 1566 | Loss 0.033154 | Grad 0.0641 \n","[2023-12-09 07:30:58,249::train::INFO] [Train] Iter 1567 | Loss 0.033249 | Grad 0.0338 \n","[2023-12-09 07:30:58,334::train::INFO] [Train] Iter 1568 | Loss 0.033605 | Grad 0.0669 \n","[2023-12-09 07:30:58,419::train::INFO] [Train] Iter 1569 | Loss 0.032226 | Grad 0.0596 \n","[2023-12-09 07:30:58,503::train::INFO] [Train] Iter 1570 | Loss 0.036379 | Grad 0.0631 \n","[2023-12-09 07:30:58,586::train::INFO] [Train] Iter 1571 | Loss 0.035441 | Grad 0.0598 \n","[2023-12-09 07:30:58,669::train::INFO] [Train] Iter 1572 | Loss 0.032885 | Grad 0.0593 \n","[2023-12-09 07:30:58,752::train::INFO] [Train] Iter 1573 | Loss 0.033679 | Grad 0.0580 \n","[2023-12-09 07:30:58,837::train::INFO] [Train] Iter 1574 | Loss 0.034893 | Grad 0.0593 \n","[2023-12-09 07:30:58,921::train::INFO] [Train] Iter 1575 | Loss 0.032489 | Grad 0.0453 \n","[2023-12-09 07:30:59,005::train::INFO] [Train] Iter 1576 | Loss 0.034758 | Grad 0.0672 \n","[2023-12-09 07:30:59,095::train::INFO] [Train] Iter 1577 | Loss 0.033359 | Grad 0.0498 \n","[2023-12-09 07:30:59,178::train::INFO] [Train] Iter 1578 | Loss 0.035820 | Grad 0.0517 \n","[2023-12-09 07:30:59,262::train::INFO] [Train] Iter 1579 | Loss 0.032819 | Grad 0.0427 \n","[2023-12-09 07:30:59,345::train::INFO] [Train] Iter 1580 | Loss 0.034784 | Grad 0.0871 \n","[2023-12-09 07:30:59,430::train::INFO] [Train] Iter 1581 | Loss 0.032882 | Grad 0.0540 \n","[2023-12-09 07:30:59,516::train::INFO] [Train] Iter 1582 | Loss 0.032497 | Grad 0.0478 \n","[2023-12-09 07:30:59,601::train::INFO] [Train] Iter 1583 | Loss 0.033244 | Grad 0.0489 \n","[2023-12-09 07:30:59,685::train::INFO] [Train] Iter 1584 | Loss 0.034270 | Grad 0.0887 \n","[2023-12-09 07:30:59,769::train::INFO] [Train] Iter 1585 | Loss 0.033366 | Grad 0.0532 \n","[2023-12-09 07:30:59,857::train::INFO] [Train] Iter 1586 | Loss 0.034331 | Grad 0.0425 \n","[2023-12-09 07:30:59,940::train::INFO] [Train] Iter 1587 | Loss 0.033967 | Grad 0.0427 \n","[2023-12-09 07:31:00,028::train::INFO] [Train] Iter 1588 | Loss 0.031546 | Grad 0.0439 \n","[2023-12-09 07:31:00,111::train::INFO] [Train] Iter 1589 | Loss 0.034821 | Grad 0.0752 \n","[2023-12-09 07:31:00,195::train::INFO] [Train] Iter 1590 | Loss 0.031818 | Grad 0.0501 \n","[2023-12-09 07:31:00,278::train::INFO] [Train] Iter 1591 | Loss 0.034229 | Grad 0.0478 \n","[2023-12-09 07:31:00,362::train::INFO] [Train] Iter 1592 | Loss 0.033523 | Grad 0.0494 \n","[2023-12-09 07:31:00,446::train::INFO] [Train] Iter 1593 | Loss 0.035165 | Grad 0.0506 \n","[2023-12-09 07:31:00,529::train::INFO] [Train] Iter 1594 | Loss 0.033086 | Grad 0.0453 \n","[2023-12-09 07:31:00,613::train::INFO] [Train] Iter 1595 | Loss 0.033516 | Grad 0.0572 \n","[2023-12-09 07:31:00,697::train::INFO] [Train] Iter 1596 | Loss 0.033892 | Grad 0.0625 \n","[2023-12-09 07:31:00,782::train::INFO] [Train] Iter 1597 | Loss 0.033291 | Grad 0.0652 \n","[2023-12-09 07:31:00,873::train::INFO] [Train] Iter 1598 | Loss 0.032472 | Grad 0.0496 \n","[2023-12-09 07:31:00,957::train::INFO] [Train] Iter 1599 | Loss 0.033062 | Grad 0.0454 \n","[2023-12-09 07:31:01,043::train::INFO] [Train] Iter 1600 | Loss 0.032825 | Grad 0.0355 \n","[2023-12-09 07:31:01,126::train::INFO] [Train] Iter 1601 | Loss 0.034286 | Grad 0.0563 \n","[2023-12-09 07:31:01,211::train::INFO] [Train] Iter 1602 | Loss 0.032361 | Grad 0.0748 \n","[2023-12-09 07:31:01,295::train::INFO] [Train] Iter 1603 | Loss 0.033518 | Grad 0.0615 \n","[2023-12-09 07:31:01,378::train::INFO] [Train] Iter 1604 | Loss 0.035300 | Grad 0.0403 \n","[2023-12-09 07:31:01,462::train::INFO] [Train] Iter 1605 | Loss 0.034535 | Grad 0.0540 \n","[2023-12-09 07:31:01,546::train::INFO] [Train] Iter 1606 | Loss 0.032547 | Grad 0.0428 \n","[2023-12-09 07:31:01,634::train::INFO] [Train] Iter 1607 | Loss 0.031209 | Grad 0.0707 \n","[2023-12-09 07:31:01,718::train::INFO] [Train] Iter 1608 | Loss 0.033795 | Grad 0.0541 \n","[2023-12-09 07:31:01,805::train::INFO] [Train] Iter 1609 | Loss 0.031425 | Grad 0.0509 \n","[2023-12-09 07:31:01,892::train::INFO] [Train] Iter 1610 | Loss 0.031749 | Grad 0.0719 \n","[2023-12-09 07:31:01,975::train::INFO] [Train] Iter 1611 | Loss 0.032935 | Grad 0.0402 \n","[2023-12-09 07:31:02,061::train::INFO] [Train] Iter 1612 | Loss 0.033026 | Grad 0.0570 \n","[2023-12-09 07:31:02,144::train::INFO] [Train] Iter 1613 | Loss 0.034617 | Grad 0.0606 \n","[2023-12-09 07:31:02,227::train::INFO] [Train] Iter 1614 | Loss 0.033094 | Grad 0.1169 \n","[2023-12-09 07:31:02,311::train::INFO] [Train] Iter 1615 | Loss 0.032267 | Grad 0.0325 \n","[2023-12-09 07:31:02,396::train::INFO] [Train] Iter 1616 | Loss 0.032294 | Grad 0.0979 \n","[2023-12-09 07:31:02,479::train::INFO] [Train] Iter 1617 | Loss 0.034194 | Grad 0.0549 \n","[2023-12-09 07:31:02,563::train::INFO] [Train] Iter 1618 | Loss 0.033201 | Grad 0.0521 \n","[2023-12-09 07:31:02,645::train::INFO] [Train] Iter 1619 | Loss 0.034774 | Grad 0.0577 \n","[2023-12-09 07:31:02,732::train::INFO] [Train] Iter 1620 | Loss 0.035384 | Grad 0.0659 \n","[2023-12-09 07:31:02,815::train::INFO] [Train] Iter 1621 | Loss 0.033581 | Grad 0.0597 \n","[2023-12-09 07:31:02,909::train::INFO] [Train] Iter 1622 | Loss 0.034569 | Grad 0.0494 \n","[2023-12-09 07:31:02,993::train::INFO] [Train] Iter 1623 | Loss 0.031897 | Grad 0.0530 \n","[2023-12-09 07:31:03,078::train::INFO] [Train] Iter 1624 | Loss 0.032981 | Grad 0.0749 \n","[2023-12-09 07:31:03,160::train::INFO] [Train] Iter 1625 | Loss 0.033165 | Grad 0.0531 \n","[2023-12-09 07:31:03,246::train::INFO] [Train] Iter 1626 | Loss 0.034576 | Grad 0.0549 \n","[2023-12-09 07:31:03,330::train::INFO] [Train] Iter 1627 | Loss 0.033994 | Grad 0.0597 \n","[2023-12-09 07:31:03,413::train::INFO] [Train] Iter 1628 | Loss 0.033758 | Grad 0.0775 \n","[2023-12-09 07:31:03,497::train::INFO] [Train] Iter 1629 | Loss 0.032759 | Grad 0.1084 \n","[2023-12-09 07:31:03,579::train::INFO] [Train] Iter 1630 | Loss 0.035142 | Grad 0.0558 \n","[2023-12-09 07:31:03,662::train::INFO] [Train] Iter 1631 | Loss 0.034587 | Grad 0.0858 \n","[2023-12-09 07:31:03,749::train::INFO] [Train] Iter 1632 | Loss 0.031764 | Grad 0.0492 \n","[2023-12-09 07:31:03,832::train::INFO] [Train] Iter 1633 | Loss 0.031544 | Grad 0.0542 \n","[2023-12-09 07:31:03,919::train::INFO] [Train] Iter 1634 | Loss 0.032544 | Grad 0.0679 \n","[2023-12-09 07:31:04,003::train::INFO] [Train] Iter 1635 | Loss 0.031698 | Grad 0.0708 \n","[2023-12-09 07:31:04,086::train::INFO] [Train] Iter 1636 | Loss 0.032395 | Grad 0.0500 \n","[2023-12-09 07:31:04,170::train::INFO] [Train] Iter 1637 | Loss 0.033030 | Grad 0.0479 \n","[2023-12-09 07:31:04,257::train::INFO] [Train] Iter 1638 | Loss 0.033252 | Grad 0.0661 \n","[2023-12-09 07:31:04,341::train::INFO] [Train] Iter 1639 | Loss 0.033900 | Grad 0.0803 \n","[2023-12-09 07:31:04,427::train::INFO] [Train] Iter 1640 | Loss 0.032104 | Grad 0.0599 \n","[2023-12-09 07:31:04,521::train::INFO] [Train] Iter 1641 | Loss 0.033023 | Grad 0.0884 \n","[2023-12-09 07:31:04,616::train::INFO] [Train] Iter 1642 | Loss 0.032510 | Grad 0.0689 \n","[2023-12-09 07:31:04,709::train::INFO] [Train] Iter 1643 | Loss 0.031730 | Grad 0.0670 \n","[2023-12-09 07:31:04,802::train::INFO] [Train] Iter 1644 | Loss 0.034288 | Grad 0.0456 \n","[2023-12-09 07:31:04,893::train::INFO] [Train] Iter 1645 | Loss 0.032658 | Grad 0.0741 \n","[2023-12-09 07:31:04,990::train::INFO] [Train] Iter 1646 | Loss 0.031708 | Grad 0.0648 \n","[2023-12-09 07:31:05,088::train::INFO] [Train] Iter 1647 | Loss 0.031516 | Grad 0.0602 \n","[2023-12-09 07:31:05,179::train::INFO] [Train] Iter 1648 | Loss 0.034003 | Grad 0.0592 \n","[2023-12-09 07:31:05,274::train::INFO] [Train] Iter 1649 | Loss 0.032443 | Grad 0.0648 \n","[2023-12-09 07:31:05,367::train::INFO] [Train] Iter 1650 | Loss 0.033301 | Grad 0.0722 \n","[2023-12-09 07:31:05,458::train::INFO] [Train] Iter 1651 | Loss 0.031783 | Grad 0.0529 \n","[2023-12-09 07:31:05,549::train::INFO] [Train] Iter 1652 | Loss 0.032898 | Grad 0.0670 \n","[2023-12-09 07:31:05,640::train::INFO] [Train] Iter 1653 | Loss 0.032864 | Grad 0.0677 \n","[2023-12-09 07:31:05,731::train::INFO] [Train] Iter 1654 | Loss 0.034333 | Grad 0.0947 \n","[2023-12-09 07:31:05,821::train::INFO] [Train] Iter 1655 | Loss 0.032777 | Grad 0.0446 \n","[2023-12-09 07:31:05,912::train::INFO] [Train] Iter 1656 | Loss 0.036696 | Grad 0.0914 \n","[2023-12-09 07:31:06,007::train::INFO] [Train] Iter 1657 | Loss 0.033690 | Grad 0.0715 \n","[2023-12-09 07:31:06,102::train::INFO] [Train] Iter 1658 | Loss 0.030590 | Grad 0.0775 \n","[2023-12-09 07:31:06,194::train::INFO] [Train] Iter 1659 | Loss 0.035192 | Grad 0.0550 \n","[2023-12-09 07:31:06,287::train::INFO] [Train] Iter 1660 | Loss 0.033427 | Grad 0.0687 \n","[2023-12-09 07:31:06,379::train::INFO] [Train] Iter 1661 | Loss 0.031024 | Grad 0.0788 \n","[2023-12-09 07:31:06,469::train::INFO] [Train] Iter 1662 | Loss 0.033560 | Grad 0.0536 \n","[2023-12-09 07:31:06,561::train::INFO] [Train] Iter 1663 | Loss 0.032583 | Grad 0.1112 \n","[2023-12-09 07:31:06,652::train::INFO] [Train] Iter 1664 | Loss 0.033017 | Grad 0.0562 \n","[2023-12-09 07:31:06,742::train::INFO] [Train] Iter 1665 | Loss 0.033135 | Grad 0.0611 \n","[2023-12-09 07:31:06,833::train::INFO] [Train] Iter 1666 | Loss 0.033497 | Grad 0.0529 \n","[2023-12-09 07:31:06,925::train::INFO] [Train] Iter 1667 | Loss 0.033183 | Grad 0.0928 \n","[2023-12-09 07:31:07,021::train::INFO] [Train] Iter 1668 | Loss 0.030291 | Grad 0.0671 \n","[2023-12-09 07:31:07,112::train::INFO] [Train] Iter 1669 | Loss 0.033416 | Grad 0.0620 \n","[2023-12-09 07:31:07,206::train::INFO] [Train] Iter 1670 | Loss 0.034177 | Grad 0.0610 \n","[2023-12-09 07:31:07,298::train::INFO] [Train] Iter 1671 | Loss 0.032333 | Grad 0.0450 \n","[2023-12-09 07:31:07,393::train::INFO] [Train] Iter 1672 | Loss 0.033174 | Grad 0.0611 \n","[2023-12-09 07:31:07,485::train::INFO] [Train] Iter 1673 | Loss 0.034337 | Grad 0.1012 \n","[2023-12-09 07:31:07,575::train::INFO] [Train] Iter 1674 | Loss 0.033620 | Grad 0.0434 \n","[2023-12-09 07:31:07,666::train::INFO] [Train] Iter 1675 | Loss 0.032273 | Grad 0.0602 \n","[2023-12-09 07:31:07,758::train::INFO] [Train] Iter 1676 | Loss 0.032587 | Grad 0.0502 \n","[2023-12-09 07:31:07,850::train::INFO] [Train] Iter 1677 | Loss 0.035079 | Grad 0.1021 \n","[2023-12-09 07:31:07,940::train::INFO] [Train] Iter 1678 | Loss 0.033411 | Grad 0.1198 \n","[2023-12-09 07:31:08,032::train::INFO] [Train] Iter 1679 | Loss 0.032371 | Grad 0.0595 \n","[2023-12-09 07:31:08,123::train::INFO] [Train] Iter 1680 | Loss 0.034139 | Grad 0.0654 \n","[2023-12-09 07:31:08,217::train::INFO] [Train] Iter 1681 | Loss 0.031087 | Grad 0.0674 \n","[2023-12-09 07:31:08,309::train::INFO] [Train] Iter 1682 | Loss 0.034665 | Grad 0.0591 \n","[2023-12-09 07:31:08,401::train::INFO] [Train] Iter 1683 | Loss 0.033057 | Grad 0.0695 \n","[2023-12-09 07:31:08,492::train::INFO] [Train] Iter 1684 | Loss 0.031278 | Grad 0.0631 \n","[2023-12-09 07:31:08,582::train::INFO] [Train] Iter 1685 | Loss 0.033066 | Grad 0.0885 \n","[2023-12-09 07:31:08,673::train::INFO] [Train] Iter 1686 | Loss 0.035281 | Grad 0.0980 \n","[2023-12-09 07:31:08,764::train::INFO] [Train] Iter 1687 | Loss 0.032272 | Grad 0.0488 \n","[2023-12-09 07:31:08,855::train::INFO] [Train] Iter 1688 | Loss 0.033132 | Grad 0.0682 \n","[2023-12-09 07:31:08,947::train::INFO] [Train] Iter 1689 | Loss 0.034079 | Grad 0.0786 \n","[2023-12-09 07:31:09,038::train::INFO] [Train] Iter 1690 | Loss 0.033155 | Grad 0.0770 \n","[2023-12-09 07:31:09,132::train::INFO] [Train] Iter 1691 | Loss 0.030904 | Grad 0.0730 \n","[2023-12-09 07:31:09,225::train::INFO] [Train] Iter 1692 | Loss 0.032780 | Grad 0.0618 \n","[2023-12-09 07:31:09,317::train::INFO] [Train] Iter 1693 | Loss 0.033415 | Grad 0.0636 \n","[2023-12-09 07:31:09,410::train::INFO] [Train] Iter 1694 | Loss 0.034080 | Grad 0.0688 \n","[2023-12-09 07:31:09,503::train::INFO] [Train] Iter 1695 | Loss 0.031206 | Grad 0.0721 \n","[2023-12-09 07:31:09,597::train::INFO] [Train] Iter 1696 | Loss 0.034526 | Grad 0.0708 \n","[2023-12-09 07:31:09,689::train::INFO] [Train] Iter 1697 | Loss 0.034529 | Grad 0.0600 \n","[2023-12-09 07:31:09,779::train::INFO] [Train] Iter 1698 | Loss 0.030773 | Grad 0.0514 \n","[2023-12-09 07:31:09,871::train::INFO] [Train] Iter 1699 | Loss 0.031780 | Grad 0.0921 \n","[2023-12-09 07:31:09,913::train::INFO] [Train] Iter 1700 | Loss 0.031290 | Grad 0.0933 \n","[2023-12-09 07:31:10,003::train::INFO] [Train] Iter 1701 | Loss 0.031801 | Grad 0.0570 \n","[2023-12-09 07:31:10,096::train::INFO] [Train] Iter 1702 | Loss 0.034423 | Grad 0.0750 \n","[2023-12-09 07:31:10,195::train::INFO] [Train] Iter 1703 | Loss 0.033029 | Grad 0.0673 \n","[2023-12-09 07:31:10,286::train::INFO] [Train] Iter 1704 | Loss 0.033575 | Grad 0.0512 \n","[2023-12-09 07:31:10,377::train::INFO] [Train] Iter 1705 | Loss 0.032552 | Grad 0.0675 \n","[2023-12-09 07:31:10,470::train::INFO] [Train] Iter 1706 | Loss 0.034114 | Grad 0.0520 \n","[2023-12-09 07:31:10,561::train::INFO] [Train] Iter 1707 | Loss 0.032892 | Grad 0.0689 \n","[2023-12-09 07:31:10,654::train::INFO] [Train] Iter 1708 | Loss 0.034491 | Grad 0.0599 \n","[2023-12-09 07:31:10,746::train::INFO] [Train] Iter 1709 | Loss 0.033135 | Grad 0.0466 \n","[2023-12-09 07:31:10,836::train::INFO] [Train] Iter 1710 | Loss 0.033838 | Grad 0.0578 \n","[2023-12-09 07:31:10,926::train::INFO] [Train] Iter 1711 | Loss 0.032293 | Grad 0.0734 \n","[2023-12-09 07:31:11,017::train::INFO] [Train] Iter 1712 | Loss 0.034315 | Grad 0.0549 \n","[2023-12-09 07:31:11,101::train::INFO] [Train] Iter 1713 | Loss 0.032884 | Grad 0.0884 \n","[2023-12-09 07:31:11,185::train::INFO] [Train] Iter 1714 | Loss 0.032658 | Grad 0.0460 \n","[2023-12-09 07:31:11,269::train::INFO] [Train] Iter 1715 | Loss 0.033329 | Grad 0.0474 \n","[2023-12-09 07:31:11,352::train::INFO] [Train] Iter 1716 | Loss 0.032774 | Grad 0.0628 \n","[2023-12-09 07:31:11,437::train::INFO] [Train] Iter 1717 | Loss 0.033025 | Grad 0.0616 \n","[2023-12-09 07:31:11,522::train::INFO] [Train] Iter 1718 | Loss 0.031891 | Grad 0.0601 \n","[2023-12-09 07:31:11,606::train::INFO] [Train] Iter 1719 | Loss 0.034776 | Grad 0.0469 \n","[2023-12-09 07:31:11,692::train::INFO] [Train] Iter 1720 | Loss 0.032338 | Grad 0.0724 \n","[2023-12-09 07:31:11,790::train::INFO] [Train] Iter 1721 | Loss 0.030907 | Grad 0.0595 \n","[2023-12-09 07:31:11,879::train::INFO] [Train] Iter 1722 | Loss 0.033674 | Grad 0.0602 \n","[2023-12-09 07:31:11,965::train::INFO] [Train] Iter 1723 | Loss 0.032701 | Grad 0.0875 \n","[2023-12-09 07:31:12,050::train::INFO] [Train] Iter 1724 | Loss 0.033113 | Grad 0.0900 \n","[2023-12-09 07:31:12,133::train::INFO] [Train] Iter 1725 | Loss 0.032279 | Grad 0.0512 \n","[2023-12-09 07:31:12,228::train::INFO] [Train] Iter 1726 | Loss 0.032957 | Grad 0.0772 \n","[2023-12-09 07:31:12,312::train::INFO] [Train] Iter 1727 | Loss 0.034419 | Grad 0.0576 \n","[2023-12-09 07:31:12,396::train::INFO] [Train] Iter 1728 | Loss 0.033335 | Grad 0.0438 \n","[2023-12-09 07:31:12,485::train::INFO] [Train] Iter 1729 | Loss 0.032196 | Grad 0.0615 \n","[2023-12-09 07:31:12,568::train::INFO] [Train] Iter 1730 | Loss 0.033074 | Grad 0.0610 \n","[2023-12-09 07:31:12,651::train::INFO] [Train] Iter 1731 | Loss 0.034405 | Grad 0.0557 \n","[2023-12-09 07:31:12,734::train::INFO] [Train] Iter 1732 | Loss 0.031375 | Grad 0.0380 \n","[2023-12-09 07:31:12,819::train::INFO] [Train] Iter 1733 | Loss 0.033786 | Grad 0.0790 \n","[2023-12-09 07:31:12,903::train::INFO] [Train] Iter 1734 | Loss 0.032871 | Grad 0.0719 \n","[2023-12-09 07:31:12,987::train::INFO] [Train] Iter 1735 | Loss 0.031175 | Grad 0.0659 \n","[2023-12-09 07:31:13,072::train::INFO] [Train] Iter 1736 | Loss 0.034491 | Grad 0.0413 \n","[2023-12-09 07:31:13,160::train::INFO] [Train] Iter 1737 | Loss 0.032843 | Grad 0.0408 \n","[2023-12-09 07:31:13,250::train::INFO] [Train] Iter 1738 | Loss 0.034392 | Grad 0.0498 \n","[2023-12-09 07:31:13,334::train::INFO] [Train] Iter 1739 | Loss 0.031732 | Grad 0.0459 \n","[2023-12-09 07:31:13,416::train::INFO] [Train] Iter 1740 | Loss 0.032851 | Grad 0.0654 \n","[2023-12-09 07:31:13,500::train::INFO] [Train] Iter 1741 | Loss 0.033001 | Grad 0.0567 \n","[2023-12-09 07:31:13,583::train::INFO] [Train] Iter 1742 | Loss 0.032591 | Grad 0.0606 \n","[2023-12-09 07:31:13,668::train::INFO] [Train] Iter 1743 | Loss 0.032850 | Grad 0.0715 \n","[2023-12-09 07:31:13,750::train::INFO] [Train] Iter 1744 | Loss 0.031453 | Grad 0.0361 \n","[2023-12-09 07:31:13,832::train::INFO] [Train] Iter 1745 | Loss 0.032874 | Grad 0.0495 \n","[2023-12-09 07:31:13,915::train::INFO] [Train] Iter 1746 | Loss 0.033093 | Grad 0.0621 \n","[2023-12-09 07:31:13,997::train::INFO] [Train] Iter 1747 | Loss 0.031150 | Grad 0.0657 \n","[2023-12-09 07:31:14,081::train::INFO] [Train] Iter 1748 | Loss 0.031467 | Grad 0.0766 \n","[2023-12-09 07:31:14,165::train::INFO] [Train] Iter 1749 | Loss 0.033629 | Grad 0.0661 \n","[2023-12-09 07:31:14,249::train::INFO] [Train] Iter 1750 | Loss 0.031786 | Grad 0.0685 \n","[2023-12-09 07:31:14,332::train::INFO] [Train] Iter 1751 | Loss 0.035189 | Grad 0.0790 \n","[2023-12-09 07:31:14,414::train::INFO] [Train] Iter 1752 | Loss 0.032222 | Grad 0.0529 \n","[2023-12-09 07:31:14,498::train::INFO] [Train] Iter 1753 | Loss 0.032601 | Grad 0.0648 \n","[2023-12-09 07:31:14,582::train::INFO] [Train] Iter 1754 | Loss 0.031793 | Grad 0.0709 \n","[2023-12-09 07:31:14,664::train::INFO] [Train] Iter 1755 | Loss 0.033165 | Grad 0.0433 \n","[2023-12-09 07:31:14,747::train::INFO] [Train] Iter 1756 | Loss 0.034979 | Grad 0.0476 \n","[2023-12-09 07:31:14,829::train::INFO] [Train] Iter 1757 | Loss 0.032303 | Grad 0.0474 \n","[2023-12-09 07:31:14,914::train::INFO] [Train] Iter 1758 | Loss 0.032377 | Grad 0.0532 \n","[2023-12-09 07:31:14,997::train::INFO] [Train] Iter 1759 | Loss 0.031587 | Grad 0.0389 \n","[2023-12-09 07:31:15,079::train::INFO] [Train] Iter 1760 | Loss 0.030691 | Grad 0.0476 \n","[2023-12-09 07:31:15,162::train::INFO] [Train] Iter 1761 | Loss 0.033458 | Grad 0.0755 \n","[2023-12-09 07:31:15,245::train::INFO] [Train] Iter 1762 | Loss 0.034989 | Grad 0.0482 \n","[2023-12-09 07:31:15,331::train::INFO] [Train] Iter 1763 | Loss 0.032407 | Grad 0.0389 \n","[2023-12-09 07:31:15,413::train::INFO] [Train] Iter 1764 | Loss 0.034029 | Grad 0.0843 \n","[2023-12-09 07:31:15,497::train::INFO] [Train] Iter 1765 | Loss 0.034081 | Grad 0.0569 \n","[2023-12-09 07:31:15,579::train::INFO] [Train] Iter 1766 | Loss 0.032288 | Grad 0.1019 \n","[2023-12-09 07:31:15,661::train::INFO] [Train] Iter 1767 | Loss 0.032979 | Grad 0.0421 \n","[2023-12-09 07:31:15,743::train::INFO] [Train] Iter 1768 | Loss 0.030889 | Grad 0.0556 \n","[2023-12-09 07:31:15,826::train::INFO] [Train] Iter 1769 | Loss 0.032290 | Grad 0.0487 \n","[2023-12-09 07:31:15,910::train::INFO] [Train] Iter 1770 | Loss 0.032204 | Grad 0.0662 \n","[2023-12-09 07:31:15,994::train::INFO] [Train] Iter 1771 | Loss 0.032696 | Grad 0.0560 \n","[2023-12-09 07:31:16,076::train::INFO] [Train] Iter 1772 | Loss 0.031974 | Grad 0.0573 \n","[2023-12-09 07:31:16,160::train::INFO] [Train] Iter 1773 | Loss 0.032886 | Grad 0.0849 \n","[2023-12-09 07:31:16,242::train::INFO] [Train] Iter 1774 | Loss 0.031865 | Grad 0.0583 \n","[2023-12-09 07:31:16,330::train::INFO] [Train] Iter 1775 | Loss 0.033029 | Grad 0.0648 \n","[2023-12-09 07:31:16,412::train::INFO] [Train] Iter 1776 | Loss 0.031662 | Grad 0.0713 \n","[2023-12-09 07:31:16,496::train::INFO] [Train] Iter 1777 | Loss 0.031764 | Grad 0.0433 \n","[2023-12-09 07:31:16,579::train::INFO] [Train] Iter 1778 | Loss 0.031725 | Grad 0.0701 \n","[2023-12-09 07:31:16,661::train::INFO] [Train] Iter 1779 | Loss 0.032881 | Grad 0.0647 \n","[2023-12-09 07:31:16,744::train::INFO] [Train] Iter 1780 | Loss 0.031539 | Grad 0.0653 \n","[2023-12-09 07:31:16,827::train::INFO] [Train] Iter 1781 | Loss 0.032612 | Grad 0.0579 \n","[2023-12-09 07:31:16,910::train::INFO] [Train] Iter 1782 | Loss 0.030707 | Grad 0.0450 \n","[2023-12-09 07:31:16,998::train::INFO] [Train] Iter 1783 | Loss 0.031329 | Grad 0.0655 \n","[2023-12-09 07:31:17,082::train::INFO] [Train] Iter 1784 | Loss 0.033374 | Grad 0.0470 \n","[2023-12-09 07:31:17,169::train::INFO] [Train] Iter 1785 | Loss 0.033495 | Grad 0.0831 \n","[2023-12-09 07:31:17,253::train::INFO] [Train] Iter 1786 | Loss 0.032969 | Grad 0.0749 \n","[2023-12-09 07:31:17,340::train::INFO] [Train] Iter 1787 | Loss 0.032650 | Grad 0.0631 \n","[2023-12-09 07:31:17,423::train::INFO] [Train] Iter 1788 | Loss 0.033079 | Grad 0.0406 \n","[2023-12-09 07:31:17,506::train::INFO] [Train] Iter 1789 | Loss 0.032169 | Grad 0.0459 \n","[2023-12-09 07:31:17,588::train::INFO] [Train] Iter 1790 | Loss 0.033797 | Grad 0.0895 \n","[2023-12-09 07:31:17,671::train::INFO] [Train] Iter 1791 | Loss 0.031430 | Grad 0.0584 \n","[2023-12-09 07:31:17,755::train::INFO] [Train] Iter 1792 | Loss 0.032191 | Grad 0.0483 \n","[2023-12-09 07:31:17,839::train::INFO] [Train] Iter 1793 | Loss 0.032172 | Grad 0.0463 \n","[2023-12-09 07:31:17,923::train::INFO] [Train] Iter 1794 | Loss 0.032181 | Grad 0.0661 \n","[2023-12-09 07:31:18,006::train::INFO] [Train] Iter 1795 | Loss 0.034541 | Grad 0.0648 \n","[2023-12-09 07:31:18,090::train::INFO] [Train] Iter 1796 | Loss 0.029445 | Grad 0.0707 \n","[2023-12-09 07:31:18,175::train::INFO] [Train] Iter 1797 | Loss 0.032402 | Grad 0.0414 \n","[2023-12-09 07:31:18,257::train::INFO] [Train] Iter 1798 | Loss 0.031853 | Grad 0.0479 \n","[2023-12-09 07:31:18,341::train::INFO] [Train] Iter 1799 | Loss 0.031183 | Grad 0.0789 \n","[2023-12-09 07:31:18,425::train::INFO] [Train] Iter 1800 | Loss 0.033813 | Grad 0.0521 \n","[2023-12-09 07:31:18,511::train::INFO] [Train] Iter 1801 | Loss 0.032270 | Grad 0.0410 \n","[2023-12-09 07:31:18,594::train::INFO] [Train] Iter 1802 | Loss 0.032074 | Grad 0.0398 \n","[2023-12-09 07:31:18,677::train::INFO] [Train] Iter 1803 | Loss 0.032206 | Grad 0.0528 \n","[2023-12-09 07:31:18,760::train::INFO] [Train] Iter 1804 | Loss 0.031932 | Grad 0.0453 \n","[2023-12-09 07:31:18,844::train::INFO] [Train] Iter 1805 | Loss 0.032502 | Grad 0.0525 \n","[2023-12-09 07:31:18,927::train::INFO] [Train] Iter 1806 | Loss 0.033050 | Grad 0.0356 \n","[2023-12-09 07:31:19,011::train::INFO] [Train] Iter 1807 | Loss 0.030231 | Grad 0.0585 \n","[2023-12-09 07:31:19,094::train::INFO] [Train] Iter 1808 | Loss 0.032833 | Grad 0.0427 \n","[2023-12-09 07:31:19,178::train::INFO] [Train] Iter 1809 | Loss 0.035012 | Grad 0.0648 \n","[2023-12-09 07:31:19,261::train::INFO] [Train] Iter 1810 | Loss 0.031868 | Grad 0.0492 \n","[2023-12-09 07:31:19,343::train::INFO] [Train] Iter 1811 | Loss 0.033439 | Grad 0.0381 \n","[2023-12-09 07:31:19,426::train::INFO] [Train] Iter 1812 | Loss 0.031547 | Grad 0.0491 \n","[2023-12-09 07:31:19,510::train::INFO] [Train] Iter 1813 | Loss 0.031584 | Grad 0.0558 \n","[2023-12-09 07:31:19,592::train::INFO] [Train] Iter 1814 | Loss 0.032564 | Grad 0.0518 \n","[2023-12-09 07:31:19,674::train::INFO] [Train] Iter 1815 | Loss 0.031566 | Grad 0.0508 \n","[2023-12-09 07:31:19,757::train::INFO] [Train] Iter 1816 | Loss 0.032510 | Grad 0.0442 \n","[2023-12-09 07:31:19,840::train::INFO] [Train] Iter 1817 | Loss 0.032525 | Grad 0.0309 \n","[2023-12-09 07:31:19,923::train::INFO] [Train] Iter 1818 | Loss 0.031648 | Grad 0.0645 \n","[2023-12-09 07:31:20,007::train::INFO] [Train] Iter 1819 | Loss 0.029017 | Grad 0.0638 \n","[2023-12-09 07:31:20,090::train::INFO] [Train] Iter 1820 | Loss 0.033021 | Grad 0.0361 \n","[2023-12-09 07:31:20,175::train::INFO] [Train] Iter 1821 | Loss 0.031502 | Grad 0.0493 \n","[2023-12-09 07:31:20,259::train::INFO] [Train] Iter 1822 | Loss 0.030168 | Grad 0.0534 \n","[2023-12-09 07:31:20,342::train::INFO] [Train] Iter 1823 | Loss 0.030285 | Grad 0.0611 \n","[2023-12-09 07:31:20,429::train::INFO] [Train] Iter 1824 | Loss 0.032374 | Grad 0.0790 \n","[2023-12-09 07:31:20,517::train::INFO] [Train] Iter 1825 | Loss 0.032195 | Grad 0.0481 \n","[2023-12-09 07:31:20,600::train::INFO] [Train] Iter 1826 | Loss 0.032037 | Grad 0.0686 \n","[2023-12-09 07:31:20,684::train::INFO] [Train] Iter 1827 | Loss 0.030685 | Grad 0.0332 \n","[2023-12-09 07:31:20,768::train::INFO] [Train] Iter 1828 | Loss 0.032150 | Grad 0.0468 \n","[2023-12-09 07:31:20,853::train::INFO] [Train] Iter 1829 | Loss 0.032729 | Grad 0.0572 \n","[2023-12-09 07:31:20,936::train::INFO] [Train] Iter 1830 | Loss 0.030197 | Grad 0.0729 \n","[2023-12-09 07:31:21,022::train::INFO] [Train] Iter 1831 | Loss 0.032843 | Grad 0.0662 \n","[2023-12-09 07:31:21,122::train::INFO] [Train] Iter 1832 | Loss 0.032735 | Grad 0.0759 \n","[2023-12-09 07:31:21,211::train::INFO] [Train] Iter 1833 | Loss 0.031679 | Grad 0.0550 \n","[2023-12-09 07:31:21,302::train::INFO] [Train] Iter 1834 | Loss 0.030904 | Grad 0.0915 \n","[2023-12-09 07:31:21,395::train::INFO] [Train] Iter 1835 | Loss 0.031026 | Grad 0.0430 \n","[2023-12-09 07:31:21,489::train::INFO] [Train] Iter 1836 | Loss 0.030642 | Grad 0.0901 \n","[2023-12-09 07:31:21,578::train::INFO] [Train] Iter 1837 | Loss 0.031381 | Grad 0.0838 \n","[2023-12-09 07:31:21,669::train::INFO] [Train] Iter 1838 | Loss 0.031350 | Grad 0.0812 \n","[2023-12-09 07:31:21,761::train::INFO] [Train] Iter 1839 | Loss 0.032303 | Grad 0.0749 \n","[2023-12-09 07:31:21,853::train::INFO] [Train] Iter 1840 | Loss 0.032279 | Grad 0.0788 \n","[2023-12-09 07:31:21,944::train::INFO] [Train] Iter 1841 | Loss 0.033186 | Grad 0.1134 \n","[2023-12-09 07:31:22,034::train::INFO] [Train] Iter 1842 | Loss 0.031722 | Grad 0.0642 \n","[2023-12-09 07:31:22,125::train::INFO] [Train] Iter 1843 | Loss 0.034098 | Grad 0.0488 \n","[2023-12-09 07:31:22,215::train::INFO] [Train] Iter 1844 | Loss 0.032912 | Grad 0.0948 \n","[2023-12-09 07:31:22,304::train::INFO] [Train] Iter 1845 | Loss 0.034834 | Grad 0.0767 \n","[2023-12-09 07:31:22,396::train::INFO] [Train] Iter 1846 | Loss 0.033263 | Grad 0.0832 \n","[2023-12-09 07:31:22,487::train::INFO] [Train] Iter 1847 | Loss 0.031929 | Grad 0.0553 \n","[2023-12-09 07:31:22,577::train::INFO] [Train] Iter 1848 | Loss 0.032565 | Grad 0.0690 \n","[2023-12-09 07:31:22,674::train::INFO] [Train] Iter 1849 | Loss 0.033107 | Grad 0.0593 \n","[2023-12-09 07:31:22,765::train::INFO] [Train] Iter 1850 | Loss 0.034332 | Grad 0.0924 \n","[2023-12-09 07:31:22,863::train::INFO] [Train] Iter 1851 | Loss 0.034234 | Grad 0.0577 \n","[2023-12-09 07:31:22,954::train::INFO] [Train] Iter 1852 | Loss 0.033432 | Grad 0.0697 \n","[2023-12-09 07:31:23,042::train::INFO] [Train] Iter 1853 | Loss 0.031236 | Grad 0.0365 \n","[2023-12-09 07:31:23,144::train::INFO] [Train] Iter 1854 | Loss 0.031548 | Grad 0.0893 \n","[2023-12-09 07:31:23,234::train::INFO] [Train] Iter 1855 | Loss 0.032255 | Grad 0.0561 \n","[2023-12-09 07:31:23,324::train::INFO] [Train] Iter 1856 | Loss 0.032808 | Grad 0.0526 \n","[2023-12-09 07:31:23,415::train::INFO] [Train] Iter 1857 | Loss 0.030178 | Grad 0.0587 \n","[2023-12-09 07:31:23,505::train::INFO] [Train] Iter 1858 | Loss 0.031906 | Grad 0.0905 \n","[2023-12-09 07:31:23,596::train::INFO] [Train] Iter 1859 | Loss 0.030650 | Grad 0.0830 \n","[2023-12-09 07:31:23,686::train::INFO] [Train] Iter 1860 | Loss 0.031611 | Grad 0.0751 \n","[2023-12-09 07:31:23,780::train::INFO] [Train] Iter 1861 | Loss 0.031740 | Grad 0.1332 \n","[2023-12-09 07:31:23,872::train::INFO] [Train] Iter 1862 | Loss 0.032274 | Grad 0.0932 \n","[2023-12-09 07:31:23,965::train::INFO] [Train] Iter 1863 | Loss 0.033878 | Grad 0.0938 \n","[2023-12-09 07:31:24,065::train::INFO] [Train] Iter 1864 | Loss 0.033106 | Grad 0.0593 \n","[2023-12-09 07:31:24,157::train::INFO] [Train] Iter 1865 | Loss 0.031329 | Grad 0.0686 \n","[2023-12-09 07:31:24,248::train::INFO] [Train] Iter 1866 | Loss 0.032564 | Grad 0.0955 \n","[2023-12-09 07:31:24,344::train::INFO] [Train] Iter 1867 | Loss 0.031429 | Grad 0.0463 \n","[2023-12-09 07:31:24,433::train::INFO] [Train] Iter 1868 | Loss 0.033021 | Grad 0.1305 \n","[2023-12-09 07:31:24,523::train::INFO] [Train] Iter 1869 | Loss 0.029720 | Grad 0.0790 \n","[2023-12-09 07:31:24,620::train::INFO] [Train] Iter 1870 | Loss 0.030305 | Grad 0.0570 \n","[2023-12-09 07:31:24,709::train::INFO] [Train] Iter 1871 | Loss 0.031082 | Grad 0.0601 \n","[2023-12-09 07:31:24,798::train::INFO] [Train] Iter 1872 | Loss 0.034510 | Grad 0.0501 \n","[2023-12-09 07:31:24,888::train::INFO] [Train] Iter 1873 | Loss 0.034244 | Grad 0.0756 \n","[2023-12-09 07:31:24,977::train::INFO] [Train] Iter 1874 | Loss 0.031835 | Grad 0.0553 \n","[2023-12-09 07:31:25,067::train::INFO] [Train] Iter 1875 | Loss 0.031914 | Grad 0.0519 \n","[2023-12-09 07:31:25,157::train::INFO] [Train] Iter 1876 | Loss 0.030511 | Grad 0.0564 \n","[2023-12-09 07:31:25,246::train::INFO] [Train] Iter 1877 | Loss 0.030537 | Grad 0.0473 \n","[2023-12-09 07:31:25,337::train::INFO] [Train] Iter 1878 | Loss 0.029958 | Grad 0.0510 \n","[2023-12-09 07:31:25,427::train::INFO] [Train] Iter 1879 | Loss 0.029810 | Grad 0.0526 \n","[2023-12-09 07:31:25,517::train::INFO] [Train] Iter 1880 | Loss 0.032439 | Grad 0.0462 \n","[2023-12-09 07:31:25,614::train::INFO] [Train] Iter 1881 | Loss 0.033842 | Grad 0.0590 \n","[2023-12-09 07:31:25,704::train::INFO] [Train] Iter 1882 | Loss 0.030846 | Grad 0.0405 \n","[2023-12-09 07:31:25,795::train::INFO] [Train] Iter 1883 | Loss 0.029989 | Grad 0.0653 \n","[2023-12-09 07:31:25,889::train::INFO] [Train] Iter 1884 | Loss 0.032853 | Grad 0.0691 \n","[2023-12-09 07:31:25,979::train::INFO] [Train] Iter 1885 | Loss 0.030517 | Grad 0.0500 \n","[2023-12-09 07:31:26,068::train::INFO] [Train] Iter 1886 | Loss 0.032895 | Grad 0.0643 \n","[2023-12-09 07:31:26,158::train::INFO] [Train] Iter 1887 | Loss 0.030215 | Grad 0.0435 \n","[2023-12-09 07:31:26,254::train::INFO] [Train] Iter 1888 | Loss 0.032451 | Grad 0.0326 \n","[2023-12-09 07:31:26,343::train::INFO] [Train] Iter 1889 | Loss 0.031905 | Grad 0.0781 \n","[2023-12-09 07:31:26,433::train::INFO] [Train] Iter 1890 | Loss 0.032524 | Grad 0.0511 \n","[2023-12-09 07:31:26,526::train::INFO] [Train] Iter 1891 | Loss 0.033096 | Grad 0.0566 \n","[2023-12-09 07:31:26,616::train::INFO] [Train] Iter 1892 | Loss 0.031292 | Grad 0.0857 \n","[2023-12-09 07:31:26,707::train::INFO] [Train] Iter 1893 | Loss 0.031394 | Grad 0.0638 \n","[2023-12-09 07:31:26,805::train::INFO] [Train] Iter 1894 | Loss 0.031134 | Grad 0.0312 \n","[2023-12-09 07:31:26,895::train::INFO] [Train] Iter 1895 | Loss 0.033055 | Grad 0.0470 \n","[2023-12-09 07:31:26,988::train::INFO] [Train] Iter 1896 | Loss 0.032993 | Grad 0.0344 \n","[2023-12-09 07:31:27,086::train::INFO] [Train] Iter 1897 | Loss 0.031135 | Grad 0.0604 \n","[2023-12-09 07:31:27,179::train::INFO] [Train] Iter 1898 | Loss 0.030644 | Grad 0.0723 \n","[2023-12-09 07:31:27,266::train::INFO] [Train] Iter 1899 | Loss 0.032303 | Grad 0.0322 \n","[2023-12-09 07:31:27,348::train::INFO] [Train] Iter 1900 | Loss 0.029830 | Grad 0.0376 \n","[2023-12-09 07:31:27,430::train::INFO] [Train] Iter 1901 | Loss 0.030567 | Grad 0.0422 \n","[2023-12-09 07:31:27,513::train::INFO] [Train] Iter 1902 | Loss 0.032012 | Grad 0.0547 \n","[2023-12-09 07:31:27,596::train::INFO] [Train] Iter 1903 | Loss 0.032679 | Grad 0.0536 \n","[2023-12-09 07:31:27,679::train::INFO] [Train] Iter 1904 | Loss 0.031188 | Grad 0.0428 \n","[2023-12-09 07:31:27,761::train::INFO] [Train] Iter 1905 | Loss 0.031398 | Grad 0.0522 \n","[2023-12-09 07:31:27,843::train::INFO] [Train] Iter 1906 | Loss 0.031067 | Grad 0.0442 \n","[2023-12-09 07:31:27,925::train::INFO] [Train] Iter 1907 | Loss 0.031197 | Grad 0.0383 \n","[2023-12-09 07:31:28,008::train::INFO] [Train] Iter 1908 | Loss 0.031295 | Grad 0.0481 \n","[2023-12-09 07:31:28,093::train::INFO] [Train] Iter 1909 | Loss 0.030091 | Grad 0.0542 \n","[2023-12-09 07:31:28,175::train::INFO] [Train] Iter 1910 | Loss 0.034112 | Grad 0.0567 \n","[2023-12-09 07:31:28,257::train::INFO] [Train] Iter 1911 | Loss 0.033262 | Grad 0.0476 \n","[2023-12-09 07:31:28,338::train::INFO] [Train] Iter 1912 | Loss 0.030700 | Grad 0.0496 \n","[2023-12-09 07:31:28,419::train::INFO] [Train] Iter 1913 | Loss 0.031677 | Grad 0.0428 \n","[2023-12-09 07:31:28,501::train::INFO] [Train] Iter 1914 | Loss 0.032702 | Grad 0.0454 \n","[2023-12-09 07:31:28,586::train::INFO] [Train] Iter 1915 | Loss 0.030335 | Grad 0.0523 \n","[2023-12-09 07:31:28,671::train::INFO] [Train] Iter 1916 | Loss 0.032905 | Grad 0.0483 \n","[2023-12-09 07:31:28,758::train::INFO] [Train] Iter 1917 | Loss 0.031194 | Grad 0.0433 \n","[2023-12-09 07:31:28,840::train::INFO] [Train] Iter 1918 | Loss 0.034023 | Grad 0.0451 \n","[2023-12-09 07:31:28,922::train::INFO] [Train] Iter 1919 | Loss 0.030760 | Grad 0.0390 \n","[2023-12-09 07:31:29,005::train::INFO] [Train] Iter 1920 | Loss 0.032576 | Grad 0.0586 \n","[2023-12-09 07:31:29,088::train::INFO] [Train] Iter 1921 | Loss 0.030905 | Grad 0.0564 \n","[2023-12-09 07:31:29,171::train::INFO] [Train] Iter 1922 | Loss 0.030551 | Grad 0.0482 \n","[2023-12-09 07:31:29,257::train::INFO] [Train] Iter 1923 | Loss 0.031248 | Grad 0.0524 \n","[2023-12-09 07:31:29,340::train::INFO] [Train] Iter 1924 | Loss 0.032245 | Grad 0.0652 \n","[2023-12-09 07:31:29,422::train::INFO] [Train] Iter 1925 | Loss 0.031345 | Grad 0.0425 \n","[2023-12-09 07:31:29,504::train::INFO] [Train] Iter 1926 | Loss 0.032245 | Grad 0.0368 \n","[2023-12-09 07:31:29,587::train::INFO] [Train] Iter 1927 | Loss 0.032120 | Grad 0.0373 \n","[2023-12-09 07:31:29,670::train::INFO] [Train] Iter 1928 | Loss 0.029480 | Grad 0.0357 \n","[2023-12-09 07:31:29,758::train::INFO] [Train] Iter 1929 | Loss 0.032701 | Grad 0.0580 \n","[2023-12-09 07:31:29,840::train::INFO] [Train] Iter 1930 | Loss 0.029712 | Grad 0.0438 \n","[2023-12-09 07:31:29,923::train::INFO] [Train] Iter 1931 | Loss 0.032268 | Grad 0.0415 \n","[2023-12-09 07:31:30,006::train::INFO] [Train] Iter 1932 | Loss 0.031485 | Grad 0.0455 \n","[2023-12-09 07:31:30,088::train::INFO] [Train] Iter 1933 | Loss 0.033206 | Grad 0.0515 \n","[2023-12-09 07:31:30,173::train::INFO] [Train] Iter 1934 | Loss 0.031156 | Grad 0.0468 \n","[2023-12-09 07:31:30,256::train::INFO] [Train] Iter 1935 | Loss 0.031554 | Grad 0.0542 \n","[2023-12-09 07:31:30,339::train::INFO] [Train] Iter 1936 | Loss 0.031781 | Grad 0.0446 \n","[2023-12-09 07:31:30,421::train::INFO] [Train] Iter 1937 | Loss 0.031337 | Grad 0.0648 \n","[2023-12-09 07:31:30,506::train::INFO] [Train] Iter 1938 | Loss 0.030344 | Grad 0.0412 \n","[2023-12-09 07:31:30,589::train::INFO] [Train] Iter 1939 | Loss 0.030998 | Grad 0.0450 \n","[2023-12-09 07:31:30,672::train::INFO] [Train] Iter 1940 | Loss 0.030930 | Grad 0.0368 \n","[2023-12-09 07:31:30,757::train::INFO] [Train] Iter 1941 | Loss 0.032171 | Grad 0.0656 \n","[2023-12-09 07:31:30,840::train::INFO] [Train] Iter 1942 | Loss 0.030362 | Grad 0.0565 \n","[2023-12-09 07:31:30,923::train::INFO] [Train] Iter 1943 | Loss 0.031516 | Grad 0.0388 \n","[2023-12-09 07:31:31,005::train::INFO] [Train] Iter 1944 | Loss 0.033386 | Grad 0.0431 \n","[2023-12-09 07:31:31,093::train::INFO] [Train] Iter 1945 | Loss 0.032655 | Grad 0.0449 \n","[2023-12-09 07:31:31,176::train::INFO] [Train] Iter 1946 | Loss 0.030508 | Grad 0.0355 \n","[2023-12-09 07:31:31,264::train::INFO] [Train] Iter 1947 | Loss 0.029113 | Grad 0.0579 \n","[2023-12-09 07:31:31,348::train::INFO] [Train] Iter 1948 | Loss 0.031774 | Grad 0.0403 \n","[2023-12-09 07:31:31,430::train::INFO] [Train] Iter 1949 | Loss 0.029386 | Grad 0.0531 \n","[2023-12-09 07:31:31,512::train::INFO] [Train] Iter 1950 | Loss 0.029355 | Grad 0.0524 \n","[2023-12-09 07:31:31,594::train::INFO] [Train] Iter 1951 | Loss 0.030983 | Grad 0.0468 \n","[2023-12-09 07:31:31,677::train::INFO] [Train] Iter 1952 | Loss 0.030990 | Grad 0.0471 \n","[2023-12-09 07:31:31,762::train::INFO] [Train] Iter 1953 | Loss 0.032813 | Grad 0.0629 \n","[2023-12-09 07:31:31,847::train::INFO] [Train] Iter 1954 | Loss 0.031074 | Grad 0.0932 \n","[2023-12-09 07:31:31,929::train::INFO] [Train] Iter 1955 | Loss 0.030265 | Grad 0.0384 \n","[2023-12-09 07:31:32,011::train::INFO] [Train] Iter 1956 | Loss 0.030196 | Grad 0.0868 \n","[2023-12-09 07:31:32,094::train::INFO] [Train] Iter 1957 | Loss 0.032310 | Grad 0.0516 \n","[2023-12-09 07:31:32,177::train::INFO] [Train] Iter 1958 | Loss 0.031305 | Grad 0.0476 \n","[2023-12-09 07:31:32,258::train::INFO] [Train] Iter 1959 | Loss 0.033004 | Grad 0.0532 \n","[2023-12-09 07:31:32,340::train::INFO] [Train] Iter 1960 | Loss 0.033394 | Grad 0.0601 \n","[2023-12-09 07:31:32,422::train::INFO] [Train] Iter 1961 | Loss 0.031662 | Grad 0.0513 \n","[2023-12-09 07:31:32,504::train::INFO] [Train] Iter 1962 | Loss 0.032749 | Grad 0.0409 \n","[2023-12-09 07:31:32,586::train::INFO] [Train] Iter 1963 | Loss 0.029861 | Grad 0.0401 \n","[2023-12-09 07:31:32,668::train::INFO] [Train] Iter 1964 | Loss 0.031000 | Grad 0.0646 \n","[2023-12-09 07:31:32,750::train::INFO] [Train] Iter 1965 | Loss 0.031226 | Grad 0.0386 \n","[2023-12-09 07:31:32,835::train::INFO] [Train] Iter 1966 | Loss 0.032927 | Grad 0.0493 \n","[2023-12-09 07:31:32,918::train::INFO] [Train] Iter 1967 | Loss 0.032110 | Grad 0.0547 \n","[2023-12-09 07:31:33,002::train::INFO] [Train] Iter 1968 | Loss 0.031790 | Grad 0.0523 \n","[2023-12-09 07:31:33,086::train::INFO] [Train] Iter 1969 | Loss 0.030722 | Grad 0.0813 \n","[2023-12-09 07:31:33,171::train::INFO] [Train] Iter 1970 | Loss 0.033175 | Grad 0.0527 \n","[2023-12-09 07:31:33,254::train::INFO] [Train] Iter 1971 | Loss 0.032690 | Grad 0.0775 \n","[2023-12-09 07:31:33,337::train::INFO] [Train] Iter 1972 | Loss 0.029682 | Grad 0.0426 \n","[2023-12-09 07:31:33,421::train::INFO] [Train] Iter 1973 | Loss 0.029456 | Grad 0.0489 \n","[2023-12-09 07:31:33,510::train::INFO] [Train] Iter 1974 | Loss 0.030606 | Grad 0.0477 \n","[2023-12-09 07:31:33,593::train::INFO] [Train] Iter 1975 | Loss 0.029653 | Grad 0.0626 \n","[2023-12-09 07:31:33,675::train::INFO] [Train] Iter 1976 | Loss 0.030480 | Grad 0.0469 \n","[2023-12-09 07:31:33,757::train::INFO] [Train] Iter 1977 | Loss 0.031137 | Grad 0.0439 \n","[2023-12-09 07:31:33,845::train::INFO] [Train] Iter 1978 | Loss 0.031026 | Grad 0.0517 \n","[2023-12-09 07:31:33,928::train::INFO] [Train] Iter 1979 | Loss 0.032103 | Grad 0.0853 \n","[2023-12-09 07:31:34,010::train::INFO] [Train] Iter 1980 | Loss 0.030234 | Grad 0.0504 \n","[2023-12-09 07:31:34,093::train::INFO] [Train] Iter 1981 | Loss 0.031197 | Grad 0.0732 \n","[2023-12-09 07:31:34,179::train::INFO] [Train] Iter 1982 | Loss 0.030524 | Grad 0.0650 \n","[2023-12-09 07:31:34,262::train::INFO] [Train] Iter 1983 | Loss 0.029790 | Grad 0.0629 \n","[2023-12-09 07:31:34,344::train::INFO] [Train] Iter 1984 | Loss 0.032314 | Grad 0.0342 \n","[2023-12-09 07:31:34,428::train::INFO] [Train] Iter 1985 | Loss 0.030390 | Grad 0.0615 \n","[2023-12-09 07:31:34,511::train::INFO] [Train] Iter 1986 | Loss 0.029810 | Grad 0.0570 \n","[2023-12-09 07:31:34,593::train::INFO] [Train] Iter 1987 | Loss 0.029510 | Grad 0.0467 \n","[2023-12-09 07:31:34,677::train::INFO] [Train] Iter 1988 | Loss 0.032075 | Grad 0.0555 \n","[2023-12-09 07:31:34,759::train::INFO] [Train] Iter 1989 | Loss 0.030431 | Grad 0.0540 \n","[2023-12-09 07:31:34,844::train::INFO] [Train] Iter 1990 | Loss 0.031507 | Grad 0.0660 \n","[2023-12-09 07:31:34,928::train::INFO] [Train] Iter 1991 | Loss 0.029702 | Grad 0.0512 \n","[2023-12-09 07:31:35,016::train::INFO] [Train] Iter 1992 | Loss 0.030978 | Grad 0.0426 \n","[2023-12-09 07:31:35,098::train::INFO] [Train] Iter 1993 | Loss 0.030966 | Grad 0.0570 \n","[2023-12-09 07:31:35,182::train::INFO] [Train] Iter 1994 | Loss 0.032705 | Grad 0.0903 \n","[2023-12-09 07:31:35,265::train::INFO] [Train] Iter 1995 | Loss 0.030885 | Grad 0.0381 \n","[2023-12-09 07:31:35,348::train::INFO] [Train] Iter 1996 | Loss 0.034931 | Grad 0.0692 \n","[2023-12-09 07:31:35,431::train::INFO] [Train] Iter 1997 | Loss 0.032077 | Grad 0.0713 \n","[2023-12-09 07:31:35,513::train::INFO] [Train] Iter 1998 | Loss 0.028494 | Grad 0.0742 \n","[2023-12-09 07:31:35,595::train::INFO] [Train] Iter 1999 | Loss 0.033374 | Grad 0.0369 \n","[2023-12-09 07:31:35,677::train::INFO] [Train] Iter 2000 | Loss 0.031544 | Grad 0.0481 \n","Validate: 100% 241/241 [00:04<00:00, 55.05it/s]\n","val loss list [tensor(0.0334, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0312, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0336, device='cuda:0'), tensor(0.0325, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0327, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0326, device='cuda:0'), tensor(0.0332, device='cuda:0'), tensor(0.0335, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0320, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0343, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0346, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0317, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0298, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0331, device='cuda:0'), tensor(0.0350, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0338, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0325, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0343, device='cuda:0'), tensor(0.0325, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0332, device='cuda:0'), tensor(0.0350, device='cuda:0'), tensor(0.0317, device='cuda:0'), tensor(0.0359, device='cuda:0'), tensor(0.0355, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0330, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0317, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0320, device='cuda:0'), tensor(0.0338, device='cuda:0'), tensor(0.0303, device='cuda:0'), tensor(0.0322, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0298, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0369, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0330, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0347, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0333, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0312, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0322, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0311, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0312, device='cuda:0'), tensor(0.0321, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0327, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0344, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0317, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0313, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0248, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0335, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0356, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0305, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0311, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0321, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0321, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0361, device='cuda:0'), tensor(0.0305, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0338, device='cuda:0'), tensor(0.0347, device='cuda:0'), tensor(0.0353, device='cuda:0'), tensor(0.0322, device='cuda:0'), tensor(0.0320, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0343, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0336, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0303, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0329, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0330, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0367, device='cuda:0'), tensor(0.0313, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0353, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0332, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0303, device='cuda:0'), tensor(0.0312, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0354, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0356, device='cuda:0'), tensor(0.0335, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0335, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0322, device='cuda:0'), tensor(0.0315, device='cuda:0'), tensor(0.0303, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0340, device='cuda:0'), tensor(0.0336, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0298, device='cuda:0'), tensor(0.0320, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0322, device='cuda:0'), tensor(0.0328, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0326, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0238, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0312, device='cuda:0'), tensor(0.0319, device='cuda:0'), tensor(0.0344, device='cuda:0'), tensor(0.0334, device='cuda:0'), tensor(0.0248, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0319, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0343, device='cuda:0')]\n","[2023-12-09 07:31:40,393::train::INFO] [Train] Iter 2001 | Loss 0.028979 | Grad 0.0754 \n","[2023-12-09 07:31:40,483::train::INFO] [Train] Iter 2002 | Loss 0.031778 | Grad 0.0363 \n","[2023-12-09 07:31:40,573::train::INFO] [Train] Iter 2003 | Loss 0.030568 | Grad 0.0631 \n","[2023-12-09 07:31:40,663::train::INFO] [Train] Iter 2004 | Loss 0.031136 | Grad 0.0465 \n","[2023-12-09 07:31:40,752::train::INFO] [Train] Iter 2005 | Loss 0.031197 | Grad 0.0425 \n","[2023-12-09 07:31:40,842::train::INFO] [Train] Iter 2006 | Loss 0.031679 | Grad 0.0454 \n","[2023-12-09 07:31:40,934::train::INFO] [Train] Iter 2007 | Loss 0.031127 | Grad 0.0423 \n","[2023-12-09 07:31:41,023::train::INFO] [Train] Iter 2008 | Loss 0.028075 | Grad 0.0613 \n","[2023-12-09 07:31:41,113::train::INFO] [Train] Iter 2009 | Loss 0.031499 | Grad 0.0466 \n","[2023-12-09 07:31:41,201::train::INFO] [Train] Iter 2010 | Loss 0.032344 | Grad 0.0451 \n","[2023-12-09 07:31:41,293::train::INFO] [Train] Iter 2011 | Loss 0.030415 | Grad 0.0425 \n","[2023-12-09 07:31:41,383::train::INFO] [Train] Iter 2012 | Loss 0.031255 | Grad 0.0570 \n","[2023-12-09 07:31:41,473::train::INFO] [Train] Iter 2013 | Loss 0.032128 | Grad 0.0685 \n","[2023-12-09 07:31:41,564::train::INFO] [Train] Iter 2014 | Loss 0.031711 | Grad 0.0401 \n","[2023-12-09 07:31:41,654::train::INFO] [Train] Iter 2015 | Loss 0.030423 | Grad 0.0669 \n","[2023-12-09 07:31:41,747::train::INFO] [Train] Iter 2016 | Loss 0.030792 | Grad 0.0512 \n","[2023-12-09 07:31:41,839::train::INFO] [Train] Iter 2017 | Loss 0.033198 | Grad 0.0652 \n","[2023-12-09 07:31:41,932::train::INFO] [Train] Iter 2018 | Loss 0.031412 | Grad 0.0953 \n","[2023-12-09 07:31:42,024::train::INFO] [Train] Iter 2019 | Loss 0.030769 | Grad 0.0541 \n","[2023-12-09 07:31:42,120::train::INFO] [Train] Iter 2020 | Loss 0.032166 | Grad 0.0478 \n","[2023-12-09 07:31:42,216::train::INFO] [Train] Iter 2021 | Loss 0.029234 | Grad 0.0574 \n","[2023-12-09 07:31:42,307::train::INFO] [Train] Iter 2022 | Loss 0.033011 | Grad 0.0582 \n","[2023-12-09 07:31:42,398::train::INFO] [Train] Iter 2023 | Loss 0.031221 | Grad 0.0517 \n","[2023-12-09 07:31:42,490::train::INFO] [Train] Iter 2024 | Loss 0.029260 | Grad 0.0553 \n","[2023-12-09 07:31:42,580::train::INFO] [Train] Iter 2025 | Loss 0.031255 | Grad 0.0689 \n","[2023-12-09 07:31:42,669::train::INFO] [Train] Iter 2026 | Loss 0.033373 | Grad 0.0825 \n","[2023-12-09 07:31:42,757::train::INFO] [Train] Iter 2027 | Loss 0.030443 | Grad 0.0468 \n","[2023-12-09 07:31:42,847::train::INFO] [Train] Iter 2028 | Loss 0.031561 | Grad 0.0585 \n","[2023-12-09 07:31:42,941::train::INFO] [Train] Iter 2029 | Loss 0.031994 | Grad 0.0697 \n","[2023-12-09 07:31:43,032::train::INFO] [Train] Iter 2030 | Loss 0.031491 | Grad 0.0738 \n","[2023-12-09 07:31:43,122::train::INFO] [Train] Iter 2031 | Loss 0.028978 | Grad 0.0492 \n","[2023-12-09 07:31:43,216::train::INFO] [Train] Iter 2032 | Loss 0.031127 | Grad 0.0720 \n","[2023-12-09 07:31:43,305::train::INFO] [Train] Iter 2033 | Loss 0.031421 | Grad 0.0486 \n","[2023-12-09 07:31:43,395::train::INFO] [Train] Iter 2034 | Loss 0.032320 | Grad 0.0576 \n","[2023-12-09 07:31:43,486::train::INFO] [Train] Iter 2035 | Loss 0.029261 | Grad 0.0541 \n","[2023-12-09 07:31:43,578::train::INFO] [Train] Iter 2036 | Loss 0.032901 | Grad 0.0681 \n","[2023-12-09 07:31:43,660::train::INFO] [Train] Iter 2037 | Loss 0.032929 | Grad 0.0482 \n","[2023-12-09 07:31:43,744::train::INFO] [Train] Iter 2038 | Loss 0.028928 | Grad 0.0438 \n","[2023-12-09 07:31:43,826::train::INFO] [Train] Iter 2039 | Loss 0.029850 | Grad 0.0806 \n","[2023-12-09 07:31:43,859::train::INFO] [Train] Iter 2040 | Loss 0.029439 | Grad 0.0870 \n","[2023-12-09 07:31:43,941::train::INFO] [Train] Iter 2041 | Loss 0.029731 | Grad 0.0480 \n","[2023-12-09 07:31:44,024::train::INFO] [Train] Iter 2042 | Loss 0.032573 | Grad 0.0678 \n","[2023-12-09 07:31:44,106::train::INFO] [Train] Iter 2043 | Loss 0.030996 | Grad 0.0547 \n","[2023-12-09 07:31:44,190::train::INFO] [Train] Iter 2044 | Loss 0.031736 | Grad 0.0553 \n","[2023-12-09 07:31:44,273::train::INFO] [Train] Iter 2045 | Loss 0.030788 | Grad 0.0571 \n","[2023-12-09 07:31:44,360::train::INFO] [Train] Iter 2046 | Loss 0.032439 | Grad 0.0465 \n","[2023-12-09 07:31:44,443::train::INFO] [Train] Iter 2047 | Loss 0.030899 | Grad 0.0569 \n","[2023-12-09 07:31:44,525::train::INFO] [Train] Iter 2048 | Loss 0.032720 | Grad 0.0516 \n","[2023-12-09 07:31:44,607::train::INFO] [Train] Iter 2049 | Loss 0.031308 | Grad 0.0385 \n","[2023-12-09 07:31:44,692::train::INFO] [Train] Iter 2050 | Loss 0.032040 | Grad 0.0462 \n","[2023-12-09 07:31:44,775::train::INFO] [Train] Iter 2051 | Loss 0.030241 | Grad 0.0471 \n","[2023-12-09 07:31:44,857::train::INFO] [Train] Iter 2052 | Loss 0.032670 | Grad 0.0488 \n","[2023-12-09 07:31:44,940::train::INFO] [Train] Iter 2053 | Loss 0.031137 | Grad 0.0627 \n","[2023-12-09 07:31:45,026::train::INFO] [Train] Iter 2054 | Loss 0.030925 | Grad 0.0446 \n","[2023-12-09 07:31:45,108::train::INFO] [Train] Iter 2055 | Loss 0.031481 | Grad 0.0384 \n","[2023-12-09 07:31:45,190::train::INFO] [Train] Iter 2056 | Loss 0.030977 | Grad 0.0663 \n","[2023-12-09 07:31:45,273::train::INFO] [Train] Iter 2057 | Loss 0.031146 | Grad 0.0557 \n","[2023-12-09 07:31:45,357::train::INFO] [Train] Iter 2058 | Loss 0.030041 | Grad 0.0453 \n","[2023-12-09 07:31:45,440::train::INFO] [Train] Iter 2059 | Loss 0.032944 | Grad 0.0457 \n","[2023-12-09 07:31:45,524::train::INFO] [Train] Iter 2060 | Loss 0.030633 | Grad 0.0770 \n","[2023-12-09 07:31:45,608::train::INFO] [Train] Iter 2061 | Loss 0.029091 | Grad 0.0540 \n","[2023-12-09 07:31:45,691::train::INFO] [Train] Iter 2062 | Loss 0.031893 | Grad 0.0427 \n","[2023-12-09 07:31:45,775::train::INFO] [Train] Iter 2063 | Loss 0.030626 | Grad 0.0756 \n","[2023-12-09 07:31:45,862::train::INFO] [Train] Iter 2064 | Loss 0.031043 | Grad 0.0836 \n","[2023-12-09 07:31:45,946::train::INFO] [Train] Iter 2065 | Loss 0.030463 | Grad 0.0570 \n","[2023-12-09 07:31:46,029::train::INFO] [Train] Iter 2066 | Loss 0.031118 | Grad 0.0658 \n","[2023-12-09 07:31:46,112::train::INFO] [Train] Iter 2067 | Loss 0.032622 | Grad 0.0559 \n","[2023-12-09 07:31:46,195::train::INFO] [Train] Iter 2068 | Loss 0.031638 | Grad 0.0473 \n","[2023-12-09 07:31:46,278::train::INFO] [Train] Iter 2069 | Loss 0.030207 | Grad 0.0535 \n","[2023-12-09 07:31:46,365::train::INFO] [Train] Iter 2070 | Loss 0.031449 | Grad 0.0607 \n","[2023-12-09 07:31:46,448::train::INFO] [Train] Iter 2071 | Loss 0.032704 | Grad 0.0552 \n","[2023-12-09 07:31:46,531::train::INFO] [Train] Iter 2072 | Loss 0.029608 | Grad 0.0387 \n","[2023-12-09 07:31:46,614::train::INFO] [Train] Iter 2073 | Loss 0.032116 | Grad 0.0650 \n","[2023-12-09 07:31:46,697::train::INFO] [Train] Iter 2074 | Loss 0.031151 | Grad 0.0518 \n","[2023-12-09 07:31:46,782::train::INFO] [Train] Iter 2075 | Loss 0.029312 | Grad 0.0526 \n","[2023-12-09 07:31:46,866::train::INFO] [Train] Iter 2076 | Loss 0.032964 | Grad 0.0481 \n","[2023-12-09 07:31:46,948::train::INFO] [Train] Iter 2077 | Loss 0.031121 | Grad 0.0417 \n","[2023-12-09 07:31:47,031::train::INFO] [Train] Iter 2078 | Loss 0.032710 | Grad 0.0387 \n","[2023-12-09 07:31:47,113::train::INFO] [Train] Iter 2079 | Loss 0.029816 | Grad 0.0369 \n","[2023-12-09 07:31:47,198::train::INFO] [Train] Iter 2080 | Loss 0.031012 | Grad 0.0586 \n","[2023-12-09 07:31:47,287::train::INFO] [Train] Iter 2081 | Loss 0.031498 | Grad 0.0490 \n","[2023-12-09 07:31:47,381::train::INFO] [Train] Iter 2082 | Loss 0.030989 | Grad 0.0531 \n","[2023-12-09 07:31:47,465::train::INFO] [Train] Iter 2083 | Loss 0.031055 | Grad 0.0637 \n","[2023-12-09 07:31:47,549::train::INFO] [Train] Iter 2084 | Loss 0.029777 | Grad 0.0335 \n","[2023-12-09 07:31:47,632::train::INFO] [Train] Iter 2085 | Loss 0.031220 | Grad 0.0436 \n","[2023-12-09 07:31:47,715::train::INFO] [Train] Iter 2086 | Loss 0.031352 | Grad 0.0511 \n","[2023-12-09 07:31:47,800::train::INFO] [Train] Iter 2087 | Loss 0.029290 | Grad 0.0498 \n","[2023-12-09 07:31:47,882::train::INFO] [Train] Iter 2088 | Loss 0.029775 | Grad 0.0684 \n","[2023-12-09 07:31:47,969::train::INFO] [Train] Iter 2089 | Loss 0.031914 | Grad 0.0593 \n","[2023-12-09 07:31:48,051::train::INFO] [Train] Iter 2090 | Loss 0.029908 | Grad 0.0566 \n","[2023-12-09 07:31:48,133::train::INFO] [Train] Iter 2091 | Loss 0.033453 | Grad 0.0754 \n","[2023-12-09 07:31:48,215::train::INFO] [Train] Iter 2092 | Loss 0.030554 | Grad 0.0504 \n","[2023-12-09 07:31:48,302::train::INFO] [Train] Iter 2093 | Loss 0.031090 | Grad 0.0555 \n","[2023-12-09 07:31:48,389::train::INFO] [Train] Iter 2094 | Loss 0.030182 | Grad 0.0609 \n","[2023-12-09 07:31:48,472::train::INFO] [Train] Iter 2095 | Loss 0.031493 | Grad 0.0472 \n","[2023-12-09 07:31:48,554::train::INFO] [Train] Iter 2096 | Loss 0.033398 | Grad 0.0624 \n","[2023-12-09 07:31:48,636::train::INFO] [Train] Iter 2097 | Loss 0.030692 | Grad 0.0450 \n","[2023-12-09 07:31:48,722::train::INFO] [Train] Iter 2098 | Loss 0.030720 | Grad 0.0595 \n","[2023-12-09 07:31:48,805::train::INFO] [Train] Iter 2099 | Loss 0.029902 | Grad 0.0485 \n","[2023-12-09 07:31:48,887::train::INFO] [Train] Iter 2100 | Loss 0.028949 | Grad 0.0461 \n","[2023-12-09 07:31:48,970::train::INFO] [Train] Iter 2101 | Loss 0.031878 | Grad 0.0632 \n","[2023-12-09 07:31:49,052::train::INFO] [Train] Iter 2102 | Loss 0.033348 | Grad 0.0519 \n","[2023-12-09 07:31:49,134::train::INFO] [Train] Iter 2103 | Loss 0.030740 | Grad 0.0357 \n","[2023-12-09 07:31:49,216::train::INFO] [Train] Iter 2104 | Loss 0.032385 | Grad 0.0571 \n","[2023-12-09 07:31:49,298::train::INFO] [Train] Iter 2105 | Loss 0.032534 | Grad 0.0544 \n","[2023-12-09 07:31:49,383::train::INFO] [Train] Iter 2106 | Loss 0.030535 | Grad 0.0713 \n","[2023-12-09 07:31:49,466::train::INFO] [Train] Iter 2107 | Loss 0.031273 | Grad 0.0328 \n","[2023-12-09 07:31:49,548::train::INFO] [Train] Iter 2108 | Loss 0.029114 | Grad 0.0498 \n","[2023-12-09 07:31:49,631::train::INFO] [Train] Iter 2109 | Loss 0.030705 | Grad 0.0407 \n","[2023-12-09 07:31:49,716::train::INFO] [Train] Iter 2110 | Loss 0.030557 | Grad 0.0445 \n","[2023-12-09 07:31:49,798::train::INFO] [Train] Iter 2111 | Loss 0.030943 | Grad 0.0360 \n","[2023-12-09 07:31:49,880::train::INFO] [Train] Iter 2112 | Loss 0.030380 | Grad 0.0565 \n","[2023-12-09 07:31:49,963::train::INFO] [Train] Iter 2113 | Loss 0.031026 | Grad 0.0586 \n","[2023-12-09 07:31:50,047::train::INFO] [Train] Iter 2114 | Loss 0.030079 | Grad 0.0400 \n","[2023-12-09 07:31:50,129::train::INFO] [Train] Iter 2115 | Loss 0.031161 | Grad 0.0450 \n","[2023-12-09 07:31:50,212::train::INFO] [Train] Iter 2116 | Loss 0.029869 | Grad 0.0487 \n","[2023-12-09 07:31:50,298::train::INFO] [Train] Iter 2117 | Loss 0.029991 | Grad 0.0367 \n","[2023-12-09 07:31:50,382::train::INFO] [Train] Iter 2118 | Loss 0.030068 | Grad 0.0616 \n","[2023-12-09 07:31:50,467::train::INFO] [Train] Iter 2119 | Loss 0.031229 | Grad 0.0540 \n","[2023-12-09 07:31:50,550::train::INFO] [Train] Iter 2120 | Loss 0.029788 | Grad 0.0562 \n","[2023-12-09 07:31:50,634::train::INFO] [Train] Iter 2121 | Loss 0.030853 | Grad 0.0491 \n","[2023-12-09 07:31:50,719::train::INFO] [Train] Iter 2122 | Loss 0.028899 | Grad 0.0430 \n","[2023-12-09 07:31:50,803::train::INFO] [Train] Iter 2123 | Loss 0.029601 | Grad 0.0548 \n","[2023-12-09 07:31:50,886::train::INFO] [Train] Iter 2124 | Loss 0.031672 | Grad 0.0378 \n","[2023-12-09 07:31:50,969::train::INFO] [Train] Iter 2125 | Loss 0.031465 | Grad 0.0589 \n","[2023-12-09 07:31:51,051::train::INFO] [Train] Iter 2126 | Loss 0.031335 | Grad 0.0766 \n","[2023-12-09 07:31:51,134::train::INFO] [Train] Iter 2127 | Loss 0.030875 | Grad 0.0593 \n","[2023-12-09 07:31:51,218::train::INFO] [Train] Iter 2128 | Loss 0.031710 | Grad 0.0338 \n","[2023-12-09 07:31:51,300::train::INFO] [Train] Iter 2129 | Loss 0.030572 | Grad 0.0513 \n","[2023-12-09 07:31:51,383::train::INFO] [Train] Iter 2130 | Loss 0.032108 | Grad 0.0845 \n","[2023-12-09 07:31:51,467::train::INFO] [Train] Iter 2131 | Loss 0.029625 | Grad 0.0435 \n","[2023-12-09 07:31:51,550::train::INFO] [Train] Iter 2132 | Loss 0.030462 | Grad 0.0398 \n","[2023-12-09 07:31:51,632::train::INFO] [Train] Iter 2133 | Loss 0.030550 | Grad 0.0317 \n","[2023-12-09 07:31:51,714::train::INFO] [Train] Iter 2134 | Loss 0.030588 | Grad 0.0777 \n","[2023-12-09 07:31:51,802::train::INFO] [Train] Iter 2135 | Loss 0.033014 | Grad 0.0461 \n","[2023-12-09 07:31:51,884::train::INFO] [Train] Iter 2136 | Loss 0.027714 | Grad 0.0602 \n","[2023-12-09 07:31:51,968::train::INFO] [Train] Iter 2137 | Loss 0.030850 | Grad 0.0395 \n","[2023-12-09 07:31:52,050::train::INFO] [Train] Iter 2138 | Loss 0.030248 | Grad 0.0513 \n","[2023-12-09 07:31:52,134::train::INFO] [Train] Iter 2139 | Loss 0.029615 | Grad 0.0759 \n","[2023-12-09 07:31:52,220::train::INFO] [Train] Iter 2140 | Loss 0.032305 | Grad 0.0480 \n","[2023-12-09 07:31:52,303::train::INFO] [Train] Iter 2141 | Loss 0.030635 | Grad 0.0357 \n","[2023-12-09 07:31:52,387::train::INFO] [Train] Iter 2142 | Loss 0.030362 | Grad 0.0424 \n","[2023-12-09 07:31:52,475::train::INFO] [Train] Iter 2143 | Loss 0.030638 | Grad 0.0566 \n","[2023-12-09 07:31:52,558::train::INFO] [Train] Iter 2144 | Loss 0.030306 | Grad 0.0351 \n","[2023-12-09 07:31:52,640::train::INFO] [Train] Iter 2145 | Loss 0.030974 | Grad 0.0437 \n","[2023-12-09 07:31:52,723::train::INFO] [Train] Iter 2146 | Loss 0.031697 | Grad 0.0344 \n","[2023-12-09 07:31:52,806::train::INFO] [Train] Iter 2147 | Loss 0.028424 | Grad 0.0529 \n","[2023-12-09 07:31:52,889::train::INFO] [Train] Iter 2148 | Loss 0.031401 | Grad 0.0429 \n","[2023-12-09 07:31:52,972::train::INFO] [Train] Iter 2149 | Loss 0.033802 | Grad 0.0774 \n","[2023-12-09 07:31:53,055::train::INFO] [Train] Iter 2150 | Loss 0.030250 | Grad 0.0432 \n","[2023-12-09 07:31:53,138::train::INFO] [Train] Iter 2151 | Loss 0.031905 | Grad 0.0343 \n","[2023-12-09 07:31:53,220::train::INFO] [Train] Iter 2152 | Loss 0.030069 | Grad 0.0481 \n","[2023-12-09 07:31:53,306::train::INFO] [Train] Iter 2153 | Loss 0.030003 | Grad 0.0461 \n","[2023-12-09 07:31:53,390::train::INFO] [Train] Iter 2154 | Loss 0.031095 | Grad 0.0544 \n","[2023-12-09 07:31:53,473::train::INFO] [Train] Iter 2155 | Loss 0.030084 | Grad 0.0466 \n","[2023-12-09 07:31:53,556::train::INFO] [Train] Iter 2156 | Loss 0.030961 | Grad 0.0519 \n","[2023-12-09 07:31:53,647::train::INFO] [Train] Iter 2157 | Loss 0.031097 | Grad 0.0347 \n","[2023-12-09 07:31:53,738::train::INFO] [Train] Iter 2158 | Loss 0.030293 | Grad 0.0755 \n","[2023-12-09 07:31:53,831::train::INFO] [Train] Iter 2159 | Loss 0.027318 | Grad 0.0352 \n","[2023-12-09 07:31:53,921::train::INFO] [Train] Iter 2160 | Loss 0.031566 | Grad 0.0354 \n","[2023-12-09 07:31:54,009::train::INFO] [Train] Iter 2161 | Loss 0.029931 | Grad 0.0485 \n","[2023-12-09 07:31:54,100::train::INFO] [Train] Iter 2162 | Loss 0.028378 | Grad 0.0444 \n","[2023-12-09 07:31:54,191::train::INFO] [Train] Iter 2163 | Loss 0.028801 | Grad 0.0412 \n","[2023-12-09 07:31:54,281::train::INFO] [Train] Iter 2164 | Loss 0.031003 | Grad 0.0645 \n","[2023-12-09 07:31:54,376::train::INFO] [Train] Iter 2165 | Loss 0.030620 | Grad 0.0402 \n","[2023-12-09 07:31:54,467::train::INFO] [Train] Iter 2166 | Loss 0.030579 | Grad 0.0527 \n","[2023-12-09 07:31:54,560::train::INFO] [Train] Iter 2167 | Loss 0.029086 | Grad 0.0255 \n","[2023-12-09 07:31:54,649::train::INFO] [Train] Iter 2168 | Loss 0.030464 | Grad 0.0387 \n","[2023-12-09 07:31:54,742::train::INFO] [Train] Iter 2169 | Loss 0.031157 | Grad 0.0451 \n","[2023-12-09 07:31:54,832::train::INFO] [Train] Iter 2170 | Loss 0.028669 | Grad 0.0589 \n","[2023-12-09 07:31:54,925::train::INFO] [Train] Iter 2171 | Loss 0.031200 | Grad 0.0313 \n","[2023-12-09 07:31:55,021::train::INFO] [Train] Iter 2172 | Loss 0.031091 | Grad 0.0536 \n","[2023-12-09 07:31:55,113::train::INFO] [Train] Iter 2173 | Loss 0.030177 | Grad 0.0446 \n","[2023-12-09 07:31:55,204::train::INFO] [Train] Iter 2174 | Loss 0.029219 | Grad 0.0698 \n","[2023-12-09 07:31:55,295::train::INFO] [Train] Iter 2175 | Loss 0.029617 | Grad 0.0476 \n","[2023-12-09 07:31:55,386::train::INFO] [Train] Iter 2176 | Loss 0.029009 | Grad 0.0902 \n","[2023-12-09 07:31:55,477::train::INFO] [Train] Iter 2177 | Loss 0.029685 | Grad 0.0644 \n","[2023-12-09 07:31:55,568::train::INFO] [Train] Iter 2178 | Loss 0.029869 | Grad 0.0727 \n","[2023-12-09 07:31:55,660::train::INFO] [Train] Iter 2179 | Loss 0.030739 | Grad 0.0652 \n","[2023-12-09 07:31:55,748::train::INFO] [Train] Iter 2180 | Loss 0.030746 | Grad 0.0825 \n","[2023-12-09 07:31:55,837::train::INFO] [Train] Iter 2181 | Loss 0.031524 | Grad 0.0894 \n","[2023-12-09 07:31:55,929::train::INFO] [Train] Iter 2182 | Loss 0.030147 | Grad 0.0357 \n","[2023-12-09 07:31:56,018::train::INFO] [Train] Iter 2183 | Loss 0.032547 | Grad 0.0519 \n","[2023-12-09 07:31:56,107::train::INFO] [Train] Iter 2184 | Loss 0.031163 | Grad 0.0796 \n","[2023-12-09 07:31:56,197::train::INFO] [Train] Iter 2185 | Loss 0.033438 | Grad 0.0648 \n","[2023-12-09 07:31:56,287::train::INFO] [Train] Iter 2186 | Loss 0.031642 | Grad 0.0623 \n","[2023-12-09 07:31:56,378::train::INFO] [Train] Iter 2187 | Loss 0.030320 | Grad 0.0453 \n","[2023-12-09 07:31:56,466::train::INFO] [Train] Iter 2188 | Loss 0.031225 | Grad 0.0679 \n","[2023-12-09 07:31:56,558::train::INFO] [Train] Iter 2189 | Loss 0.031803 | Grad 0.0581 \n","[2023-12-09 07:31:56,649::train::INFO] [Train] Iter 2190 | Loss 0.032921 | Grad 0.0718 \n","[2023-12-09 07:31:56,740::train::INFO] [Train] Iter 2191 | Loss 0.032795 | Grad 0.0567 \n","[2023-12-09 07:31:56,829::train::INFO] [Train] Iter 2192 | Loss 0.032066 | Grad 0.0728 \n","[2023-12-09 07:31:56,920::train::INFO] [Train] Iter 2193 | Loss 0.029886 | Grad 0.0505 \n","[2023-12-09 07:31:57,009::train::INFO] [Train] Iter 2194 | Loss 0.030061 | Grad 0.0945 \n","[2023-12-09 07:31:57,099::train::INFO] [Train] Iter 2195 | Loss 0.030755 | Grad 0.0424 \n","[2023-12-09 07:31:57,189::train::INFO] [Train] Iter 2196 | Loss 0.031591 | Grad 0.0553 \n","[2023-12-09 07:31:57,279::train::INFO] [Train] Iter 2197 | Loss 0.028668 | Grad 0.0715 \n","[2023-12-09 07:31:57,372::train::INFO] [Train] Iter 2198 | Loss 0.030486 | Grad 0.0663 \n","[2023-12-09 07:31:57,463::train::INFO] [Train] Iter 2199 | Loss 0.028913 | Grad 0.0549 \n","[2023-12-09 07:31:57,559::train::INFO] [Train] Iter 2200 | Loss 0.029889 | Grad 0.0382 \n","[2023-12-09 07:31:57,649::train::INFO] [Train] Iter 2201 | Loss 0.030234 | Grad 0.0652 \n","[2023-12-09 07:31:57,751::train::INFO] [Train] Iter 2202 | Loss 0.030903 | Grad 0.0631 \n","[2023-12-09 07:31:57,850::train::INFO] [Train] Iter 2203 | Loss 0.032348 | Grad 0.0574 \n","[2023-12-09 07:31:57,942::train::INFO] [Train] Iter 2204 | Loss 0.031621 | Grad 0.0396 \n","[2023-12-09 07:31:58,032::train::INFO] [Train] Iter 2205 | Loss 0.029820 | Grad 0.0606 \n","[2023-12-09 07:31:58,127::train::INFO] [Train] Iter 2206 | Loss 0.030922 | Grad 0.0675 \n","[2023-12-09 07:31:58,217::train::INFO] [Train] Iter 2207 | Loss 0.029842 | Grad 0.0407 \n","[2023-12-09 07:31:58,308::train::INFO] [Train] Iter 2208 | Loss 0.031425 | Grad 0.0712 \n","[2023-12-09 07:31:58,399::train::INFO] [Train] Iter 2209 | Loss 0.028283 | Grad 0.0710 \n","[2023-12-09 07:31:58,489::train::INFO] [Train] Iter 2210 | Loss 0.028628 | Grad 0.0532 \n","[2023-12-09 07:31:58,579::train::INFO] [Train] Iter 2211 | Loss 0.029590 | Grad 0.0587 \n","[2023-12-09 07:31:58,668::train::INFO] [Train] Iter 2212 | Loss 0.033062 | Grad 0.0425 \n","[2023-12-09 07:31:58,769::train::INFO] [Train] Iter 2213 | Loss 0.032743 | Grad 0.0807 \n","[2023-12-09 07:31:58,860::train::INFO] [Train] Iter 2214 | Loss 0.030175 | Grad 0.0544 \n","[2023-12-09 07:31:58,950::train::INFO] [Train] Iter 2215 | Loss 0.030348 | Grad 0.0396 \n","[2023-12-09 07:31:59,048::train::INFO] [Train] Iter 2216 | Loss 0.028960 | Grad 0.0458 \n","[2023-12-09 07:31:59,142::train::INFO] [Train] Iter 2217 | Loss 0.028996 | Grad 0.0351 \n","[2023-12-09 07:31:59,231::train::INFO] [Train] Iter 2218 | Loss 0.028329 | Grad 0.0631 \n","[2023-12-09 07:31:59,321::train::INFO] [Train] Iter 2219 | Loss 0.028287 | Grad 0.0418 \n","[2023-12-09 07:31:59,409::train::INFO] [Train] Iter 2220 | Loss 0.031119 | Grad 0.0564 \n","[2023-12-09 07:31:59,501::train::INFO] [Train] Iter 2221 | Loss 0.032453 | Grad 0.0624 \n","[2023-12-09 07:31:59,591::train::INFO] [Train] Iter 2222 | Loss 0.029347 | Grad 0.0413 \n","[2023-12-09 07:31:59,693::train::INFO] [Train] Iter 2223 | Loss 0.028339 | Grad 0.0372 \n","[2023-12-09 07:31:59,783::train::INFO] [Train] Iter 2224 | Loss 0.031403 | Grad 0.0691 \n","[2023-12-09 07:31:59,876::train::INFO] [Train] Iter 2225 | Loss 0.028952 | Grad 0.0491 \n","[2023-12-09 07:31:59,960::train::INFO] [Train] Iter 2226 | Loss 0.031323 | Grad 0.0394 \n","[2023-12-09 07:32:00,043::train::INFO] [Train] Iter 2227 | Loss 0.028774 | Grad 0.0298 \n","[2023-12-09 07:32:00,126::train::INFO] [Train] Iter 2228 | Loss 0.031196 | Grad 0.0338 \n","[2023-12-09 07:32:00,211::train::INFO] [Train] Iter 2229 | Loss 0.030542 | Grad 0.0691 \n","[2023-12-09 07:32:00,294::train::INFO] [Train] Iter 2230 | Loss 0.031137 | Grad 0.0380 \n","[2023-12-09 07:32:00,376::train::INFO] [Train] Iter 2231 | Loss 0.031521 | Grad 0.0606 \n","[2023-12-09 07:32:00,459::train::INFO] [Train] Iter 2232 | Loss 0.029684 | Grad 0.0711 \n","[2023-12-09 07:32:00,557::train::INFO] [Train] Iter 2233 | Loss 0.029751 | Grad 0.0459 \n","[2023-12-09 07:32:00,639::train::INFO] [Train] Iter 2234 | Loss 0.029864 | Grad 0.0430 \n","[2023-12-09 07:32:00,722::train::INFO] [Train] Iter 2235 | Loss 0.031766 | Grad 0.0538 \n","[2023-12-09 07:32:00,805::train::INFO] [Train] Iter 2236 | Loss 0.031705 | Grad 0.0432 \n","[2023-12-09 07:32:00,888::train::INFO] [Train] Iter 2237 | Loss 0.029769 | Grad 0.0637 \n","[2023-12-09 07:32:00,970::train::INFO] [Train] Iter 2238 | Loss 0.029153 | Grad 0.0467 \n","[2023-12-09 07:32:01,056::train::INFO] [Train] Iter 2239 | Loss 0.030985 | Grad 0.0410 \n","[2023-12-09 07:32:01,138::train::INFO] [Train] Iter 2240 | Loss 0.028200 | Grad 0.0418 \n","[2023-12-09 07:32:01,221::train::INFO] [Train] Iter 2241 | Loss 0.029028 | Grad 0.0432 \n","[2023-12-09 07:32:01,305::train::INFO] [Train] Iter 2242 | Loss 0.030506 | Grad 0.0448 \n","[2023-12-09 07:32:01,391::train::INFO] [Train] Iter 2243 | Loss 0.031275 | Grad 0.0416 \n","[2023-12-09 07:32:01,474::train::INFO] [Train] Iter 2244 | Loss 0.029765 | Grad 0.0408 \n","[2023-12-09 07:32:01,555::train::INFO] [Train] Iter 2245 | Loss 0.029739 | Grad 0.0554 \n","[2023-12-09 07:32:01,638::train::INFO] [Train] Iter 2246 | Loss 0.029753 | Grad 0.0570 \n","[2023-12-09 07:32:01,721::train::INFO] [Train] Iter 2247 | Loss 0.029933 | Grad 0.0391 \n","[2023-12-09 07:32:01,805::train::INFO] [Train] Iter 2248 | Loss 0.029992 | Grad 0.0448 \n","[2023-12-09 07:32:01,889::train::INFO] [Train] Iter 2249 | Loss 0.028745 | Grad 0.0449 \n","[2023-12-09 07:32:01,972::train::INFO] [Train] Iter 2250 | Loss 0.032603 | Grad 0.0555 \n","[2023-12-09 07:32:02,055::train::INFO] [Train] Iter 2251 | Loss 0.031865 | Grad 0.0438 \n","[2023-12-09 07:32:02,137::train::INFO] [Train] Iter 2252 | Loss 0.029389 | Grad 0.0510 \n","[2023-12-09 07:32:02,221::train::INFO] [Train] Iter 2253 | Loss 0.030400 | Grad 0.0393 \n","[2023-12-09 07:32:02,303::train::INFO] [Train] Iter 2254 | Loss 0.031353 | Grad 0.0399 \n","[2023-12-09 07:32:02,387::train::INFO] [Train] Iter 2255 | Loss 0.029076 | Grad 0.0457 \n","[2023-12-09 07:32:02,469::train::INFO] [Train] Iter 2256 | Loss 0.031767 | Grad 0.0552 \n","[2023-12-09 07:32:02,553::train::INFO] [Train] Iter 2257 | Loss 0.029694 | Grad 0.0480 \n","[2023-12-09 07:32:02,635::train::INFO] [Train] Iter 2258 | Loss 0.032840 | Grad 0.0343 \n","[2023-12-09 07:32:02,718::train::INFO] [Train] Iter 2259 | Loss 0.029435 | Grad 0.0407 \n","[2023-12-09 07:32:02,800::train::INFO] [Train] Iter 2260 | Loss 0.031256 | Grad 0.0621 \n","[2023-12-09 07:32:02,888::train::INFO] [Train] Iter 2261 | Loss 0.029600 | Grad 0.0446 \n","[2023-12-09 07:32:02,972::train::INFO] [Train] Iter 2262 | Loss 0.029276 | Grad 0.0345 \n","[2023-12-09 07:32:03,058::train::INFO] [Train] Iter 2263 | Loss 0.030016 | Grad 0.0504 \n","[2023-12-09 07:32:03,141::train::INFO] [Train] Iter 2264 | Loss 0.030873 | Grad 0.0557 \n","[2023-12-09 07:32:03,224::train::INFO] [Train] Iter 2265 | Loss 0.030148 | Grad 0.0637 \n","[2023-12-09 07:32:03,306::train::INFO] [Train] Iter 2266 | Loss 0.030998 | Grad 0.0416 \n","[2023-12-09 07:32:03,389::train::INFO] [Train] Iter 2267 | Loss 0.030882 | Grad 0.0413 \n","[2023-12-09 07:32:03,475::train::INFO] [Train] Iter 2268 | Loss 0.028231 | Grad 0.0364 \n","[2023-12-09 07:32:03,558::train::INFO] [Train] Iter 2269 | Loss 0.031433 | Grad 0.0565 \n","[2023-12-09 07:32:03,640::train::INFO] [Train] Iter 2270 | Loss 0.028302 | Grad 0.0406 \n","[2023-12-09 07:32:03,723::train::INFO] [Train] Iter 2271 | Loss 0.030941 | Grad 0.0426 \n","[2023-12-09 07:32:03,805::train::INFO] [Train] Iter 2272 | Loss 0.030206 | Grad 0.0519 \n","[2023-12-09 07:32:03,890::train::INFO] [Train] Iter 2273 | Loss 0.031940 | Grad 0.0447 \n","[2023-12-09 07:32:03,973::train::INFO] [Train] Iter 2274 | Loss 0.029985 | Grad 0.0546 \n","[2023-12-09 07:32:04,055::train::INFO] [Train] Iter 2275 | Loss 0.030286 | Grad 0.0508 \n","[2023-12-09 07:32:04,137::train::INFO] [Train] Iter 2276 | Loss 0.030446 | Grad 0.0426 \n","[2023-12-09 07:32:04,220::train::INFO] [Train] Iter 2277 | Loss 0.030042 | Grad 0.0645 \n","[2023-12-09 07:32:04,302::train::INFO] [Train] Iter 2278 | Loss 0.028868 | Grad 0.0375 \n","[2023-12-09 07:32:04,386::train::INFO] [Train] Iter 2279 | Loss 0.029602 | Grad 0.0411 \n","[2023-12-09 07:32:04,468::train::INFO] [Train] Iter 2280 | Loss 0.029731 | Grad 0.0349 \n","[2023-12-09 07:32:04,550::train::INFO] [Train] Iter 2281 | Loss 0.030820 | Grad 0.0682 \n","[2023-12-09 07:32:04,633::train::INFO] [Train] Iter 2282 | Loss 0.029138 | Grad 0.0451 \n","[2023-12-09 07:32:04,715::train::INFO] [Train] Iter 2283 | Loss 0.030256 | Grad 0.0417 \n","[2023-12-09 07:32:04,797::train::INFO] [Train] Iter 2284 | Loss 0.032131 | Grad 0.0449 \n","[2023-12-09 07:32:04,882::train::INFO] [Train] Iter 2285 | Loss 0.031416 | Grad 0.0494 \n","[2023-12-09 07:32:04,965::train::INFO] [Train] Iter 2286 | Loss 0.029207 | Grad 0.0409 \n","[2023-12-09 07:32:05,047::train::INFO] [Train] Iter 2287 | Loss 0.027773 | Grad 0.0486 \n","[2023-12-09 07:32:05,129::train::INFO] [Train] Iter 2288 | Loss 0.030481 | Grad 0.0415 \n","[2023-12-09 07:32:05,212::train::INFO] [Train] Iter 2289 | Loss 0.027980 | Grad 0.0510 \n","[2023-12-09 07:32:05,296::train::INFO] [Train] Iter 2290 | Loss 0.027889 | Grad 0.0466 \n","[2023-12-09 07:32:05,382::train::INFO] [Train] Iter 2291 | Loss 0.029642 | Grad 0.0371 \n","[2023-12-09 07:32:05,464::train::INFO] [Train] Iter 2292 | Loss 0.029663 | Grad 0.0502 \n","[2023-12-09 07:32:05,545::train::INFO] [Train] Iter 2293 | Loss 0.031540 | Grad 0.0499 \n","[2023-12-09 07:32:05,628::train::INFO] [Train] Iter 2294 | Loss 0.029605 | Grad 0.0674 \n","[2023-12-09 07:32:05,714::train::INFO] [Train] Iter 2295 | Loss 0.028977 | Grad 0.0377 \n","[2023-12-09 07:32:05,797::train::INFO] [Train] Iter 2296 | Loss 0.028808 | Grad 0.0648 \n","[2023-12-09 07:32:05,880::train::INFO] [Train] Iter 2297 | Loss 0.031017 | Grad 0.0404 \n","[2023-12-09 07:32:05,966::train::INFO] [Train] Iter 2298 | Loss 0.030035 | Grad 0.0442 \n","[2023-12-09 07:32:06,048::train::INFO] [Train] Iter 2299 | Loss 0.031885 | Grad 0.0451 \n","[2023-12-09 07:32:06,131::train::INFO] [Train] Iter 2300 | Loss 0.031971 | Grad 0.0434 \n","[2023-12-09 07:32:06,214::train::INFO] [Train] Iter 2301 | Loss 0.030427 | Grad 0.0509 \n","[2023-12-09 07:32:06,298::train::INFO] [Train] Iter 2302 | Loss 0.031593 | Grad 0.0359 \n","[2023-12-09 07:32:06,380::train::INFO] [Train] Iter 2303 | Loss 0.028542 | Grad 0.0397 \n","[2023-12-09 07:32:06,466::train::INFO] [Train] Iter 2304 | Loss 0.029678 | Grad 0.0453 \n","[2023-12-09 07:32:06,548::train::INFO] [Train] Iter 2305 | Loss 0.030071 | Grad 0.0359 \n","[2023-12-09 07:32:06,631::train::INFO] [Train] Iter 2306 | Loss 0.031872 | Grad 0.0523 \n","[2023-12-09 07:32:06,716::train::INFO] [Train] Iter 2307 | Loss 0.030787 | Grad 0.0510 \n","[2023-12-09 07:32:06,798::train::INFO] [Train] Iter 2308 | Loss 0.030516 | Grad 0.0537 \n","[2023-12-09 07:32:06,882::train::INFO] [Train] Iter 2309 | Loss 0.029294 | Grad 0.0699 \n","[2023-12-09 07:32:06,970::train::INFO] [Train] Iter 2310 | Loss 0.031825 | Grad 0.0439 \n","[2023-12-09 07:32:07,057::train::INFO] [Train] Iter 2311 | Loss 0.031394 | Grad 0.0626 \n","[2023-12-09 07:32:07,140::train::INFO] [Train] Iter 2312 | Loss 0.028294 | Grad 0.0406 \n","[2023-12-09 07:32:07,224::train::INFO] [Train] Iter 2313 | Loss 0.028193 | Grad 0.0451 \n","[2023-12-09 07:32:07,308::train::INFO] [Train] Iter 2314 | Loss 0.029438 | Grad 0.0407 \n","[2023-12-09 07:32:07,392::train::INFO] [Train] Iter 2315 | Loss 0.028277 | Grad 0.0502 \n","[2023-12-09 07:32:07,476::train::INFO] [Train] Iter 2316 | Loss 0.029243 | Grad 0.0405 \n","[2023-12-09 07:32:07,560::train::INFO] [Train] Iter 2317 | Loss 0.029928 | Grad 0.0472 \n","[2023-12-09 07:32:07,643::train::INFO] [Train] Iter 2318 | Loss 0.029581 | Grad 0.0433 \n","[2023-12-09 07:32:07,727::train::INFO] [Train] Iter 2319 | Loss 0.030848 | Grad 0.0686 \n","[2023-12-09 07:32:07,811::train::INFO] [Train] Iter 2320 | Loss 0.029050 | Grad 0.0462 \n","[2023-12-09 07:32:07,896::train::INFO] [Train] Iter 2321 | Loss 0.030083 | Grad 0.0616 \n","[2023-12-09 07:32:07,986::train::INFO] [Train] Iter 2322 | Loss 0.029249 | Grad 0.0577 \n","[2023-12-09 07:32:08,071::train::INFO] [Train] Iter 2323 | Loss 0.028484 | Grad 0.0548 \n","[2023-12-09 07:32:08,155::train::INFO] [Train] Iter 2324 | Loss 0.031089 | Grad 0.0333 \n","[2023-12-09 07:32:08,237::train::INFO] [Train] Iter 2325 | Loss 0.028860 | Grad 0.0565 \n","[2023-12-09 07:32:08,321::train::INFO] [Train] Iter 2326 | Loss 0.028505 | Grad 0.0501 \n","[2023-12-09 07:32:08,406::train::INFO] [Train] Iter 2327 | Loss 0.028142 | Grad 0.0432 \n","[2023-12-09 07:32:08,490::train::INFO] [Train] Iter 2328 | Loss 0.030757 | Grad 0.0517 \n","[2023-12-09 07:32:08,572::train::INFO] [Train] Iter 2329 | Loss 0.029142 | Grad 0.0544 \n","[2023-12-09 07:32:08,654::train::INFO] [Train] Iter 2330 | Loss 0.030250 | Grad 0.0580 \n","[2023-12-09 07:32:08,738::train::INFO] [Train] Iter 2331 | Loss 0.028351 | Grad 0.0484 \n","[2023-12-09 07:32:08,821::train::INFO] [Train] Iter 2332 | Loss 0.029735 | Grad 0.0488 \n","[2023-12-09 07:32:08,904::train::INFO] [Train] Iter 2333 | Loss 0.029652 | Grad 0.0569 \n","[2023-12-09 07:32:08,988::train::INFO] [Train] Iter 2334 | Loss 0.031525 | Grad 0.0704 \n","[2023-12-09 07:32:09,071::train::INFO] [Train] Iter 2335 | Loss 0.029707 | Grad 0.0357 \n","[2023-12-09 07:32:09,155::train::INFO] [Train] Iter 2336 | Loss 0.033751 | Grad 0.0647 \n","[2023-12-09 07:32:09,239::train::INFO] [Train] Iter 2337 | Loss 0.030847 | Grad 0.0586 \n","[2023-12-09 07:32:09,321::train::INFO] [Train] Iter 2338 | Loss 0.026958 | Grad 0.0546 \n","[2023-12-09 07:32:09,409::train::INFO] [Train] Iter 2339 | Loss 0.032218 | Grad 0.0366 \n","[2023-12-09 07:32:09,492::train::INFO] [Train] Iter 2340 | Loss 0.030314 | Grad 0.0473 \n","[2023-12-09 07:32:09,576::train::INFO] [Train] Iter 2341 | Loss 0.027592 | Grad 0.0628 \n","[2023-12-09 07:32:09,658::train::INFO] [Train] Iter 2342 | Loss 0.030670 | Grad 0.0413 \n","[2023-12-09 07:32:09,741::train::INFO] [Train] Iter 2343 | Loss 0.029408 | Grad 0.0668 \n","[2023-12-09 07:32:09,826::train::INFO] [Train] Iter 2344 | Loss 0.029967 | Grad 0.0421 \n","[2023-12-09 07:32:09,913::train::INFO] [Train] Iter 2345 | Loss 0.030061 | Grad 0.0381 \n","[2023-12-09 07:32:10,006::train::INFO] [Train] Iter 2346 | Loss 0.030448 | Grad 0.0420 \n","[2023-12-09 07:32:10,097::train::INFO] [Train] Iter 2347 | Loss 0.029868 | Grad 0.0489 \n","[2023-12-09 07:32:10,188::train::INFO] [Train] Iter 2348 | Loss 0.026742 | Grad 0.0547 \n","[2023-12-09 07:32:10,280::train::INFO] [Train] Iter 2349 | Loss 0.030289 | Grad 0.0386 \n","[2023-12-09 07:32:10,372::train::INFO] [Train] Iter 2350 | Loss 0.031218 | Grad 0.0441 \n","[2023-12-09 07:32:10,464::train::INFO] [Train] Iter 2351 | Loss 0.029186 | Grad 0.0387 \n","[2023-12-09 07:32:10,555::train::INFO] [Train] Iter 2352 | Loss 0.029858 | Grad 0.0452 \n","[2023-12-09 07:32:10,645::train::INFO] [Train] Iter 2353 | Loss 0.030685 | Grad 0.0588 \n","[2023-12-09 07:32:10,741::train::INFO] [Train] Iter 2354 | Loss 0.030460 | Grad 0.0283 \n","[2023-12-09 07:32:10,833::train::INFO] [Train] Iter 2355 | Loss 0.029101 | Grad 0.0526 \n","[2023-12-09 07:32:10,929::train::INFO] [Train] Iter 2356 | Loss 0.029553 | Grad 0.0393 \n","[2023-12-09 07:32:11,019::train::INFO] [Train] Iter 2357 | Loss 0.032005 | Grad 0.0615 \n","[2023-12-09 07:32:11,111::train::INFO] [Train] Iter 2358 | Loss 0.030067 | Grad 0.0704 \n","[2023-12-09 07:32:11,200::train::INFO] [Train] Iter 2359 | Loss 0.029676 | Grad 0.0415 \n","[2023-12-09 07:32:11,290::train::INFO] [Train] Iter 2360 | Loss 0.030891 | Grad 0.0422 \n","[2023-12-09 07:32:11,382::train::INFO] [Train] Iter 2361 | Loss 0.027909 | Grad 0.0440 \n","[2023-12-09 07:32:11,474::train::INFO] [Train] Iter 2362 | Loss 0.031847 | Grad 0.0488 \n","[2023-12-09 07:32:11,564::train::INFO] [Train] Iter 2363 | Loss 0.030106 | Grad 0.0414 \n","[2023-12-09 07:32:11,655::train::INFO] [Train] Iter 2364 | Loss 0.027946 | Grad 0.0489 \n","[2023-12-09 07:32:11,746::train::INFO] [Train] Iter 2365 | Loss 0.030079 | Grad 0.0550 \n","[2023-12-09 07:32:11,846::train::INFO] [Train] Iter 2366 | Loss 0.032335 | Grad 0.0897 \n","[2023-12-09 07:32:11,940::train::INFO] [Train] Iter 2367 | Loss 0.029278 | Grad 0.0437 \n","[2023-12-09 07:32:12,032::train::INFO] [Train] Iter 2368 | Loss 0.030567 | Grad 0.0570 \n","[2023-12-09 07:32:12,127::train::INFO] [Train] Iter 2369 | Loss 0.030612 | Grad 0.0599 \n","[2023-12-09 07:32:12,226::train::INFO] [Train] Iter 2370 | Loss 0.030398 | Grad 0.0514 \n","[2023-12-09 07:32:12,318::train::INFO] [Train] Iter 2371 | Loss 0.027762 | Grad 0.0457 \n","[2023-12-09 07:32:12,413::train::INFO] [Train] Iter 2372 | Loss 0.030111 | Grad 0.0632 \n","[2023-12-09 07:32:12,505::train::INFO] [Train] Iter 2373 | Loss 0.030297 | Grad 0.0481 \n","[2023-12-09 07:32:12,596::train::INFO] [Train] Iter 2374 | Loss 0.031286 | Grad 0.0500 \n","[2023-12-09 07:32:12,689::train::INFO] [Train] Iter 2375 | Loss 0.027979 | Grad 0.0468 \n","[2023-12-09 07:32:12,782::train::INFO] [Train] Iter 2376 | Loss 0.031823 | Grad 0.0645 \n","[2023-12-09 07:32:12,872::train::INFO] [Train] Iter 2377 | Loss 0.031819 | Grad 0.0483 \n","[2023-12-09 07:32:12,962::train::INFO] [Train] Iter 2378 | Loss 0.027682 | Grad 0.0442 \n","[2023-12-09 07:32:13,053::train::INFO] [Train] Iter 2379 | Loss 0.028516 | Grad 0.0687 \n","[2023-12-09 07:32:13,095::train::INFO] [Train] Iter 2380 | Loss 0.028392 | Grad 0.0846 \n","[2023-12-09 07:32:13,185::train::INFO] [Train] Iter 2381 | Loss 0.028308 | Grad 0.0478 \n","[2023-12-09 07:32:13,275::train::INFO] [Train] Iter 2382 | Loss 0.031432 | Grad 0.0610 \n","[2023-12-09 07:32:13,364::train::INFO] [Train] Iter 2383 | Loss 0.029743 | Grad 0.0497 \n","[2023-12-09 07:32:13,455::train::INFO] [Train] Iter 2384 | Loss 0.030589 | Grad 0.0438 \n","[2023-12-09 07:32:13,545::train::INFO] [Train] Iter 2385 | Loss 0.029629 | Grad 0.0492 \n","[2023-12-09 07:32:13,636::train::INFO] [Train] Iter 2386 | Loss 0.031482 | Grad 0.0434 \n","[2023-12-09 07:32:13,727::train::INFO] [Train] Iter 2387 | Loss 0.029743 | Grad 0.0470 \n","[2023-12-09 07:32:13,818::train::INFO] [Train] Iter 2388 | Loss 0.031499 | Grad 0.0447 \n","[2023-12-09 07:32:13,908::train::INFO] [Train] Iter 2389 | Loss 0.030103 | Grad 0.0380 \n","[2023-12-09 07:32:14,001::train::INFO] [Train] Iter 2390 | Loss 0.030868 | Grad 0.0427 \n","[2023-12-09 07:32:14,092::train::INFO] [Train] Iter 2391 | Loss 0.028938 | Grad 0.0423 \n","[2023-12-09 07:32:14,183::train::INFO] [Train] Iter 2392 | Loss 0.031618 | Grad 0.0445 \n","[2023-12-09 07:32:14,279::train::INFO] [Train] Iter 2393 | Loss 0.029970 | Grad 0.0638 \n","[2023-12-09 07:32:14,369::train::INFO] [Train] Iter 2394 | Loss 0.029842 | Grad 0.0429 \n","[2023-12-09 07:32:14,459::train::INFO] [Train] Iter 2395 | Loss 0.030177 | Grad 0.0346 \n","[2023-12-09 07:32:14,549::train::INFO] [Train] Iter 2396 | Loss 0.029647 | Grad 0.0461 \n","[2023-12-09 07:32:14,644::train::INFO] [Train] Iter 2397 | Loss 0.029992 | Grad 0.0538 \n","[2023-12-09 07:32:14,735::train::INFO] [Train] Iter 2398 | Loss 0.029066 | Grad 0.0473 \n","[2023-12-09 07:32:14,826::train::INFO] [Train] Iter 2399 | Loss 0.031752 | Grad 0.0415 \n","[2023-12-09 07:32:14,916::train::INFO] [Train] Iter 2400 | Loss 0.029393 | Grad 0.0759 \n","[2023-12-09 07:32:15,005::train::INFO] [Train] Iter 2401 | Loss 0.028061 | Grad 0.0487 \n","[2023-12-09 07:32:15,096::train::INFO] [Train] Iter 2402 | Loss 0.030820 | Grad 0.0355 \n","[2023-12-09 07:32:15,185::train::INFO] [Train] Iter 2403 | Loss 0.029362 | Grad 0.0545 \n","[2023-12-09 07:32:15,275::train::INFO] [Train] Iter 2404 | Loss 0.029945 | Grad 0.0772 \n","[2023-12-09 07:32:15,364::train::INFO] [Train] Iter 2405 | Loss 0.029228 | Grad 0.0496 \n","[2023-12-09 07:32:15,453::train::INFO] [Train] Iter 2406 | Loss 0.029922 | Grad 0.0554 \n","[2023-12-09 07:32:15,546::train::INFO] [Train] Iter 2407 | Loss 0.031506 | Grad 0.0523 \n","[2023-12-09 07:32:15,636::train::INFO] [Train] Iter 2408 | Loss 0.030578 | Grad 0.0399 \n","[2023-12-09 07:32:15,725::train::INFO] [Train] Iter 2409 | Loss 0.028938 | Grad 0.0501 \n","[2023-12-09 07:32:15,815::train::INFO] [Train] Iter 2410 | Loss 0.030322 | Grad 0.0522 \n","[2023-12-09 07:32:15,906::train::INFO] [Train] Iter 2411 | Loss 0.031652 | Grad 0.0508 \n","[2023-12-09 07:32:15,996::train::INFO] [Train] Iter 2412 | Loss 0.028504 | Grad 0.0338 \n","[2023-12-09 07:32:16,088::train::INFO] [Train] Iter 2413 | Loss 0.031026 | Grad 0.0645 \n","[2023-12-09 07:32:16,178::train::INFO] [Train] Iter 2414 | Loss 0.030203 | Grad 0.0527 \n","[2023-12-09 07:32:16,267::train::INFO] [Train] Iter 2415 | Loss 0.028064 | Grad 0.0477 \n","[2023-12-09 07:32:16,362::train::INFO] [Train] Iter 2416 | Loss 0.031861 | Grad 0.0396 \n","[2023-12-09 07:32:16,448::train::INFO] [Train] Iter 2417 | Loss 0.030022 | Grad 0.0398 \n","[2023-12-09 07:32:16,531::train::INFO] [Train] Iter 2418 | Loss 0.031658 | Grad 0.0378 \n","[2023-12-09 07:32:16,614::train::INFO] [Train] Iter 2419 | Loss 0.028687 | Grad 0.0383 \n","[2023-12-09 07:32:16,696::train::INFO] [Train] Iter 2420 | Loss 0.029828 | Grad 0.0555 \n","[2023-12-09 07:32:16,779::train::INFO] [Train] Iter 2421 | Loss 0.030481 | Grad 0.0469 \n","[2023-12-09 07:32:16,861::train::INFO] [Train] Iter 2422 | Loss 0.029875 | Grad 0.0419 \n","[2023-12-09 07:32:16,948::train::INFO] [Train] Iter 2423 | Loss 0.029862 | Grad 0.0512 \n","[2023-12-09 07:32:17,030::train::INFO] [Train] Iter 2424 | Loss 0.028750 | Grad 0.0312 \n","[2023-12-09 07:32:17,115::train::INFO] [Train] Iter 2425 | Loss 0.030127 | Grad 0.0383 \n","[2023-12-09 07:32:17,200::train::INFO] [Train] Iter 2426 | Loss 0.030224 | Grad 0.0435 \n","[2023-12-09 07:32:17,285::train::INFO] [Train] Iter 2427 | Loss 0.028126 | Grad 0.0355 \n","[2023-12-09 07:32:17,371::train::INFO] [Train] Iter 2428 | Loss 0.028697 | Grad 0.0543 \n","[2023-12-09 07:32:17,462::train::INFO] [Train] Iter 2429 | Loss 0.030722 | Grad 0.0435 \n","[2023-12-09 07:32:17,548::train::INFO] [Train] Iter 2430 | Loss 0.028574 | Grad 0.0397 \n","[2023-12-09 07:32:17,632::train::INFO] [Train] Iter 2431 | Loss 0.032157 | Grad 0.0575 \n","[2023-12-09 07:32:17,716::train::INFO] [Train] Iter 2432 | Loss 0.029363 | Grad 0.0396 \n","[2023-12-09 07:32:17,801::train::INFO] [Train] Iter 2433 | Loss 0.030088 | Grad 0.0482 \n","[2023-12-09 07:32:17,884::train::INFO] [Train] Iter 2434 | Loss 0.029047 | Grad 0.0508 \n","[2023-12-09 07:32:17,971::train::INFO] [Train] Iter 2435 | Loss 0.030394 | Grad 0.0413 \n","[2023-12-09 07:32:18,056::train::INFO] [Train] Iter 2436 | Loss 0.032379 | Grad 0.0563 \n","[2023-12-09 07:32:18,142::train::INFO] [Train] Iter 2437 | Loss 0.029589 | Grad 0.0387 \n","[2023-12-09 07:32:18,224::train::INFO] [Train] Iter 2438 | Loss 0.029555 | Grad 0.0455 \n","[2023-12-09 07:32:18,307::train::INFO] [Train] Iter 2439 | Loss 0.028733 | Grad 0.0394 \n","[2023-12-09 07:32:18,391::train::INFO] [Train] Iter 2440 | Loss 0.027745 | Grad 0.0429 \n","[2023-12-09 07:32:18,474::train::INFO] [Train] Iter 2441 | Loss 0.030932 | Grad 0.0550 \n","[2023-12-09 07:32:18,561::train::INFO] [Train] Iter 2442 | Loss 0.032255 | Grad 0.0496 \n","[2023-12-09 07:32:18,643::train::INFO] [Train] Iter 2443 | Loss 0.029568 | Grad 0.0348 \n","[2023-12-09 07:32:18,726::train::INFO] [Train] Iter 2444 | Loss 0.031363 | Grad 0.0462 \n","[2023-12-09 07:32:18,808::train::INFO] [Train] Iter 2445 | Loss 0.031415 | Grad 0.0496 \n","[2023-12-09 07:32:18,891::train::INFO] [Train] Iter 2446 | Loss 0.029446 | Grad 0.0624 \n","[2023-12-09 07:32:18,976::train::INFO] [Train] Iter 2447 | Loss 0.030137 | Grad 0.0340 \n","[2023-12-09 07:32:19,059::train::INFO] [Train] Iter 2448 | Loss 0.027973 | Grad 0.0438 \n","[2023-12-09 07:32:19,141::train::INFO] [Train] Iter 2449 | Loss 0.029776 | Grad 0.0402 \n","[2023-12-09 07:32:19,223::train::INFO] [Train] Iter 2450 | Loss 0.029561 | Grad 0.0439 \n","[2023-12-09 07:32:19,309::train::INFO] [Train] Iter 2451 | Loss 0.029890 | Grad 0.0351 \n","[2023-12-09 07:32:19,391::train::INFO] [Train] Iter 2452 | Loss 0.029268 | Grad 0.0459 \n","[2023-12-09 07:32:19,476::train::INFO] [Train] Iter 2453 | Loss 0.029913 | Grad 0.0580 \n","[2023-12-09 07:32:19,560::train::INFO] [Train] Iter 2454 | Loss 0.028899 | Grad 0.0355 \n","[2023-12-09 07:32:19,643::train::INFO] [Train] Iter 2455 | Loss 0.029988 | Grad 0.0438 \n","[2023-12-09 07:32:19,726::train::INFO] [Train] Iter 2456 | Loss 0.028814 | Grad 0.0432 \n","[2023-12-09 07:32:19,809::train::INFO] [Train] Iter 2457 | Loss 0.028878 | Grad 0.0364 \n","[2023-12-09 07:32:19,892::train::INFO] [Train] Iter 2458 | Loss 0.028936 | Grad 0.0501 \n","[2023-12-09 07:32:19,976::train::INFO] [Train] Iter 2459 | Loss 0.030234 | Grad 0.0522 \n","[2023-12-09 07:32:20,059::train::INFO] [Train] Iter 2460 | Loss 0.028727 | Grad 0.0533 \n","[2023-12-09 07:32:20,141::train::INFO] [Train] Iter 2461 | Loss 0.029780 | Grad 0.0444 \n","[2023-12-09 07:32:20,224::train::INFO] [Train] Iter 2462 | Loss 0.027726 | Grad 0.0407 \n","[2023-12-09 07:32:20,306::train::INFO] [Train] Iter 2463 | Loss 0.028550 | Grad 0.0487 \n","[2023-12-09 07:32:20,389::train::INFO] [Train] Iter 2464 | Loss 0.030632 | Grad 0.0343 \n","[2023-12-09 07:32:20,474::train::INFO] [Train] Iter 2465 | Loss 0.030297 | Grad 0.0533 \n","[2023-12-09 07:32:20,557::train::INFO] [Train] Iter 2466 | Loss 0.030391 | Grad 0.0659 \n","[2023-12-09 07:32:20,640::train::INFO] [Train] Iter 2467 | Loss 0.029758 | Grad 0.0524 \n","[2023-12-09 07:32:20,722::train::INFO] [Train] Iter 2468 | Loss 0.030889 | Grad 0.0374 \n","[2023-12-09 07:32:20,806::train::INFO] [Train] Iter 2469 | Loss 0.029397 | Grad 0.0394 \n","[2023-12-09 07:32:20,889::train::INFO] [Train] Iter 2470 | Loss 0.030957 | Grad 0.0688 \n","[2023-12-09 07:32:20,971::train::INFO] [Train] Iter 2471 | Loss 0.028532 | Grad 0.0386 \n","[2023-12-09 07:32:21,056::train::INFO] [Train] Iter 2472 | Loss 0.029437 | Grad 0.0381 \n","[2023-12-09 07:32:21,140::train::INFO] [Train] Iter 2473 | Loss 0.029562 | Grad 0.0354 \n","[2023-12-09 07:32:21,224::train::INFO] [Train] Iter 2474 | Loss 0.029486 | Grad 0.0627 \n","[2023-12-09 07:32:21,307::train::INFO] [Train] Iter 2475 | Loss 0.032014 | Grad 0.0372 \n","[2023-12-09 07:32:21,397::train::INFO] [Train] Iter 2476 | Loss 0.026594 | Grad 0.0464 \n","[2023-12-09 07:32:21,486::train::INFO] [Train] Iter 2477 | Loss 0.029893 | Grad 0.0401 \n","[2023-12-09 07:32:21,570::train::INFO] [Train] Iter 2478 | Loss 0.029133 | Grad 0.0463 \n","[2023-12-09 07:32:21,652::train::INFO] [Train] Iter 2479 | Loss 0.028494 | Grad 0.0617 \n","[2023-12-09 07:32:21,734::train::INFO] [Train] Iter 2480 | Loss 0.031347 | Grad 0.0433 \n","[2023-12-09 07:32:21,818::train::INFO] [Train] Iter 2481 | Loss 0.029527 | Grad 0.0330 \n","[2023-12-09 07:32:21,901::train::INFO] [Train] Iter 2482 | Loss 0.029223 | Grad 0.0379 \n","[2023-12-09 07:32:21,983::train::INFO] [Train] Iter 2483 | Loss 0.029413 | Grad 0.0480 \n","[2023-12-09 07:32:22,067::train::INFO] [Train] Iter 2484 | Loss 0.029254 | Grad 0.0362 \n","[2023-12-09 07:32:22,150::train::INFO] [Train] Iter 2485 | Loss 0.029938 | Grad 0.0416 \n","[2023-12-09 07:32:22,232::train::INFO] [Train] Iter 2486 | Loss 0.030756 | Grad 0.0411 \n","[2023-12-09 07:32:22,319::train::INFO] [Train] Iter 2487 | Loss 0.027183 | Grad 0.0493 \n","[2023-12-09 07:32:22,402::train::INFO] [Train] Iter 2488 | Loss 0.030391 | Grad 0.0352 \n","[2023-12-09 07:32:22,488::train::INFO] [Train] Iter 2489 | Loss 0.032844 | Grad 0.0587 \n","[2023-12-09 07:32:22,572::train::INFO] [Train] Iter 2490 | Loss 0.029182 | Grad 0.0478 \n","[2023-12-09 07:32:22,655::train::INFO] [Train] Iter 2491 | Loss 0.030914 | Grad 0.0304 \n","[2023-12-09 07:32:22,737::train::INFO] [Train] Iter 2492 | Loss 0.029116 | Grad 0.0561 \n","[2023-12-09 07:32:22,819::train::INFO] [Train] Iter 2493 | Loss 0.029052 | Grad 0.0437 \n","[2023-12-09 07:32:22,904::train::INFO] [Train] Iter 2494 | Loss 0.030013 | Grad 0.0468 \n","[2023-12-09 07:32:22,987::train::INFO] [Train] Iter 2495 | Loss 0.029110 | Grad 0.0573 \n","[2023-12-09 07:32:23,069::train::INFO] [Train] Iter 2496 | Loss 0.029963 | Grad 0.0601 \n","[2023-12-09 07:32:23,152::train::INFO] [Train] Iter 2497 | Loss 0.030073 | Grad 0.0333 \n","[2023-12-09 07:32:23,235::train::INFO] [Train] Iter 2498 | Loss 0.029216 | Grad 0.0623 \n","[2023-12-09 07:32:23,320::train::INFO] [Train] Iter 2499 | Loss 0.026261 | Grad 0.0407 \n","[2023-12-09 07:32:23,402::train::INFO] [Train] Iter 2500 | Loss 0.030521 | Grad 0.0329 \n","Validate: 100% 241/241 [00:04<00:00, 60.11it/s]\n","val loss list [tensor(0.0316, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0245, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0320, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0305, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0332, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0258, device='cuda:0'), tensor(0.0328, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0315, device='cuda:0'), tensor(0.0340, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0327, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0334, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0348, device='cuda:0'), tensor(0.0341, device='cuda:0'), tensor(0.0305, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0298, device='cuda:0'), tensor(0.0315, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0327, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0354, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0322, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0328, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0334, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0321, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0249, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0312, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0328, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0228, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0321, device='cuda:0'), tensor(0.0235, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0303, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0305, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0305, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0347, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0317, device='cuda:0'), tensor(0.0334, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0326, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0303, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0327, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0350, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0339, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0311, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0341, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0320, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0330, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0213, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0332, device='cuda:0'), tensor(0.0319, device='cuda:0'), tensor(0.0227, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0333, device='cuda:0')]\n","[2023-12-09 07:32:27,723::train::INFO] [Train] Iter 2501 | Loss 0.028812 | Grad 0.0392 \n","[2023-12-09 07:32:27,810::train::INFO] [Train] Iter 2502 | Loss 0.027196 | Grad 0.0399 \n","[2023-12-09 07:32:27,900::train::INFO] [Train] Iter 2503 | Loss 0.027810 | Grad 0.0356 \n","[2023-12-09 07:32:27,992::train::INFO] [Train] Iter 2504 | Loss 0.029959 | Grad 0.0552 \n","[2023-12-09 07:32:28,083::train::INFO] [Train] Iter 2505 | Loss 0.029482 | Grad 0.0448 \n","[2023-12-09 07:32:28,174::train::INFO] [Train] Iter 2506 | Loss 0.029651 | Grad 0.0486 \n","[2023-12-09 07:32:28,264::train::INFO] [Train] Iter 2507 | Loss 0.028037 | Grad 0.0247 \n","[2023-12-09 07:32:28,355::train::INFO] [Train] Iter 2508 | Loss 0.029363 | Grad 0.0372 \n","[2023-12-09 07:32:28,445::train::INFO] [Train] Iter 2509 | Loss 0.030234 | Grad 0.0420 \n","[2023-12-09 07:32:28,535::train::INFO] [Train] Iter 2510 | Loss 0.027673 | Grad 0.0563 \n","[2023-12-09 07:32:28,626::train::INFO] [Train] Iter 2511 | Loss 0.030233 | Grad 0.0316 \n","[2023-12-09 07:32:28,715::train::INFO] [Train] Iter 2512 | Loss 0.030084 | Grad 0.0456 \n","[2023-12-09 07:32:28,803::train::INFO] [Train] Iter 2513 | Loss 0.029269 | Grad 0.0389 \n","[2023-12-09 07:32:28,892::train::INFO] [Train] Iter 2514 | Loss 0.028197 | Grad 0.0609 \n","[2023-12-09 07:32:28,985::train::INFO] [Train] Iter 2515 | Loss 0.028581 | Grad 0.0378 \n","[2023-12-09 07:32:29,075::train::INFO] [Train] Iter 2516 | Loss 0.027838 | Grad 0.0712 \n","[2023-12-09 07:32:29,162::train::INFO] [Train] Iter 2517 | Loss 0.028645 | Grad 0.0552 \n","[2023-12-09 07:32:29,253::train::INFO] [Train] Iter 2518 | Loss 0.028844 | Grad 0.0661 \n","[2023-12-09 07:32:29,341::train::INFO] [Train] Iter 2519 | Loss 0.029669 | Grad 0.0647 \n","[2023-12-09 07:32:29,433::train::INFO] [Train] Iter 2520 | Loss 0.029687 | Grad 0.0690 \n","[2023-12-09 07:32:29,523::train::INFO] [Train] Iter 2521 | Loss 0.030535 | Grad 0.0712 \n","[2023-12-09 07:32:29,613::train::INFO] [Train] Iter 2522 | Loss 0.029271 | Grad 0.0370 \n","[2023-12-09 07:32:29,704::train::INFO] [Train] Iter 2523 | Loss 0.031561 | Grad 0.0413 \n","[2023-12-09 07:32:29,795::train::INFO] [Train] Iter 2524 | Loss 0.029993 | Grad 0.0623 \n","[2023-12-09 07:32:29,886::train::INFO] [Train] Iter 2525 | Loss 0.032464 | Grad 0.0555 \n","[2023-12-09 07:32:29,977::train::INFO] [Train] Iter 2526 | Loss 0.030612 | Grad 0.0570 \n","[2023-12-09 07:32:30,070::train::INFO] [Train] Iter 2527 | Loss 0.029208 | Grad 0.0389 \n","[2023-12-09 07:32:30,162::train::INFO] [Train] Iter 2528 | Loss 0.030137 | Grad 0.0596 \n","[2023-12-09 07:32:30,252::train::INFO] [Train] Iter 2529 | Loss 0.030797 | Grad 0.0489 \n","[2023-12-09 07:32:30,343::train::INFO] [Train] Iter 2530 | Loss 0.032027 | Grad 0.0679 \n","[2023-12-09 07:32:30,433::train::INFO] [Train] Iter 2531 | Loss 0.031839 | Grad 0.0483 \n","[2023-12-09 07:32:30,522::train::INFO] [Train] Iter 2532 | Loss 0.031150 | Grad 0.0781 \n","[2023-12-09 07:32:30,613::train::INFO] [Train] Iter 2533 | Loss 0.028864 | Grad 0.0370 \n","[2023-12-09 07:32:30,703::train::INFO] [Train] Iter 2534 | Loss 0.029052 | Grad 0.0651 \n","[2023-12-09 07:32:30,794::train::INFO] [Train] Iter 2535 | Loss 0.029907 | Grad 0.0417 \n","[2023-12-09 07:32:30,890::train::INFO] [Train] Iter 2536 | Loss 0.030703 | Grad 0.0327 \n","[2023-12-09 07:32:30,982::train::INFO] [Train] Iter 2537 | Loss 0.027487 | Grad 0.0416 \n","[2023-12-09 07:32:31,072::train::INFO] [Train] Iter 2538 | Loss 0.029689 | Grad 0.0671 \n","[2023-12-09 07:32:31,163::train::INFO] [Train] Iter 2539 | Loss 0.027659 | Grad 0.0443 \n","[2023-12-09 07:32:31,259::train::INFO] [Train] Iter 2540 | Loss 0.028922 | Grad 0.0529 \n","[2023-12-09 07:32:31,350::train::INFO] [Train] Iter 2541 | Loss 0.029204 | Grad 0.0772 \n","[2023-12-09 07:32:31,450::train::INFO] [Train] Iter 2542 | Loss 0.029970 | Grad 0.0385 \n","[2023-12-09 07:32:31,540::train::INFO] [Train] Iter 2543 | Loss 0.031539 | Grad 0.0579 \n","[2023-12-09 07:32:31,630::train::INFO] [Train] Iter 2544 | Loss 0.030919 | Grad 0.0500 \n","[2023-12-09 07:32:31,719::train::INFO] [Train] Iter 2545 | Loss 0.028694 | Grad 0.0450 \n","[2023-12-09 07:32:31,809::train::INFO] [Train] Iter 2546 | Loss 0.029943 | Grad 0.0631 \n","[2023-12-09 07:32:31,898::train::INFO] [Train] Iter 2547 | Loss 0.028892 | Grad 0.0388 \n","[2023-12-09 07:32:31,993::train::INFO] [Train] Iter 2548 | Loss 0.030675 | Grad 0.0655 \n","[2023-12-09 07:32:32,085::train::INFO] [Train] Iter 2549 | Loss 0.027159 | Grad 0.0553 \n","[2023-12-09 07:32:32,175::train::INFO] [Train] Iter 2550 | Loss 0.027411 | Grad 0.0435 \n","[2023-12-09 07:32:32,268::train::INFO] [Train] Iter 2551 | Loss 0.028746 | Grad 0.0736 \n","[2023-12-09 07:32:32,362::train::INFO] [Train] Iter 2552 | Loss 0.032180 | Grad 0.0396 \n","[2023-12-09 07:32:32,452::train::INFO] [Train] Iter 2553 | Loss 0.031528 | Grad 0.0618 \n","[2023-12-09 07:32:32,541::train::INFO] [Train] Iter 2554 | Loss 0.029052 | Grad 0.0462 \n","[2023-12-09 07:32:32,632::train::INFO] [Train] Iter 2555 | Loss 0.029519 | Grad 0.0419 \n","[2023-12-09 07:32:32,715::train::INFO] [Train] Iter 2556 | Loss 0.028033 | Grad 0.0384 \n","[2023-12-09 07:32:32,797::train::INFO] [Train] Iter 2557 | Loss 0.028059 | Grad 0.0393 \n","[2023-12-09 07:32:32,880::train::INFO] [Train] Iter 2558 | Loss 0.027208 | Grad 0.0393 \n","[2023-12-09 07:32:32,964::train::INFO] [Train] Iter 2559 | Loss 0.027300 | Grad 0.0323 \n","[2023-12-09 07:32:33,047::train::INFO] [Train] Iter 2560 | Loss 0.030249 | Grad 0.0504 \n","[2023-12-09 07:32:33,131::train::INFO] [Train] Iter 2561 | Loss 0.031439 | Grad 0.0562 \n","[2023-12-09 07:32:33,214::train::INFO] [Train] Iter 2562 | Loss 0.028200 | Grad 0.0326 \n","[2023-12-09 07:32:33,296::train::INFO] [Train] Iter 2563 | Loss 0.027354 | Grad 0.0430 \n","[2023-12-09 07:32:33,378::train::INFO] [Train] Iter 2564 | Loss 0.030418 | Grad 0.0632 \n","[2023-12-09 07:32:33,460::train::INFO] [Train] Iter 2565 | Loss 0.027964 | Grad 0.0374 \n","[2023-12-09 07:32:33,544::train::INFO] [Train] Iter 2566 | Loss 0.030322 | Grad 0.0374 \n","[2023-12-09 07:32:33,628::train::INFO] [Train] Iter 2567 | Loss 0.027875 | Grad 0.0377 \n","[2023-12-09 07:32:33,710::train::INFO] [Train] Iter 2568 | Loss 0.030363 | Grad 0.0350 \n","[2023-12-09 07:32:33,794::train::INFO] [Train] Iter 2569 | Loss 0.029526 | Grad 0.0546 \n","[2023-12-09 07:32:33,879::train::INFO] [Train] Iter 2570 | Loss 0.030280 | Grad 0.0362 \n","[2023-12-09 07:32:33,962::train::INFO] [Train] Iter 2571 | Loss 0.030428 | Grad 0.0494 \n","[2023-12-09 07:32:34,050::train::INFO] [Train] Iter 2572 | Loss 0.028672 | Grad 0.0690 \n","[2023-12-09 07:32:34,133::train::INFO] [Train] Iter 2573 | Loss 0.028773 | Grad 0.0413 \n","[2023-12-09 07:32:34,215::train::INFO] [Train] Iter 2574 | Loss 0.028960 | Grad 0.0380 \n","[2023-12-09 07:32:34,297::train::INFO] [Train] Iter 2575 | Loss 0.030772 | Grad 0.0436 \n","[2023-12-09 07:32:34,378::train::INFO] [Train] Iter 2576 | Loss 0.030828 | Grad 0.0359 \n","[2023-12-09 07:32:34,466::train::INFO] [Train] Iter 2577 | Loss 0.028841 | Grad 0.0582 \n","[2023-12-09 07:32:34,549::train::INFO] [Train] Iter 2578 | Loss 0.028151 | Grad 0.0404 \n","[2023-12-09 07:32:34,632::train::INFO] [Train] Iter 2579 | Loss 0.030230 | Grad 0.0375 \n","[2023-12-09 07:32:34,714::train::INFO] [Train] Iter 2580 | Loss 0.027190 | Grad 0.0406 \n","[2023-12-09 07:32:34,797::train::INFO] [Train] Iter 2581 | Loss 0.028002 | Grad 0.0479 \n","[2023-12-09 07:32:34,880::train::INFO] [Train] Iter 2582 | Loss 0.029572 | Grad 0.0471 \n","[2023-12-09 07:32:34,963::train::INFO] [Train] Iter 2583 | Loss 0.030441 | Grad 0.0425 \n","[2023-12-09 07:32:35,054::train::INFO] [Train] Iter 2584 | Loss 0.028835 | Grad 0.0391 \n","[2023-12-09 07:32:35,137::train::INFO] [Train] Iter 2585 | Loss 0.028611 | Grad 0.0481 \n","[2023-12-09 07:32:35,220::train::INFO] [Train] Iter 2586 | Loss 0.028765 | Grad 0.0558 \n","[2023-12-09 07:32:35,302::train::INFO] [Train] Iter 2587 | Loss 0.028885 | Grad 0.0340 \n","[2023-12-09 07:32:35,388::train::INFO] [Train] Iter 2588 | Loss 0.028956 | Grad 0.0439 \n","[2023-12-09 07:32:35,472::train::INFO] [Train] Iter 2589 | Loss 0.027852 | Grad 0.0460 \n","[2023-12-09 07:32:35,555::train::INFO] [Train] Iter 2590 | Loss 0.031476 | Grad 0.0514 \n","[2023-12-09 07:32:35,637::train::INFO] [Train] Iter 2591 | Loss 0.030794 | Grad 0.0425 \n","[2023-12-09 07:32:35,719::train::INFO] [Train] Iter 2592 | Loss 0.028462 | Grad 0.0473 \n","[2023-12-09 07:32:35,802::train::INFO] [Train] Iter 2593 | Loss 0.029474 | Grad 0.0415 \n","[2023-12-09 07:32:35,885::train::INFO] [Train] Iter 2594 | Loss 0.030387 | Grad 0.0406 \n","[2023-12-09 07:32:35,972::train::INFO] [Train] Iter 2595 | Loss 0.028087 | Grad 0.0567 \n","[2023-12-09 07:32:36,056::train::INFO] [Train] Iter 2596 | Loss 0.030796 | Grad 0.0381 \n","[2023-12-09 07:32:36,138::train::INFO] [Train] Iter 2597 | Loss 0.028584 | Grad 0.0431 \n","[2023-12-09 07:32:36,221::train::INFO] [Train] Iter 2598 | Loss 0.032023 | Grad 0.0411 \n","[2023-12-09 07:32:36,303::train::INFO] [Train] Iter 2599 | Loss 0.028490 | Grad 0.0381 \n","[2023-12-09 07:32:36,386::train::INFO] [Train] Iter 2600 | Loss 0.030201 | Grad 0.0448 \n","[2023-12-09 07:32:36,469::train::INFO] [Train] Iter 2601 | Loss 0.028832 | Grad 0.0499 \n","[2023-12-09 07:32:36,551::train::INFO] [Train] Iter 2602 | Loss 0.028323 | Grad 0.0390 \n","[2023-12-09 07:32:36,634::train::INFO] [Train] Iter 2603 | Loss 0.029034 | Grad 0.0451 \n","[2023-12-09 07:32:36,718::train::INFO] [Train] Iter 2604 | Loss 0.030025 | Grad 0.0674 \n","[2023-12-09 07:32:36,801::train::INFO] [Train] Iter 2605 | Loss 0.029166 | Grad 0.0604 \n","[2023-12-09 07:32:36,885::train::INFO] [Train] Iter 2606 | Loss 0.030076 | Grad 0.0442 \n","[2023-12-09 07:32:36,970::train::INFO] [Train] Iter 2607 | Loss 0.029966 | Grad 0.0379 \n","[2023-12-09 07:32:37,054::train::INFO] [Train] Iter 2608 | Loss 0.027250 | Grad 0.0312 \n","[2023-12-09 07:32:37,138::train::INFO] [Train] Iter 2609 | Loss 0.030545 | Grad 0.0477 \n","[2023-12-09 07:32:37,220::train::INFO] [Train] Iter 2610 | Loss 0.027267 | Grad 0.0303 \n","[2023-12-09 07:32:37,308::train::INFO] [Train] Iter 2611 | Loss 0.030073 | Grad 0.0458 \n","[2023-12-09 07:32:37,391::train::INFO] [Train] Iter 2612 | Loss 0.029206 | Grad 0.0378 \n","[2023-12-09 07:32:37,473::train::INFO] [Train] Iter 2613 | Loss 0.031151 | Grad 0.0419 \n","[2023-12-09 07:32:37,556::train::INFO] [Train] Iter 2614 | Loss 0.029108 | Grad 0.0471 \n","[2023-12-09 07:32:37,638::train::INFO] [Train] Iter 2615 | Loss 0.029321 | Grad 0.0408 \n","[2023-12-09 07:32:37,722::train::INFO] [Train] Iter 2616 | Loss 0.029444 | Grad 0.0374 \n","[2023-12-09 07:32:37,804::train::INFO] [Train] Iter 2617 | Loss 0.029213 | Grad 0.0589 \n","[2023-12-09 07:32:37,886::train::INFO] [Train] Iter 2618 | Loss 0.027868 | Grad 0.0310 \n","[2023-12-09 07:32:37,968::train::INFO] [Train] Iter 2619 | Loss 0.028704 | Grad 0.0385 \n","[2023-12-09 07:32:38,050::train::INFO] [Train] Iter 2620 | Loss 0.028957 | Grad 0.0356 \n","[2023-12-09 07:32:38,139::train::INFO] [Train] Iter 2621 | Loss 0.029898 | Grad 0.0660 \n","[2023-12-09 07:32:38,222::train::INFO] [Train] Iter 2622 | Loss 0.028250 | Grad 0.0466 \n","[2023-12-09 07:32:38,303::train::INFO] [Train] Iter 2623 | Loss 0.029273 | Grad 0.0387 \n","[2023-12-09 07:32:38,393::train::INFO] [Train] Iter 2624 | Loss 0.031141 | Grad 0.0391 \n","[2023-12-09 07:32:38,475::train::INFO] [Train] Iter 2625 | Loss 0.030525 | Grad 0.0488 \n","[2023-12-09 07:32:38,558::train::INFO] [Train] Iter 2626 | Loss 0.028263 | Grad 0.0369 \n","[2023-12-09 07:32:38,642::train::INFO] [Train] Iter 2627 | Loss 0.026770 | Grad 0.0464 \n","[2023-12-09 07:32:38,726::train::INFO] [Train] Iter 2628 | Loss 0.029522 | Grad 0.0379 \n","[2023-12-09 07:32:38,808::train::INFO] [Train] Iter 2629 | Loss 0.026992 | Grad 0.0434 \n","[2023-12-09 07:32:38,891::train::INFO] [Train] Iter 2630 | Loss 0.026803 | Grad 0.0466 \n","[2023-12-09 07:32:38,972::train::INFO] [Train] Iter 2631 | Loss 0.028677 | Grad 0.0379 \n","[2023-12-09 07:32:39,055::train::INFO] [Train] Iter 2632 | Loss 0.028594 | Grad 0.0414 \n","[2023-12-09 07:32:39,138::train::INFO] [Train] Iter 2633 | Loss 0.030585 | Grad 0.0419 \n","[2023-12-09 07:32:39,224::train::INFO] [Train] Iter 2634 | Loss 0.028606 | Grad 0.0576 \n","[2023-12-09 07:32:39,308::train::INFO] [Train] Iter 2635 | Loss 0.028060 | Grad 0.0414 \n","[2023-12-09 07:32:39,394::train::INFO] [Train] Iter 2636 | Loss 0.027763 | Grad 0.0536 \n","[2023-12-09 07:32:39,477::train::INFO] [Train] Iter 2637 | Loss 0.030099 | Grad 0.0429 \n","[2023-12-09 07:32:39,558::train::INFO] [Train] Iter 2638 | Loss 0.029144 | Grad 0.0431 \n","[2023-12-09 07:32:39,640::train::INFO] [Train] Iter 2639 | Loss 0.031063 | Grad 0.0416 \n","[2023-12-09 07:32:39,724::train::INFO] [Train] Iter 2640 | Loss 0.031022 | Grad 0.0412 \n","[2023-12-09 07:32:39,807::train::INFO] [Train] Iter 2641 | Loss 0.029467 | Grad 0.0447 \n","[2023-12-09 07:32:39,889::train::INFO] [Train] Iter 2642 | Loss 0.030707 | Grad 0.0357 \n","[2023-12-09 07:32:39,972::train::INFO] [Train] Iter 2643 | Loss 0.027712 | Grad 0.0413 \n","[2023-12-09 07:32:40,054::train::INFO] [Train] Iter 2644 | Loss 0.028771 | Grad 0.0535 \n","[2023-12-09 07:32:40,138::train::INFO] [Train] Iter 2645 | Loss 0.029140 | Grad 0.0295 \n","[2023-12-09 07:32:40,222::train::INFO] [Train] Iter 2646 | Loss 0.031013 | Grad 0.0392 \n","[2023-12-09 07:32:40,307::train::INFO] [Train] Iter 2647 | Loss 0.029798 | Grad 0.0456 \n","[2023-12-09 07:32:40,390::train::INFO] [Train] Iter 2648 | Loss 0.029611 | Grad 0.0448 \n","[2023-12-09 07:32:40,474::train::INFO] [Train] Iter 2649 | Loss 0.028253 | Grad 0.0567 \n","[2023-12-09 07:32:40,557::train::INFO] [Train] Iter 2650 | Loss 0.030946 | Grad 0.0427 \n","[2023-12-09 07:32:40,640::train::INFO] [Train] Iter 2651 | Loss 0.030494 | Grad 0.0609 \n","[2023-12-09 07:32:40,723::train::INFO] [Train] Iter 2652 | Loss 0.027267 | Grad 0.0400 \n","[2023-12-09 07:32:40,808::train::INFO] [Train] Iter 2653 | Loss 0.027186 | Grad 0.0404 \n","[2023-12-09 07:32:40,891::train::INFO] [Train] Iter 2654 | Loss 0.028493 | Grad 0.0458 \n","[2023-12-09 07:32:40,974::train::INFO] [Train] Iter 2655 | Loss 0.027260 | Grad 0.0461 \n","[2023-12-09 07:32:41,056::train::INFO] [Train] Iter 2656 | Loss 0.028421 | Grad 0.0401 \n","[2023-12-09 07:32:41,138::train::INFO] [Train] Iter 2657 | Loss 0.029048 | Grad 0.0431 \n","[2023-12-09 07:32:41,222::train::INFO] [Train] Iter 2658 | Loss 0.028561 | Grad 0.0437 \n","[2023-12-09 07:32:41,307::train::INFO] [Train] Iter 2659 | Loss 0.029857 | Grad 0.0572 \n","[2023-12-09 07:32:41,390::train::INFO] [Train] Iter 2660 | Loss 0.028128 | Grad 0.0423 \n","[2023-12-09 07:32:41,472::train::INFO] [Train] Iter 2661 | Loss 0.029317 | Grad 0.0683 \n","[2023-12-09 07:32:41,555::train::INFO] [Train] Iter 2662 | Loss 0.028265 | Grad 0.0495 \n","[2023-12-09 07:32:41,640::train::INFO] [Train] Iter 2663 | Loss 0.027490 | Grad 0.0426 \n","[2023-12-09 07:32:41,724::train::INFO] [Train] Iter 2664 | Loss 0.030182 | Grad 0.0362 \n","[2023-12-09 07:32:41,808::train::INFO] [Train] Iter 2665 | Loss 0.027781 | Grad 0.0460 \n","[2023-12-09 07:32:41,891::train::INFO] [Train] Iter 2666 | Loss 0.027659 | Grad 0.0376 \n","[2023-12-09 07:32:41,976::train::INFO] [Train] Iter 2667 | Loss 0.027223 | Grad 0.0420 \n","[2023-12-09 07:32:42,058::train::INFO] [Train] Iter 2668 | Loss 0.029849 | Grad 0.0473 \n","[2023-12-09 07:32:42,145::train::INFO] [Train] Iter 2669 | Loss 0.028100 | Grad 0.0506 \n","[2023-12-09 07:32:42,235::train::INFO] [Train] Iter 2670 | Loss 0.029311 | Grad 0.0503 \n","[2023-12-09 07:32:42,318::train::INFO] [Train] Iter 2671 | Loss 0.027441 | Grad 0.0464 \n","[2023-12-09 07:32:42,400::train::INFO] [Train] Iter 2672 | Loss 0.028890 | Grad 0.0538 \n","[2023-12-09 07:32:42,482::train::INFO] [Train] Iter 2673 | Loss 0.028750 | Grad 0.0490 \n","[2023-12-09 07:32:42,564::train::INFO] [Train] Iter 2674 | Loss 0.030704 | Grad 0.0610 \n","[2023-12-09 07:32:42,647::train::INFO] [Train] Iter 2675 | Loss 0.028913 | Grad 0.0324 \n","[2023-12-09 07:32:42,740::train::INFO] [Train] Iter 2676 | Loss 0.033024 | Grad 0.0652 \n","[2023-12-09 07:32:42,830::train::INFO] [Train] Iter 2677 | Loss 0.030033 | Grad 0.0495 \n","[2023-12-09 07:32:42,923::train::INFO] [Train] Iter 2678 | Loss 0.025818 | Grad 0.0418 \n","[2023-12-09 07:32:43,028::train::INFO] [Train] Iter 2679 | Loss 0.031419 | Grad 0.0393 \n","[2023-12-09 07:32:43,125::train::INFO] [Train] Iter 2680 | Loss 0.029405 | Grad 0.0503 \n","[2023-12-09 07:32:43,219::train::INFO] [Train] Iter 2681 | Loss 0.026646 | Grad 0.0587 \n","[2023-12-09 07:32:43,312::train::INFO] [Train] Iter 2682 | Loss 0.029895 | Grad 0.0384 \n","[2023-12-09 07:32:43,403::train::INFO] [Train] Iter 2683 | Loss 0.028584 | Grad 0.0671 \n","[2023-12-09 07:32:43,493::train::INFO] [Train] Iter 2684 | Loss 0.029077 | Grad 0.0333 \n","[2023-12-09 07:32:43,584::train::INFO] [Train] Iter 2685 | Loss 0.029381 | Grad 0.0452 \n","[2023-12-09 07:32:43,673::train::INFO] [Train] Iter 2686 | Loss 0.029566 | Grad 0.0349 \n","[2023-12-09 07:32:43,764::train::INFO] [Train] Iter 2687 | Loss 0.028972 | Grad 0.0415 \n","[2023-12-09 07:32:43,854::train::INFO] [Train] Iter 2688 | Loss 0.025856 | Grad 0.0592 \n","[2023-12-09 07:32:43,943::train::INFO] [Train] Iter 2689 | Loss 0.029434 | Grad 0.0409 \n","[2023-12-09 07:32:44,032::train::INFO] [Train] Iter 2690 | Loss 0.030349 | Grad 0.0428 \n","[2023-12-09 07:32:44,123::train::INFO] [Train] Iter 2691 | Loss 0.028277 | Grad 0.0323 \n","[2023-12-09 07:32:44,216::train::INFO] [Train] Iter 2692 | Loss 0.028955 | Grad 0.0422 \n","[2023-12-09 07:32:44,308::train::INFO] [Train] Iter 2693 | Loss 0.029744 | Grad 0.0511 \n","[2023-12-09 07:32:44,397::train::INFO] [Train] Iter 2694 | Loss 0.029591 | Grad 0.0305 \n","[2023-12-09 07:32:44,491::train::INFO] [Train] Iter 2695 | Loss 0.028183 | Grad 0.0479 \n","[2023-12-09 07:32:44,581::train::INFO] [Train] Iter 2696 | Loss 0.028735 | Grad 0.0358 \n","[2023-12-09 07:32:44,671::train::INFO] [Train] Iter 2697 | Loss 0.031184 | Grad 0.0609 \n","[2023-12-09 07:32:44,764::train::INFO] [Train] Iter 2698 | Loss 0.029115 | Grad 0.0599 \n","[2023-12-09 07:32:44,857::train::INFO] [Train] Iter 2699 | Loss 0.028955 | Grad 0.0467 \n","[2023-12-09 07:32:44,952::train::INFO] [Train] Iter 2700 | Loss 0.029973 | Grad 0.0499 \n","[2023-12-09 07:32:45,043::train::INFO] [Train] Iter 2701 | Loss 0.026951 | Grad 0.0430 \n","[2023-12-09 07:32:45,137::train::INFO] [Train] Iter 2702 | Loss 0.031016 | Grad 0.0407 \n","[2023-12-09 07:32:45,228::train::INFO] [Train] Iter 2703 | Loss 0.029338 | Grad 0.0407 \n","[2023-12-09 07:32:45,317::train::INFO] [Train] Iter 2704 | Loss 0.027047 | Grad 0.0443 \n","[2023-12-09 07:32:45,409::train::INFO] [Train] Iter 2705 | Loss 0.029361 | Grad 0.0543 \n","[2023-12-09 07:32:45,500::train::INFO] [Train] Iter 2706 | Loss 0.031704 | Grad 0.0940 \n","[2023-12-09 07:32:45,589::train::INFO] [Train] Iter 2707 | Loss 0.028383 | Grad 0.0386 \n","[2023-12-09 07:32:45,679::train::INFO] [Train] Iter 2708 | Loss 0.029845 | Grad 0.0483 \n","[2023-12-09 07:32:45,774::train::INFO] [Train] Iter 2709 | Loss 0.029660 | Grad 0.0591 \n","[2023-12-09 07:32:45,864::train::INFO] [Train] Iter 2710 | Loss 0.029690 | Grad 0.0461 \n","[2023-12-09 07:32:45,954::train::INFO] [Train] Iter 2711 | Loss 0.026916 | Grad 0.0513 \n","[2023-12-09 07:32:46,053::train::INFO] [Train] Iter 2712 | Loss 0.029329 | Grad 0.0546 \n","[2023-12-09 07:32:46,144::train::INFO] [Train] Iter 2713 | Loss 0.029498 | Grad 0.0498 \n","[2023-12-09 07:32:46,233::train::INFO] [Train] Iter 2714 | Loss 0.030500 | Grad 0.0417 \n","[2023-12-09 07:32:46,322::train::INFO] [Train] Iter 2715 | Loss 0.027077 | Grad 0.0412 \n","[2023-12-09 07:32:46,413::train::INFO] [Train] Iter 2716 | Loss 0.031028 | Grad 0.0582 \n","[2023-12-09 07:32:46,502::train::INFO] [Train] Iter 2717 | Loss 0.031053 | Grad 0.0462 \n","[2023-12-09 07:32:46,595::train::INFO] [Train] Iter 2718 | Loss 0.026841 | Grad 0.0495 \n","[2023-12-09 07:32:46,686::train::INFO] [Train] Iter 2719 | Loss 0.027540 | Grad 0.0634 \n","[2023-12-09 07:32:46,729::train::INFO] [Train] Iter 2720 | Loss 0.027533 | Grad 0.0814 \n","[2023-12-09 07:32:46,820::train::INFO] [Train] Iter 2721 | Loss 0.027363 | Grad 0.0437 \n","[2023-12-09 07:32:46,914::train::INFO] [Train] Iter 2722 | Loss 0.030585 | Grad 0.0529 \n","[2023-12-09 07:32:47,004::train::INFO] [Train] Iter 2723 | Loss 0.028760 | Grad 0.0468 \n","[2023-12-09 07:32:47,101::train::INFO] [Train] Iter 2724 | Loss 0.029836 | Grad 0.0363 \n","[2023-12-09 07:32:47,195::train::INFO] [Train] Iter 2725 | Loss 0.028847 | Grad 0.0399 \n","[2023-12-09 07:32:47,294::train::INFO] [Train] Iter 2726 | Loss 0.030848 | Grad 0.0444 \n","[2023-12-09 07:32:47,384::train::INFO] [Train] Iter 2727 | Loss 0.029043 | Grad 0.0438 \n","[2023-12-09 07:32:47,474::train::INFO] [Train] Iter 2728 | Loss 0.030653 | Grad 0.0359 \n","[2023-12-09 07:32:47,566::train::INFO] [Train] Iter 2729 | Loss 0.029219 | Grad 0.0400 \n","[2023-12-09 07:32:47,654::train::INFO] [Train] Iter 2730 | Loss 0.030130 | Grad 0.0455 \n","[2023-12-09 07:32:47,743::train::INFO] [Train] Iter 2731 | Loss 0.027970 | Grad 0.0402 \n","[2023-12-09 07:32:47,836::train::INFO] [Train] Iter 2732 | Loss 0.030906 | Grad 0.0485 \n","[2023-12-09 07:32:47,929::train::INFO] [Train] Iter 2733 | Loss 0.028958 | Grad 0.0450 \n","[2023-12-09 07:32:48,018::train::INFO] [Train] Iter 2734 | Loss 0.029043 | Grad 0.0354 \n","[2023-12-09 07:32:48,108::train::INFO] [Train] Iter 2735 | Loss 0.029356 | Grad 0.0404 \n","[2023-12-09 07:32:48,199::train::INFO] [Train] Iter 2736 | Loss 0.028837 | Grad 0.0360 \n","[2023-12-09 07:32:48,290::train::INFO] [Train] Iter 2737 | Loss 0.029157 | Grad 0.0452 \n","[2023-12-09 07:32:48,379::train::INFO] [Train] Iter 2738 | Loss 0.028246 | Grad 0.0459 \n","[2023-12-09 07:32:48,474::train::INFO] [Train] Iter 2739 | Loss 0.030812 | Grad 0.0336 \n","[2023-12-09 07:32:48,565::train::INFO] [Train] Iter 2740 | Loss 0.028317 | Grad 0.0579 \n","[2023-12-09 07:32:48,654::train::INFO] [Train] Iter 2741 | Loss 0.027174 | Grad 0.0353 \n","[2023-12-09 07:32:48,747::train::INFO] [Train] Iter 2742 | Loss 0.030082 | Grad 0.0384 \n","[2023-12-09 07:32:48,830::train::INFO] [Train] Iter 2743 | Loss 0.028421 | Grad 0.0513 \n","[2023-12-09 07:32:48,913::train::INFO] [Train] Iter 2744 | Loss 0.028801 | Grad 0.0585 \n","[2023-12-09 07:32:48,996::train::INFO] [Train] Iter 2745 | Loss 0.028312 | Grad 0.0340 \n","[2023-12-09 07:32:49,080::train::INFO] [Train] Iter 2746 | Loss 0.029035 | Grad 0.0410 \n","[2023-12-09 07:32:49,164::train::INFO] [Train] Iter 2747 | Loss 0.030623 | Grad 0.0372 \n","[2023-12-09 07:32:49,247::train::INFO] [Train] Iter 2748 | Loss 0.029734 | Grad 0.0391 \n","[2023-12-09 07:32:49,330::train::INFO] [Train] Iter 2749 | Loss 0.027928 | Grad 0.0529 \n","[2023-12-09 07:32:49,416::train::INFO] [Train] Iter 2750 | Loss 0.029405 | Grad 0.0398 \n","[2023-12-09 07:32:49,498::train::INFO] [Train] Iter 2751 | Loss 0.030833 | Grad 0.0443 \n","[2023-12-09 07:32:49,581::train::INFO] [Train] Iter 2752 | Loss 0.027687 | Grad 0.0364 \n","[2023-12-09 07:32:49,667::train::INFO] [Train] Iter 2753 | Loss 0.030295 | Grad 0.0609 \n","[2023-12-09 07:32:49,749::train::INFO] [Train] Iter 2754 | Loss 0.029474 | Grad 0.0525 \n","[2023-12-09 07:32:49,834::train::INFO] [Train] Iter 2755 | Loss 0.027226 | Grad 0.0487 \n","[2023-12-09 07:32:49,916::train::INFO] [Train] Iter 2756 | Loss 0.031076 | Grad 0.0383 \n","[2023-12-09 07:32:49,999::train::INFO] [Train] Iter 2757 | Loss 0.029227 | Grad 0.0364 \n","[2023-12-09 07:32:50,082::train::INFO] [Train] Iter 2758 | Loss 0.030858 | Grad 0.0374 \n","[2023-12-09 07:32:50,170::train::INFO] [Train] Iter 2759 | Loss 0.027804 | Grad 0.0363 \n","[2023-12-09 07:32:50,252::train::INFO] [Train] Iter 2760 | Loss 0.029034 | Grad 0.0494 \n","[2023-12-09 07:32:50,336::train::INFO] [Train] Iter 2761 | Loss 0.029788 | Grad 0.0471 \n","[2023-12-09 07:32:50,418::train::INFO] [Train] Iter 2762 | Loss 0.029178 | Grad 0.0319 \n","[2023-12-09 07:32:50,501::train::INFO] [Train] Iter 2763 | Loss 0.029006 | Grad 0.0510 \n","[2023-12-09 07:32:50,583::train::INFO] [Train] Iter 2764 | Loss 0.028035 | Grad 0.0421 \n","[2023-12-09 07:32:50,668::train::INFO] [Train] Iter 2765 | Loss 0.029309 | Grad 0.0323 \n","[2023-12-09 07:32:50,751::train::INFO] [Train] Iter 2766 | Loss 0.029467 | Grad 0.0524 \n","[2023-12-09 07:32:50,833::train::INFO] [Train] Iter 2767 | Loss 0.027232 | Grad 0.0343 \n","[2023-12-09 07:32:50,917::train::INFO] [Train] Iter 2768 | Loss 0.027925 | Grad 0.0566 \n","[2023-12-09 07:32:51,000::train::INFO] [Train] Iter 2769 | Loss 0.029996 | Grad 0.0482 \n","[2023-12-09 07:32:51,082::train::INFO] [Train] Iter 2770 | Loss 0.027575 | Grad 0.0371 \n","[2023-12-09 07:32:51,164::train::INFO] [Train] Iter 2771 | Loss 0.031325 | Grad 0.0492 \n","[2023-12-09 07:32:51,246::train::INFO] [Train] Iter 2772 | Loss 0.028506 | Grad 0.0364 \n","[2023-12-09 07:32:51,329::train::INFO] [Train] Iter 2773 | Loss 0.029423 | Grad 0.0438 \n","[2023-12-09 07:32:51,411::train::INFO] [Train] Iter 2774 | Loss 0.028202 | Grad 0.0387 \n","[2023-12-09 07:32:51,494::train::INFO] [Train] Iter 2775 | Loss 0.029546 | Grad 0.0370 \n","[2023-12-09 07:32:51,585::train::INFO] [Train] Iter 2776 | Loss 0.031525 | Grad 0.0405 \n","[2023-12-09 07:32:51,669::train::INFO] [Train] Iter 2777 | Loss 0.028850 | Grad 0.0407 \n","[2023-12-09 07:32:51,752::train::INFO] [Train] Iter 2778 | Loss 0.028783 | Grad 0.0394 \n","[2023-12-09 07:32:51,836::train::INFO] [Train] Iter 2779 | Loss 0.027836 | Grad 0.0334 \n","[2023-12-09 07:32:51,919::train::INFO] [Train] Iter 2780 | Loss 0.026924 | Grad 0.0419 \n","[2023-12-09 07:32:52,001::train::INFO] [Train] Iter 2781 | Loss 0.030191 | Grad 0.0496 \n","[2023-12-09 07:32:52,084::train::INFO] [Train] Iter 2782 | Loss 0.031438 | Grad 0.0433 \n","[2023-12-09 07:32:52,168::train::INFO] [Train] Iter 2783 | Loss 0.028688 | Grad 0.0311 \n","[2023-12-09 07:32:52,251::train::INFO] [Train] Iter 2784 | Loss 0.030745 | Grad 0.0548 \n","[2023-12-09 07:32:52,334::train::INFO] [Train] Iter 2785 | Loss 0.030657 | Grad 0.0372 \n","[2023-12-09 07:32:52,416::train::INFO] [Train] Iter 2786 | Loss 0.028615 | Grad 0.0607 \n","[2023-12-09 07:32:52,501::train::INFO] [Train] Iter 2787 | Loss 0.029301 | Grad 0.0317 \n","[2023-12-09 07:32:52,587::train::INFO] [Train] Iter 2788 | Loss 0.027076 | Grad 0.0399 \n","[2023-12-09 07:32:52,669::train::INFO] [Train] Iter 2789 | Loss 0.028996 | Grad 0.0378 \n","[2023-12-09 07:32:52,751::train::INFO] [Train] Iter 2790 | Loss 0.028762 | Grad 0.0434 \n","[2023-12-09 07:32:52,834::train::INFO] [Train] Iter 2791 | Loss 0.029014 | Grad 0.0377 \n","[2023-12-09 07:32:52,916::train::INFO] [Train] Iter 2792 | Loss 0.028470 | Grad 0.0449 \n","[2023-12-09 07:32:52,999::train::INFO] [Train] Iter 2793 | Loss 0.029110 | Grad 0.0571 \n","[2023-12-09 07:32:53,087::train::INFO] [Train] Iter 2794 | Loss 0.028012 | Grad 0.0338 \n","[2023-12-09 07:32:53,169::train::INFO] [Train] Iter 2795 | Loss 0.029157 | Grad 0.0477 \n","[2023-12-09 07:32:53,251::train::INFO] [Train] Iter 2796 | Loss 0.028071 | Grad 0.0482 \n","[2023-12-09 07:32:53,334::train::INFO] [Train] Iter 2797 | Loss 0.028020 | Grad 0.0309 \n","[2023-12-09 07:32:53,418::train::INFO] [Train] Iter 2798 | Loss 0.027967 | Grad 0.0415 \n","[2023-12-09 07:32:53,501::train::INFO] [Train] Iter 2799 | Loss 0.029438 | Grad 0.0432 \n","[2023-12-09 07:32:53,583::train::INFO] [Train] Iter 2800 | Loss 0.027861 | Grad 0.0442 \n","[2023-12-09 07:32:53,665::train::INFO] [Train] Iter 2801 | Loss 0.028925 | Grad 0.0414 \n","[2023-12-09 07:32:53,749::train::INFO] [Train] Iter 2802 | Loss 0.026745 | Grad 0.0371 \n","[2023-12-09 07:32:53,831::train::INFO] [Train] Iter 2803 | Loss 0.027681 | Grad 0.0410 \n","[2023-12-09 07:32:53,913::train::INFO] [Train] Iter 2804 | Loss 0.029781 | Grad 0.0332 \n","[2023-12-09 07:32:53,996::train::INFO] [Train] Iter 2805 | Loss 0.029331 | Grad 0.0470 \n","[2023-12-09 07:32:54,078::train::INFO] [Train] Iter 2806 | Loss 0.029654 | Grad 0.0543 \n","[2023-12-09 07:32:54,161::train::INFO] [Train] Iter 2807 | Loss 0.028832 | Grad 0.0451 \n","[2023-12-09 07:32:54,244::train::INFO] [Train] Iter 2808 | Loss 0.030272 | Grad 0.0343 \n","[2023-12-09 07:32:54,330::train::INFO] [Train] Iter 2809 | Loss 0.028610 | Grad 0.0394 \n","[2023-12-09 07:32:54,413::train::INFO] [Train] Iter 2810 | Loss 0.030136 | Grad 0.0574 \n","[2023-12-09 07:32:54,496::train::INFO] [Train] Iter 2811 | Loss 0.027713 | Grad 0.0342 \n","[2023-12-09 07:32:54,578::train::INFO] [Train] Iter 2812 | Loss 0.028670 | Grad 0.0313 \n","[2023-12-09 07:32:54,662::train::INFO] [Train] Iter 2813 | Loss 0.028757 | Grad 0.0365 \n","[2023-12-09 07:32:54,745::train::INFO] [Train] Iter 2814 | Loss 0.028730 | Grad 0.0612 \n","[2023-12-09 07:32:54,828::train::INFO] [Train] Iter 2815 | Loss 0.031186 | Grad 0.0334 \n","[2023-12-09 07:32:54,915::train::INFO] [Train] Iter 2816 | Loss 0.025776 | Grad 0.0411 \n","[2023-12-09 07:32:54,998::train::INFO] [Train] Iter 2817 | Loss 0.029110 | Grad 0.0396 \n","[2023-12-09 07:32:55,081::train::INFO] [Train] Iter 2818 | Loss 0.028203 | Grad 0.0411 \n","[2023-12-09 07:32:55,165::train::INFO] [Train] Iter 2819 | Loss 0.027594 | Grad 0.0460 \n","[2023-12-09 07:32:55,248::train::INFO] [Train] Iter 2820 | Loss 0.030538 | Grad 0.0386 \n","[2023-12-09 07:32:55,331::train::INFO] [Train] Iter 2821 | Loss 0.028701 | Grad 0.0334 \n","[2023-12-09 07:32:55,413::train::INFO] [Train] Iter 2822 | Loss 0.028448 | Grad 0.0375 \n","[2023-12-09 07:32:55,501::train::INFO] [Train] Iter 2823 | Loss 0.028521 | Grad 0.0439 \n","[2023-12-09 07:32:55,583::train::INFO] [Train] Iter 2824 | Loss 0.028480 | Grad 0.0320 \n","[2023-12-09 07:32:55,668::train::INFO] [Train] Iter 2825 | Loss 0.029195 | Grad 0.0354 \n","[2023-12-09 07:32:55,752::train::INFO] [Train] Iter 2826 | Loss 0.030100 | Grad 0.0545 \n","[2023-12-09 07:32:55,834::train::INFO] [Train] Iter 2827 | Loss 0.026265 | Grad 0.0405 \n","[2023-12-09 07:32:55,920::train::INFO] [Train] Iter 2828 | Loss 0.029679 | Grad 0.0291 \n","[2023-12-09 07:32:56,003::train::INFO] [Train] Iter 2829 | Loss 0.032144 | Grad 0.0584 \n","[2023-12-09 07:32:56,088::train::INFO] [Train] Iter 2830 | Loss 0.028396 | Grad 0.0455 \n","[2023-12-09 07:32:56,171::train::INFO] [Train] Iter 2831 | Loss 0.030238 | Grad 0.0353 \n","[2023-12-09 07:32:56,253::train::INFO] [Train] Iter 2832 | Loss 0.028342 | Grad 0.0429 \n","[2023-12-09 07:32:56,337::train::INFO] [Train] Iter 2833 | Loss 0.028244 | Grad 0.0389 \n","[2023-12-09 07:32:56,424::train::INFO] [Train] Iter 2834 | Loss 0.029139 | Grad 0.0472 \n","[2023-12-09 07:32:56,506::train::INFO] [Train] Iter 2835 | Loss 0.028342 | Grad 0.0371 \n","[2023-12-09 07:32:56,588::train::INFO] [Train] Iter 2836 | Loss 0.029129 | Grad 0.0518 \n","[2023-12-09 07:32:56,673::train::INFO] [Train] Iter 2837 | Loss 0.029350 | Grad 0.0328 \n","[2023-12-09 07:32:56,756::train::INFO] [Train] Iter 2838 | Loss 0.028490 | Grad 0.0505 \n","[2023-12-09 07:32:56,843::train::INFO] [Train] Iter 2839 | Loss 0.025357 | Grad 0.0325 \n","[2023-12-09 07:32:56,926::train::INFO] [Train] Iter 2840 | Loss 0.029809 | Grad 0.0352 \n","[2023-12-09 07:32:57,011::train::INFO] [Train] Iter 2841 | Loss 0.028079 | Grad 0.0349 \n","[2023-12-09 07:32:57,094::train::INFO] [Train] Iter 2842 | Loss 0.026249 | Grad 0.0339 \n","[2023-12-09 07:32:57,176::train::INFO] [Train] Iter 2843 | Loss 0.027096 | Grad 0.0324 \n","[2023-12-09 07:32:57,259::train::INFO] [Train] Iter 2844 | Loss 0.029252 | Grad 0.0510 \n","[2023-12-09 07:32:57,341::train::INFO] [Train] Iter 2845 | Loss 0.028622 | Grad 0.0422 \n","[2023-12-09 07:32:57,424::train::INFO] [Train] Iter 2846 | Loss 0.028968 | Grad 0.0434 \n","[2023-12-09 07:32:57,506::train::INFO] [Train] Iter 2847 | Loss 0.027263 | Grad 0.0291 \n","[2023-12-09 07:32:57,588::train::INFO] [Train] Iter 2848 | Loss 0.028487 | Grad 0.0346 \n","[2023-12-09 07:32:57,677::train::INFO] [Train] Iter 2849 | Loss 0.029422 | Grad 0.0374 \n","[2023-12-09 07:32:57,759::train::INFO] [Train] Iter 2850 | Loss 0.026802 | Grad 0.0415 \n","[2023-12-09 07:32:57,842::train::INFO] [Train] Iter 2851 | Loss 0.029570 | Grad 0.0417 \n","[2023-12-09 07:32:57,924::train::INFO] [Train] Iter 2852 | Loss 0.029349 | Grad 0.0444 \n","[2023-12-09 07:32:58,008::train::INFO] [Train] Iter 2853 | Loss 0.028491 | Grad 0.0333 \n","[2023-12-09 07:32:58,090::train::INFO] [Train] Iter 2854 | Loss 0.027376 | Grad 0.0500 \n","[2023-12-09 07:32:58,173::train::INFO] [Train] Iter 2855 | Loss 0.027826 | Grad 0.0321 \n","[2023-12-09 07:32:58,256::train::INFO] [Train] Iter 2856 | Loss 0.027042 | Grad 0.0703 \n","[2023-12-09 07:32:58,338::train::INFO] [Train] Iter 2857 | Loss 0.027832 | Grad 0.0524 \n","[2023-12-09 07:32:58,425::train::INFO] [Train] Iter 2858 | Loss 0.028016 | Grad 0.0562 \n","[2023-12-09 07:32:58,509::train::INFO] [Train] Iter 2859 | Loss 0.028855 | Grad 0.0610 \n","[2023-12-09 07:32:58,591::train::INFO] [Train] Iter 2860 | Loss 0.028924 | Grad 0.0692 \n","[2023-12-09 07:32:58,674::train::INFO] [Train] Iter 2861 | Loss 0.029673 | Grad 0.0633 \n","[2023-12-09 07:32:58,764::train::INFO] [Train] Iter 2862 | Loss 0.028484 | Grad 0.0319 \n","[2023-12-09 07:32:58,859::train::INFO] [Train] Iter 2863 | Loss 0.030784 | Grad 0.0435 \n","[2023-12-09 07:32:58,950::train::INFO] [Train] Iter 2864 | Loss 0.029184 | Grad 0.0591 \n","[2023-12-09 07:32:59,041::train::INFO] [Train] Iter 2865 | Loss 0.031636 | Grad 0.0495 \n","[2023-12-09 07:32:59,131::train::INFO] [Train] Iter 2866 | Loss 0.029846 | Grad 0.0439 \n","[2023-12-09 07:32:59,221::train::INFO] [Train] Iter 2867 | Loss 0.028455 | Grad 0.0413 \n","[2023-12-09 07:32:59,311::train::INFO] [Train] Iter 2868 | Loss 0.029454 | Grad 0.0592 \n","[2023-12-09 07:32:59,405::train::INFO] [Train] Iter 2869 | Loss 0.030026 | Grad 0.0371 \n","[2023-12-09 07:32:59,496::train::INFO] [Train] Iter 2870 | Loss 0.031309 | Grad 0.0605 \n","[2023-12-09 07:32:59,588::train::INFO] [Train] Iter 2871 | Loss 0.031167 | Grad 0.0490 \n","[2023-12-09 07:32:59,680::train::INFO] [Train] Iter 2872 | Loss 0.030444 | Grad 0.0680 \n","[2023-12-09 07:32:59,771::train::INFO] [Train] Iter 2873 | Loss 0.028247 | Grad 0.0371 \n","[2023-12-09 07:32:59,863::train::INFO] [Train] Iter 2874 | Loss 0.028285 | Grad 0.0603 \n","[2023-12-09 07:32:59,953::train::INFO] [Train] Iter 2875 | Loss 0.029200 | Grad 0.0389 \n","[2023-12-09 07:33:00,043::train::INFO] [Train] Iter 2876 | Loss 0.029981 | Grad 0.0276 \n","[2023-12-09 07:33:00,140::train::INFO] [Train] Iter 2877 | Loss 0.026726 | Grad 0.0344 \n","[2023-12-09 07:33:00,232::train::INFO] [Train] Iter 2878 | Loss 0.028973 | Grad 0.0573 \n","[2023-12-09 07:33:00,322::train::INFO] [Train] Iter 2879 | Loss 0.026786 | Grad 0.0386 \n","[2023-12-09 07:33:00,414::train::INFO] [Train] Iter 2880 | Loss 0.028078 | Grad 0.0474 \n","[2023-12-09 07:33:00,505::train::INFO] [Train] Iter 2881 | Loss 0.028462 | Grad 0.0693 \n","[2023-12-09 07:33:00,594::train::INFO] [Train] Iter 2882 | Loss 0.029378 | Grad 0.0352 \n","[2023-12-09 07:33:00,685::train::INFO] [Train] Iter 2883 | Loss 0.030782 | Grad 0.0573 \n","[2023-12-09 07:33:00,780::train::INFO] [Train] Iter 2884 | Loss 0.030242 | Grad 0.0438 \n","[2023-12-09 07:33:00,871::train::INFO] [Train] Iter 2885 | Loss 0.027879 | Grad 0.0448 \n","[2023-12-09 07:33:00,960::train::INFO] [Train] Iter 2886 | Loss 0.029238 | Grad 0.0572 \n","[2023-12-09 07:33:01,057::train::INFO] [Train] Iter 2887 | Loss 0.028248 | Grad 0.0368 \n","[2023-12-09 07:33:01,148::train::INFO] [Train] Iter 2888 | Loss 0.030139 | Grad 0.0639 \n","[2023-12-09 07:33:01,239::train::INFO] [Train] Iter 2889 | Loss 0.026491 | Grad 0.0553 \n","[2023-12-09 07:33:01,332::train::INFO] [Train] Iter 2890 | Loss 0.026636 | Grad 0.0405 \n","[2023-12-09 07:33:01,423::train::INFO] [Train] Iter 2891 | Loss 0.027954 | Grad 0.0604 \n","[2023-12-09 07:33:01,522::train::INFO] [Train] Iter 2892 | Loss 0.031570 | Grad 0.0381 \n","[2023-12-09 07:33:01,614::train::INFO] [Train] Iter 2893 | Loss 0.031003 | Grad 0.0670 \n","[2023-12-09 07:33:01,708::train::INFO] [Train] Iter 2894 | Loss 0.028259 | Grad 0.0463 \n","[2023-12-09 07:33:01,804::train::INFO] [Train] Iter 2895 | Loss 0.028826 | Grad 0.0359 \n","[2023-12-09 07:33:01,898::train::INFO] [Train] Iter 2896 | Loss 0.027355 | Grad 0.0400 \n","[2023-12-09 07:33:01,992::train::INFO] [Train] Iter 2897 | Loss 0.027341 | Grad 0.0307 \n","[2023-12-09 07:33:02,083::train::INFO] [Train] Iter 2898 | Loss 0.026485 | Grad 0.0462 \n","[2023-12-09 07:33:02,173::train::INFO] [Train] Iter 2899 | Loss 0.026611 | Grad 0.0329 \n","[2023-12-09 07:33:02,274::train::INFO] [Train] Iter 2900 | Loss 0.029724 | Grad 0.0522 \n","[2023-12-09 07:33:02,364::train::INFO] [Train] Iter 2901 | Loss 0.030829 | Grad 0.0543 \n","[2023-12-09 07:33:02,455::train::INFO] [Train] Iter 2902 | Loss 0.027404 | Grad 0.0309 \n","[2023-12-09 07:33:02,549::train::INFO] [Train] Iter 2903 | Loss 0.026626 | Grad 0.0406 \n","[2023-12-09 07:33:02,638::train::INFO] [Train] Iter 2904 | Loss 0.029755 | Grad 0.0613 \n","[2023-12-09 07:33:02,729::train::INFO] [Train] Iter 2905 | Loss 0.027297 | Grad 0.0403 \n","[2023-12-09 07:33:02,819::train::INFO] [Train] Iter 2906 | Loss 0.029632 | Grad 0.0335 \n","[2023-12-09 07:33:02,915::train::INFO] [Train] Iter 2907 | Loss 0.027224 | Grad 0.0311 \n","[2023-12-09 07:33:03,007::train::INFO] [Train] Iter 2908 | Loss 0.029761 | Grad 0.0377 \n","[2023-12-09 07:33:03,098::train::INFO] [Train] Iter 2909 | Loss 0.028939 | Grad 0.0542 \n","[2023-12-09 07:33:03,189::train::INFO] [Train] Iter 2910 | Loss 0.029733 | Grad 0.0343 \n","[2023-12-09 07:33:03,279::train::INFO] [Train] Iter 2911 | Loss 0.029797 | Grad 0.0515 \n","[2023-12-09 07:33:03,373::train::INFO] [Train] Iter 2912 | Loss 0.028001 | Grad 0.0661 \n","[2023-12-09 07:33:03,465::train::INFO] [Train] Iter 2913 | Loss 0.028033 | Grad 0.0426 \n","[2023-12-09 07:33:03,556::train::INFO] [Train] Iter 2914 | Loss 0.028352 | Grad 0.0386 \n","[2023-12-09 07:33:03,646::train::INFO] [Train] Iter 2915 | Loss 0.030103 | Grad 0.0340 \n","[2023-12-09 07:33:03,737::train::INFO] [Train] Iter 2916 | Loss 0.030237 | Grad 0.0343 \n","[2023-12-09 07:33:03,829::train::INFO] [Train] Iter 2917 | Loss 0.028161 | Grad 0.0528 \n","[2023-12-09 07:33:03,923::train::INFO] [Train] Iter 2918 | Loss 0.027495 | Grad 0.0344 \n","[2023-12-09 07:33:04,013::train::INFO] [Train] Iter 2919 | Loss 0.029664 | Grad 0.0357 \n","[2023-12-09 07:33:04,105::train::INFO] [Train] Iter 2920 | Loss 0.026546 | Grad 0.0375 \n","[2023-12-09 07:33:04,197::train::INFO] [Train] Iter 2921 | Loss 0.027288 | Grad 0.0415 \n","[2023-12-09 07:33:04,285::train::INFO] [Train] Iter 2922 | Loss 0.028825 | Grad 0.0400 \n","[2023-12-09 07:33:04,380::train::INFO] [Train] Iter 2923 | Loss 0.029838 | Grad 0.0365 \n","[2023-12-09 07:33:04,471::train::INFO] [Train] Iter 2924 | Loss 0.028228 | Grad 0.0363 \n","[2023-12-09 07:33:04,561::train::INFO] [Train] Iter 2925 | Loss 0.027834 | Grad 0.0487 \n","[2023-12-09 07:33:04,650::train::INFO] [Train] Iter 2926 | Loss 0.028153 | Grad 0.0475 \n","[2023-12-09 07:33:04,740::train::INFO] [Train] Iter 2927 | Loss 0.028275 | Grad 0.0323 \n","[2023-12-09 07:33:04,829::train::INFO] [Train] Iter 2928 | Loss 0.028238 | Grad 0.0455 \n","[2023-12-09 07:33:04,920::train::INFO] [Train] Iter 2929 | Loss 0.027175 | Grad 0.0355 \n","[2023-12-09 07:33:05,009::train::INFO] [Train] Iter 2930 | Loss 0.030707 | Grad 0.0438 \n","[2023-12-09 07:33:05,092::train::INFO] [Train] Iter 2931 | Loss 0.030039 | Grad 0.0390 \n","[2023-12-09 07:33:05,174::train::INFO] [Train] Iter 2932 | Loss 0.027805 | Grad 0.0440 \n","[2023-12-09 07:33:05,257::train::INFO] [Train] Iter 2933 | Loss 0.028796 | Grad 0.0413 \n","[2023-12-09 07:33:05,345::train::INFO] [Train] Iter 2934 | Loss 0.029703 | Grad 0.0362 \n","[2023-12-09 07:33:05,427::train::INFO] [Train] Iter 2935 | Loss 0.027479 | Grad 0.0503 \n","[2023-12-09 07:33:05,512::train::INFO] [Train] Iter 2936 | Loss 0.030192 | Grad 0.0339 \n","[2023-12-09 07:33:05,597::train::INFO] [Train] Iter 2937 | Loss 0.027834 | Grad 0.0384 \n","[2023-12-09 07:33:05,679::train::INFO] [Train] Iter 2938 | Loss 0.031362 | Grad 0.0348 \n","[2023-12-09 07:33:05,761::train::INFO] [Train] Iter 2939 | Loss 0.027850 | Grad 0.0325 \n","[2023-12-09 07:33:05,846::train::INFO] [Train] Iter 2940 | Loss 0.029473 | Grad 0.0455 \n","[2023-12-09 07:33:05,929::train::INFO] [Train] Iter 2941 | Loss 0.028169 | Grad 0.0415 \n","[2023-12-09 07:33:06,023::train::INFO] [Train] Iter 2942 | Loss 0.027693 | Grad 0.0351 \n","[2023-12-09 07:33:06,109::train::INFO] [Train] Iter 2943 | Loss 0.028366 | Grad 0.0524 \n","[2023-12-09 07:33:06,192::train::INFO] [Train] Iter 2944 | Loss 0.029414 | Grad 0.0670 \n","[2023-12-09 07:33:06,276::train::INFO] [Train] Iter 2945 | Loss 0.028497 | Grad 0.0575 \n","[2023-12-09 07:33:06,360::train::INFO] [Train] Iter 2946 | Loss 0.029360 | Grad 0.0393 \n","[2023-12-09 07:33:06,444::train::INFO] [Train] Iter 2947 | Loss 0.029264 | Grad 0.0350 \n","[2023-12-09 07:33:06,528::train::INFO] [Train] Iter 2948 | Loss 0.026559 | Grad 0.0295 \n","[2023-12-09 07:33:06,611::train::INFO] [Train] Iter 2949 | Loss 0.029937 | Grad 0.0499 \n","[2023-12-09 07:33:06,695::train::INFO] [Train] Iter 2950 | Loss 0.026685 | Grad 0.0375 \n","[2023-12-09 07:33:06,778::train::INFO] [Train] Iter 2951 | Loss 0.029459 | Grad 0.0359 \n","[2023-12-09 07:33:06,859::train::INFO] [Train] Iter 2952 | Loss 0.028570 | Grad 0.0407 \n","[2023-12-09 07:33:06,942::train::INFO] [Train] Iter 2953 | Loss 0.030559 | Grad 0.0463 \n","[2023-12-09 07:33:07,025::train::INFO] [Train] Iter 2954 | Loss 0.028500 | Grad 0.0437 \n","[2023-12-09 07:33:07,109::train::INFO] [Train] Iter 2955 | Loss 0.028813 | Grad 0.0485 \n","[2023-12-09 07:33:07,192::train::INFO] [Train] Iter 2956 | Loss 0.028782 | Grad 0.0397 \n","[2023-12-09 07:33:07,275::train::INFO] [Train] Iter 2957 | Loss 0.028592 | Grad 0.0689 \n","[2023-12-09 07:33:07,360::train::INFO] [Train] Iter 2958 | Loss 0.027206 | Grad 0.0348 \n","[2023-12-09 07:33:07,445::train::INFO] [Train] Iter 2959 | Loss 0.028003 | Grad 0.0351 \n","[2023-12-09 07:33:07,528::train::INFO] [Train] Iter 2960 | Loss 0.028374 | Grad 0.0307 \n","[2023-12-09 07:33:07,615::train::INFO] [Train] Iter 2961 | Loss 0.029160 | Grad 0.0598 \n","[2023-12-09 07:33:07,698::train::INFO] [Train] Iter 2962 | Loss 0.027637 | Grad 0.0463 \n","[2023-12-09 07:33:07,781::train::INFO] [Train] Iter 2963 | Loss 0.028644 | Grad 0.0412 \n","[2023-12-09 07:33:07,864::train::INFO] [Train] Iter 2964 | Loss 0.030438 | Grad 0.0411 \n","[2023-12-09 07:33:07,947::train::INFO] [Train] Iter 2965 | Loss 0.029932 | Grad 0.0539 \n","[2023-12-09 07:33:08,036::train::INFO] [Train] Iter 2966 | Loss 0.027731 | Grad 0.0402 \n","[2023-12-09 07:33:08,120::train::INFO] [Train] Iter 2967 | Loss 0.026080 | Grad 0.0369 \n","[2023-12-09 07:33:08,204::train::INFO] [Train] Iter 2968 | Loss 0.028840 | Grad 0.0392 \n","[2023-12-09 07:33:08,287::train::INFO] [Train] Iter 2969 | Loss 0.026217 | Grad 0.0356 \n","[2023-12-09 07:33:08,371::train::INFO] [Train] Iter 2970 | Loss 0.026020 | Grad 0.0429 \n","[2023-12-09 07:33:08,457::train::INFO] [Train] Iter 2971 | Loss 0.028055 | Grad 0.0394 \n","[2023-12-09 07:33:08,540::train::INFO] [Train] Iter 2972 | Loss 0.027934 | Grad 0.0431 \n","[2023-12-09 07:33:08,622::train::INFO] [Train] Iter 2973 | Loss 0.029942 | Grad 0.0396 \n","[2023-12-09 07:33:08,705::train::INFO] [Train] Iter 2974 | Loss 0.027897 | Grad 0.0648 \n","[2023-12-09 07:33:08,789::train::INFO] [Train] Iter 2975 | Loss 0.027415 | Grad 0.0386 \n","[2023-12-09 07:33:08,871::train::INFO] [Train] Iter 2976 | Loss 0.027073 | Grad 0.0498 \n","[2023-12-09 07:33:08,955::train::INFO] [Train] Iter 2977 | Loss 0.029480 | Grad 0.0385 \n","[2023-12-09 07:33:09,037::train::INFO] [Train] Iter 2978 | Loss 0.028613 | Grad 0.0387 \n","[2023-12-09 07:33:09,122::train::INFO] [Train] Iter 2979 | Loss 0.030518 | Grad 0.0395 \n","[2023-12-09 07:33:09,205::train::INFO] [Train] Iter 2980 | Loss 0.030316 | Grad 0.0429 \n","[2023-12-09 07:33:09,287::train::INFO] [Train] Iter 2981 | Loss 0.028749 | Grad 0.0331 \n","[2023-12-09 07:33:09,370::train::INFO] [Train] Iter 2982 | Loss 0.030114 | Grad 0.0361 \n","[2023-12-09 07:33:09,452::train::INFO] [Train] Iter 2983 | Loss 0.026962 | Grad 0.0346 \n","[2023-12-09 07:33:09,535::train::INFO] [Train] Iter 2984 | Loss 0.028177 | Grad 0.0456 \n","[2023-12-09 07:33:09,618::train::INFO] [Train] Iter 2985 | Loss 0.028566 | Grad 0.0357 \n","[2023-12-09 07:33:09,706::train::INFO] [Train] Iter 2986 | Loss 0.030450 | Grad 0.0358 \n","[2023-12-09 07:33:09,789::train::INFO] [Train] Iter 2987 | Loss 0.029045 | Grad 0.0410 \n","[2023-12-09 07:33:09,872::train::INFO] [Train] Iter 2988 | Loss 0.028915 | Grad 0.0395 \n","[2023-12-09 07:33:09,955::train::INFO] [Train] Iter 2989 | Loss 0.027550 | Grad 0.0567 \n","[2023-12-09 07:33:10,040::train::INFO] [Train] Iter 2990 | Loss 0.030315 | Grad 0.0417 \n","[2023-12-09 07:33:10,124::train::INFO] [Train] Iter 2991 | Loss 0.029773 | Grad 0.0569 \n","[2023-12-09 07:33:10,208::train::INFO] [Train] Iter 2992 | Loss 0.026443 | Grad 0.0369 \n","[2023-12-09 07:33:10,291::train::INFO] [Train] Iter 2993 | Loss 0.026474 | Grad 0.0352 \n","[2023-12-09 07:33:10,374::train::INFO] [Train] Iter 2994 | Loss 0.027919 | Grad 0.0552 \n","[2023-12-09 07:33:10,459::train::INFO] [Train] Iter 2995 | Loss 0.026617 | Grad 0.0493 \n","[2023-12-09 07:33:10,543::train::INFO] [Train] Iter 2996 | Loss 0.027791 | Grad 0.0364 \n","[2023-12-09 07:33:10,629::train::INFO] [Train] Iter 2997 | Loss 0.028327 | Grad 0.0394 \n","[2023-12-09 07:33:10,711::train::INFO] [Train] Iter 2998 | Loss 0.027748 | Grad 0.0391 \n","[2023-12-09 07:33:10,794::train::INFO] [Train] Iter 2999 | Loss 0.029162 | Grad 0.0502 \n","[2023-12-09 07:33:10,876::train::INFO] [Train] Iter 3000 | Loss 0.027601 | Grad 0.0390 \n","Validate: 100% 241/241 [00:03<00:00, 62.66it/s]\n","val loss list [tensor(0.0311, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0249, device='cuda:0'), tensor(0.0236, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0249, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0258, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0315, device='cuda:0'), tensor(0.0315, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0303, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0248, device='cuda:0'), tensor(0.0329, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0267, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0331, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0242, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0303, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0326, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0340, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0245, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0320, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0344, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0332, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0317, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0298, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0246, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0298, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0242, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0214, device='cuda:0'), tensor(0.0258, device='cuda:0'), tensor(0.0315, device='cuda:0'), tensor(0.0225, device='cuda:0'), tensor(0.0338, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0256, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0267, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0342, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0313, device='cuda:0'), tensor(0.0332, device='cuda:0'), tensor(0.0337, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0251, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0322, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0319, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0311, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0344, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0341, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0335, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0336, device='cuda:0'), tensor(0.0312, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0311, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0317, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0305, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0206, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0326, device='cuda:0'), tensor(0.0311, device='cuda:0'), tensor(0.0215, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0328, device='cuda:0')]\n","[2023-12-09 07:33:14,984::train::INFO] [Train] Iter 3001 | Loss 0.028755 | Grad 0.0556 \n","[2023-12-09 07:33:15,075::train::INFO] [Train] Iter 3002 | Loss 0.027683 | Grad 0.0485 \n","[2023-12-09 07:33:15,170::train::INFO] [Train] Iter 3003 | Loss 0.026859 | Grad 0.0379 \n","[2023-12-09 07:33:15,262::train::INFO] [Train] Iter 3004 | Loss 0.029606 | Grad 0.0414 \n","[2023-12-09 07:33:15,354::train::INFO] [Train] Iter 3005 | Loss 0.027069 | Grad 0.0445 \n","[2023-12-09 07:33:15,446::train::INFO] [Train] Iter 3006 | Loss 0.027176 | Grad 0.0423 \n","[2023-12-09 07:33:15,536::train::INFO] [Train] Iter 3007 | Loss 0.026648 | Grad 0.0409 \n","[2023-12-09 07:33:15,625::train::INFO] [Train] Iter 3008 | Loss 0.029316 | Grad 0.0516 \n","[2023-12-09 07:33:15,715::train::INFO] [Train] Iter 3009 | Loss 0.027521 | Grad 0.0535 \n","[2023-12-09 07:33:15,806::train::INFO] [Train] Iter 3010 | Loss 0.028696 | Grad 0.0534 \n","[2023-12-09 07:33:15,896::train::INFO] [Train] Iter 3011 | Loss 0.026909 | Grad 0.0484 \n","[2023-12-09 07:33:15,987::train::INFO] [Train] Iter 3012 | Loss 0.028340 | Grad 0.0523 \n","[2023-12-09 07:33:16,076::train::INFO] [Train] Iter 3013 | Loss 0.028121 | Grad 0.0558 \n","[2023-12-09 07:33:16,165::train::INFO] [Train] Iter 3014 | Loss 0.030188 | Grad 0.0558 \n","[2023-12-09 07:33:16,255::train::INFO] [Train] Iter 3015 | Loss 0.028343 | Grad 0.0305 \n","[2023-12-09 07:33:16,349::train::INFO] [Train] Iter 3016 | Loss 0.032530 | Grad 0.0654 \n","[2023-12-09 07:33:16,439::train::INFO] [Train] Iter 3017 | Loss 0.029493 | Grad 0.0493 \n","[2023-12-09 07:33:16,531::train::INFO] [Train] Iter 3018 | Loss 0.025208 | Grad 0.0405 \n","[2023-12-09 07:33:16,623::train::INFO] [Train] Iter 3019 | Loss 0.030866 | Grad 0.0364 \n","[2023-12-09 07:33:16,714::train::INFO] [Train] Iter 3020 | Loss 0.028802 | Grad 0.0529 \n","[2023-12-09 07:33:16,803::train::INFO] [Train] Iter 3021 | Loss 0.025936 | Grad 0.0491 \n","[2023-12-09 07:33:16,895::train::INFO] [Train] Iter 3022 | Loss 0.029359 | Grad 0.0347 \n","[2023-12-09 07:33:16,985::train::INFO] [Train] Iter 3023 | Loss 0.027863 | Grad 0.0531 \n","[2023-12-09 07:33:17,075::train::INFO] [Train] Iter 3024 | Loss 0.028519 | Grad 0.0327 \n","[2023-12-09 07:33:17,164::train::INFO] [Train] Iter 3025 | Loss 0.028955 | Grad 0.0460 \n","[2023-12-09 07:33:17,265::train::INFO] [Train] Iter 3026 | Loss 0.028932 | Grad 0.0335 \n","[2023-12-09 07:33:17,356::train::INFO] [Train] Iter 3027 | Loss 0.028334 | Grad 0.0399 \n","[2023-12-09 07:33:17,446::train::INFO] [Train] Iter 3028 | Loss 0.025197 | Grad 0.0530 \n","[2023-12-09 07:33:17,543::train::INFO] [Train] Iter 3029 | Loss 0.028758 | Grad 0.0381 \n","[2023-12-09 07:33:17,634::train::INFO] [Train] Iter 3030 | Loss 0.029745 | Grad 0.0404 \n","[2023-12-09 07:33:17,725::train::INFO] [Train] Iter 3031 | Loss 0.027725 | Grad 0.0315 \n","[2023-12-09 07:33:17,819::train::INFO] [Train] Iter 3032 | Loss 0.028319 | Grad 0.0386 \n","[2023-12-09 07:33:17,918::train::INFO] [Train] Iter 3033 | Loss 0.029077 | Grad 0.0448 \n","[2023-12-09 07:33:18,013::train::INFO] [Train] Iter 3034 | Loss 0.028963 | Grad 0.0305 \n","[2023-12-09 07:33:18,106::train::INFO] [Train] Iter 3035 | Loss 0.027546 | Grad 0.0443 \n","[2023-12-09 07:33:18,196::train::INFO] [Train] Iter 3036 | Loss 0.028124 | Grad 0.0338 \n","[2023-12-09 07:33:18,285::train::INFO] [Train] Iter 3037 | Loss 0.030528 | Grad 0.0527 \n","[2023-12-09 07:33:18,379::train::INFO] [Train] Iter 3038 | Loss 0.028473 | Grad 0.0463 \n","[2023-12-09 07:33:18,479::train::INFO] [Train] Iter 3039 | Loss 0.028407 | Grad 0.0421 \n","[2023-12-09 07:33:18,574::train::INFO] [Train] Iter 3040 | Loss 0.029275 | Grad 0.0381 \n","[2023-12-09 07:33:18,665::train::INFO] [Train] Iter 3041 | Loss 0.026283 | Grad 0.0380 \n","[2023-12-09 07:33:18,766::train::INFO] [Train] Iter 3042 | Loss 0.030495 | Grad 0.0392 \n","[2023-12-09 07:33:18,856::train::INFO] [Train] Iter 3043 | Loss 0.028811 | Grad 0.0379 \n","[2023-12-09 07:33:18,947::train::INFO] [Train] Iter 3044 | Loss 0.026463 | Grad 0.0422 \n","[2023-12-09 07:33:19,040::train::INFO] [Train] Iter 3045 | Loss 0.028785 | Grad 0.0484 \n","[2023-12-09 07:33:19,129::train::INFO] [Train] Iter 3046 | Loss 0.031009 | Grad 0.0824 \n","[2023-12-09 07:33:19,217::train::INFO] [Train] Iter 3047 | Loss 0.027799 | Grad 0.0387 \n","[2023-12-09 07:33:19,307::train::INFO] [Train] Iter 3048 | Loss 0.029340 | Grad 0.0458 \n","[2023-12-09 07:33:19,397::train::INFO] [Train] Iter 3049 | Loss 0.028857 | Grad 0.0504 \n","[2023-12-09 07:33:19,488::train::INFO] [Train] Iter 3050 | Loss 0.029110 | Grad 0.0503 \n","[2023-12-09 07:33:19,578::train::INFO] [Train] Iter 3051 | Loss 0.026271 | Grad 0.0446 \n","[2023-12-09 07:33:19,667::train::INFO] [Train] Iter 3052 | Loss 0.028683 | Grad 0.0452 \n","[2023-12-09 07:33:19,757::train::INFO] [Train] Iter 3053 | Loss 0.028825 | Grad 0.0515 \n","[2023-12-09 07:33:19,848::train::INFO] [Train] Iter 3054 | Loss 0.029776 | Grad 0.0382 \n","[2023-12-09 07:33:19,937::train::INFO] [Train] Iter 3055 | Loss 0.026297 | Grad 0.0415 \n","[2023-12-09 07:33:20,028::train::INFO] [Train] Iter 3056 | Loss 0.030342 | Grad 0.0507 \n","[2023-12-09 07:33:20,119::train::INFO] [Train] Iter 3057 | Loss 0.030561 | Grad 0.0429 \n","[2023-12-09 07:33:20,210::train::INFO] [Train] Iter 3058 | Loss 0.026195 | Grad 0.0415 \n","[2023-12-09 07:33:20,299::train::INFO] [Train] Iter 3059 | Loss 0.026709 | Grad 0.0451 \n","[2023-12-09 07:33:20,338::train::INFO] [Train] Iter 3060 | Loss 0.026797 | Grad 0.0806 \n","[2023-12-09 07:33:20,428::train::INFO] [Train] Iter 3061 | Loss 0.026675 | Grad 0.0388 \n","[2023-12-09 07:33:20,522::train::INFO] [Train] Iter 3062 | Loss 0.029970 | Grad 0.0497 \n","[2023-12-09 07:33:20,612::train::INFO] [Train] Iter 3063 | Loss 0.028215 | Grad 0.0530 \n","[2023-12-09 07:33:20,701::train::INFO] [Train] Iter 3064 | Loss 0.029364 | Grad 0.0354 \n","[2023-12-09 07:33:20,793::train::INFO] [Train] Iter 3065 | Loss 0.028320 | Grad 0.0368 \n","[2023-12-09 07:33:20,881::train::INFO] [Train] Iter 3066 | Loss 0.030440 | Grad 0.0406 \n","[2023-12-09 07:33:20,972::train::INFO] [Train] Iter 3067 | Loss 0.028503 | Grad 0.0515 \n","[2023-12-09 07:33:21,066::train::INFO] [Train] Iter 3068 | Loss 0.029931 | Grad 0.0347 \n","[2023-12-09 07:33:21,157::train::INFO] [Train] Iter 3069 | Loss 0.028562 | Grad 0.0444 \n","[2023-12-09 07:33:21,247::train::INFO] [Train] Iter 3070 | Loss 0.029431 | Grad 0.0438 \n","[2023-12-09 07:33:21,339::train::INFO] [Train] Iter 3071 | Loss 0.027485 | Grad 0.0416 \n","[2023-12-09 07:33:21,424::train::INFO] [Train] Iter 3072 | Loss 0.030421 | Grad 0.0452 \n","[2023-12-09 07:33:21,507::train::INFO] [Train] Iter 3073 | Loss 0.028359 | Grad 0.0440 \n","[2023-12-09 07:33:21,597::train::INFO] [Train] Iter 3074 | Loss 0.028625 | Grad 0.0402 \n","[2023-12-09 07:33:21,679::train::INFO] [Train] Iter 3075 | Loss 0.028771 | Grad 0.0345 \n","[2023-12-09 07:33:21,762::train::INFO] [Train] Iter 3076 | Loss 0.028386 | Grad 0.0407 \n","[2023-12-09 07:33:21,846::train::INFO] [Train] Iter 3077 | Loss 0.028675 | Grad 0.0484 \n","[2023-12-09 07:33:21,930::train::INFO] [Train] Iter 3078 | Loss 0.027647 | Grad 0.0454 \n","[2023-12-09 07:33:22,014::train::INFO] [Train] Iter 3079 | Loss 0.030211 | Grad 0.0328 \n","[2023-12-09 07:33:22,104::train::INFO] [Train] Iter 3080 | Loss 0.027694 | Grad 0.0506 \n","[2023-12-09 07:33:22,188::train::INFO] [Train] Iter 3081 | Loss 0.026681 | Grad 0.0372 \n","[2023-12-09 07:33:22,297::train::INFO] [Train] Iter 3082 | Loss 0.029604 | Grad 0.0340 \n","[2023-12-09 07:33:22,381::train::INFO] [Train] Iter 3083 | Loss 0.027762 | Grad 0.0495 \n","[2023-12-09 07:33:22,463::train::INFO] [Train] Iter 3084 | Loss 0.028248 | Grad 0.0576 \n","[2023-12-09 07:33:22,546::train::INFO] [Train] Iter 3085 | Loss 0.027823 | Grad 0.0339 \n","[2023-12-09 07:33:22,630::train::INFO] [Train] Iter 3086 | Loss 0.028582 | Grad 0.0501 \n","[2023-12-09 07:33:22,713::train::INFO] [Train] Iter 3087 | Loss 0.030210 | Grad 0.0444 \n","[2023-12-09 07:33:22,797::train::INFO] [Train] Iter 3088 | Loss 0.029178 | Grad 0.0398 \n","[2023-12-09 07:33:22,881::train::INFO] [Train] Iter 3089 | Loss 0.027209 | Grad 0.0444 \n","[2023-12-09 07:33:22,964::train::INFO] [Train] Iter 3090 | Loss 0.028887 | Grad 0.0387 \n","[2023-12-09 07:33:23,047::train::INFO] [Train] Iter 3091 | Loss 0.030404 | Grad 0.0461 \n","[2023-12-09 07:33:23,129::train::INFO] [Train] Iter 3092 | Loss 0.027127 | Grad 0.0293 \n","[2023-12-09 07:33:23,212::train::INFO] [Train] Iter 3093 | Loss 0.029813 | Grad 0.0539 \n","[2023-12-09 07:33:23,294::train::INFO] [Train] Iter 3094 | Loss 0.029130 | Grad 0.0604 \n","[2023-12-09 07:33:23,377::train::INFO] [Train] Iter 3095 | Loss 0.026577 | Grad 0.0318 \n","[2023-12-09 07:33:23,459::train::INFO] [Train] Iter 3096 | Loss 0.030524 | Grad 0.0340 \n","[2023-12-09 07:33:23,542::train::INFO] [Train] Iter 3097 | Loss 0.028678 | Grad 0.0357 \n","[2023-12-09 07:33:23,632::train::INFO] [Train] Iter 3098 | Loss 0.030314 | Grad 0.0381 \n","[2023-12-09 07:33:23,714::train::INFO] [Train] Iter 3099 | Loss 0.027174 | Grad 0.0278 \n","[2023-12-09 07:33:23,803::train::INFO] [Train] Iter 3100 | Loss 0.028449 | Grad 0.0441 \n","[2023-12-09 07:33:23,885::train::INFO] [Train] Iter 3101 | Loss 0.029380 | Grad 0.0488 \n","[2023-12-09 07:33:23,968::train::INFO] [Train] Iter 3102 | Loss 0.028602 | Grad 0.0266 \n","[2023-12-09 07:33:24,052::train::INFO] [Train] Iter 3103 | Loss 0.028438 | Grad 0.0479 \n","[2023-12-09 07:33:24,135::train::INFO] [Train] Iter 3104 | Loss 0.027649 | Grad 0.0429 \n","[2023-12-09 07:33:24,219::train::INFO] [Train] Iter 3105 | Loss 0.028715 | Grad 0.0292 \n","[2023-12-09 07:33:24,309::train::INFO] [Train] Iter 3106 | Loss 0.028855 | Grad 0.0405 \n","[2023-12-09 07:33:24,392::train::INFO] [Train] Iter 3107 | Loss 0.026683 | Grad 0.0366 \n","[2023-12-09 07:33:24,475::train::INFO] [Train] Iter 3108 | Loss 0.027325 | Grad 0.0486 \n","[2023-12-09 07:33:24,561::train::INFO] [Train] Iter 3109 | Loss 0.029331 | Grad 0.0382 \n","[2023-12-09 07:33:24,647::train::INFO] [Train] Iter 3110 | Loss 0.026969 | Grad 0.0372 \n","[2023-12-09 07:33:24,730::train::INFO] [Train] Iter 3111 | Loss 0.030671 | Grad 0.0375 \n","[2023-12-09 07:33:24,813::train::INFO] [Train] Iter 3112 | Loss 0.027874 | Grad 0.0383 \n","[2023-12-09 07:33:24,897::train::INFO] [Train] Iter 3113 | Loss 0.028992 | Grad 0.0416 \n","[2023-12-09 07:33:24,982::train::INFO] [Train] Iter 3114 | Loss 0.027655 | Grad 0.0431 \n","[2023-12-09 07:33:25,068::train::INFO] [Train] Iter 3115 | Loss 0.028873 | Grad 0.0341 \n","[2023-12-09 07:33:25,151::train::INFO] [Train] Iter 3116 | Loss 0.031153 | Grad 0.0486 \n","[2023-12-09 07:33:25,237::train::INFO] [Train] Iter 3117 | Loss 0.028317 | Grad 0.0415 \n","[2023-12-09 07:33:25,321::train::INFO] [Train] Iter 3118 | Loss 0.028233 | Grad 0.0492 \n","[2023-12-09 07:33:25,405::train::INFO] [Train] Iter 3119 | Loss 0.027272 | Grad 0.0366 \n","[2023-12-09 07:33:25,488::train::INFO] [Train] Iter 3120 | Loss 0.026382 | Grad 0.0406 \n","[2023-12-09 07:33:25,571::train::INFO] [Train] Iter 3121 | Loss 0.029732 | Grad 0.0547 \n","[2023-12-09 07:33:25,653::train::INFO] [Train] Iter 3122 | Loss 0.030864 | Grad 0.0386 \n","[2023-12-09 07:33:25,736::train::INFO] [Train] Iter 3123 | Loss 0.028126 | Grad 0.0340 \n","[2023-12-09 07:33:25,819::train::INFO] [Train] Iter 3124 | Loss 0.030260 | Grad 0.0545 \n","[2023-12-09 07:33:25,903::train::INFO] [Train] Iter 3125 | Loss 0.030193 | Grad 0.0428 \n","[2023-12-09 07:33:25,986::train::INFO] [Train] Iter 3126 | Loss 0.027977 | Grad 0.0546 \n","[2023-12-09 07:33:26,070::train::INFO] [Train] Iter 3127 | Loss 0.028674 | Grad 0.0307 \n","[2023-12-09 07:33:26,157::train::INFO] [Train] Iter 3128 | Loss 0.026443 | Grad 0.0359 \n","[2023-12-09 07:33:26,241::train::INFO] [Train] Iter 3129 | Loss 0.028596 | Grad 0.0420 \n","[2023-12-09 07:33:26,325::train::INFO] [Train] Iter 3130 | Loss 0.028263 | Grad 0.0399 \n","[2023-12-09 07:33:26,413::train::INFO] [Train] Iter 3131 | Loss 0.028434 | Grad 0.0312 \n","[2023-12-09 07:33:26,496::train::INFO] [Train] Iter 3132 | Loss 0.027928 | Grad 0.0427 \n","[2023-12-09 07:33:26,581::train::INFO] [Train] Iter 3133 | Loss 0.028502 | Grad 0.0557 \n","[2023-12-09 07:33:26,664::train::INFO] [Train] Iter 3134 | Loss 0.027370 | Grad 0.0326 \n","[2023-12-09 07:33:26,747::train::INFO] [Train] Iter 3135 | Loss 0.028470 | Grad 0.0352 \n","[2023-12-09 07:33:26,830::train::INFO] [Train] Iter 3136 | Loss 0.027598 | Grad 0.0576 \n","[2023-12-09 07:33:26,915::train::INFO] [Train] Iter 3137 | Loss 0.027427 | Grad 0.0323 \n","[2023-12-09 07:33:26,997::train::INFO] [Train] Iter 3138 | Loss 0.027495 | Grad 0.0444 \n","[2023-12-09 07:33:27,084::train::INFO] [Train] Iter 3139 | Loss 0.028856 | Grad 0.0438 \n","[2023-12-09 07:33:27,167::train::INFO] [Train] Iter 3140 | Loss 0.027294 | Grad 0.0423 \n","[2023-12-09 07:33:27,250::train::INFO] [Train] Iter 3141 | Loss 0.028321 | Grad 0.0414 \n","[2023-12-09 07:33:27,333::train::INFO] [Train] Iter 3142 | Loss 0.026122 | Grad 0.0353 \n","[2023-12-09 07:33:27,416::train::INFO] [Train] Iter 3143 | Loss 0.027071 | Grad 0.0315 \n","[2023-12-09 07:33:27,500::train::INFO] [Train] Iter 3144 | Loss 0.029242 | Grad 0.0332 \n","[2023-12-09 07:33:27,582::train::INFO] [Train] Iter 3145 | Loss 0.028864 | Grad 0.0468 \n","[2023-12-09 07:33:27,665::train::INFO] [Train] Iter 3146 | Loss 0.029005 | Grad 0.0490 \n","[2023-12-09 07:33:27,749::train::INFO] [Train] Iter 3147 | Loss 0.028195 | Grad 0.0492 \n","[2023-12-09 07:33:27,834::train::INFO] [Train] Iter 3148 | Loss 0.029926 | Grad 0.0329 \n","[2023-12-09 07:33:27,917::train::INFO] [Train] Iter 3149 | Loss 0.028115 | Grad 0.0391 \n","[2023-12-09 07:33:28,000::train::INFO] [Train] Iter 3150 | Loss 0.029547 | Grad 0.0502 \n","[2023-12-09 07:33:28,084::train::INFO] [Train] Iter 3151 | Loss 0.027091 | Grad 0.0317 \n","[2023-12-09 07:33:28,167::train::INFO] [Train] Iter 3152 | Loss 0.028262 | Grad 0.0385 \n","[2023-12-09 07:33:28,249::train::INFO] [Train] Iter 3153 | Loss 0.028130 | Grad 0.0317 \n","[2023-12-09 07:33:28,331::train::INFO] [Train] Iter 3154 | Loss 0.028250 | Grad 0.0569 \n","[2023-12-09 07:33:28,414::train::INFO] [Train] Iter 3155 | Loss 0.030673 | Grad 0.0339 \n","[2023-12-09 07:33:28,497::train::INFO] [Train] Iter 3156 | Loss 0.025317 | Grad 0.0422 \n","[2023-12-09 07:33:28,582::train::INFO] [Train] Iter 3157 | Loss 0.028521 | Grad 0.0365 \n","[2023-12-09 07:33:28,664::train::INFO] [Train] Iter 3158 | Loss 0.027580 | Grad 0.0384 \n","[2023-12-09 07:33:28,752::train::INFO] [Train] Iter 3159 | Loss 0.027156 | Grad 0.0533 \n","[2023-12-09 07:33:28,835::train::INFO] [Train] Iter 3160 | Loss 0.029964 | Grad 0.0372 \n","[2023-12-09 07:33:28,921::train::INFO] [Train] Iter 3161 | Loss 0.028091 | Grad 0.0339 \n","[2023-12-09 07:33:29,005::train::INFO] [Train] Iter 3162 | Loss 0.027777 | Grad 0.0331 \n","[2023-12-09 07:33:29,089::train::INFO] [Train] Iter 3163 | Loss 0.027869 | Grad 0.0449 \n","[2023-12-09 07:33:29,172::train::INFO] [Train] Iter 3164 | Loss 0.027947 | Grad 0.0312 \n","[2023-12-09 07:33:29,254::train::INFO] [Train] Iter 3165 | Loss 0.028575 | Grad 0.0342 \n","[2023-12-09 07:33:29,342::train::INFO] [Train] Iter 3166 | Loss 0.029611 | Grad 0.0585 \n","[2023-12-09 07:33:29,425::train::INFO] [Train] Iter 3167 | Loss 0.025621 | Grad 0.0413 \n","[2023-12-09 07:33:29,508::train::INFO] [Train] Iter 3168 | Loss 0.029208 | Grad 0.0303 \n","[2023-12-09 07:33:29,590::train::INFO] [Train] Iter 3169 | Loss 0.031668 | Grad 0.0525 \n","[2023-12-09 07:33:29,673::train::INFO] [Train] Iter 3170 | Loss 0.027802 | Grad 0.0422 \n","[2023-12-09 07:33:29,762::train::INFO] [Train] Iter 3171 | Loss 0.029672 | Grad 0.0302 \n","[2023-12-09 07:33:29,844::train::INFO] [Train] Iter 3172 | Loss 0.027927 | Grad 0.0463 \n","[2023-12-09 07:33:29,931::train::INFO] [Train] Iter 3173 | Loss 0.027851 | Grad 0.0360 \n","[2023-12-09 07:33:30,013::train::INFO] [Train] Iter 3174 | Loss 0.028587 | Grad 0.0482 \n","[2023-12-09 07:33:30,096::train::INFO] [Train] Iter 3175 | Loss 0.027866 | Grad 0.0424 \n","[2023-12-09 07:33:30,179::train::INFO] [Train] Iter 3176 | Loss 0.028589 | Grad 0.0503 \n","[2023-12-09 07:33:30,261::train::INFO] [Train] Iter 3177 | Loss 0.028783 | Grad 0.0321 \n","[2023-12-09 07:33:30,343::train::INFO] [Train] Iter 3178 | Loss 0.027948 | Grad 0.0459 \n","[2023-12-09 07:33:30,426::train::INFO] [Train] Iter 3179 | Loss 0.024943 | Grad 0.0441 \n","[2023-12-09 07:33:30,509::train::INFO] [Train] Iter 3180 | Loss 0.029383 | Grad 0.0441 \n","[2023-12-09 07:33:30,591::train::INFO] [Train] Iter 3181 | Loss 0.027501 | Grad 0.0352 \n","[2023-12-09 07:33:30,674::train::INFO] [Train] Iter 3182 | Loss 0.025622 | Grad 0.0390 \n","[2023-12-09 07:33:30,757::train::INFO] [Train] Iter 3183 | Loss 0.026656 | Grad 0.0300 \n","[2023-12-09 07:33:30,840::train::INFO] [Train] Iter 3184 | Loss 0.028733 | Grad 0.0518 \n","[2023-12-09 07:33:30,923::train::INFO] [Train] Iter 3185 | Loss 0.028178 | Grad 0.0541 \n","[2023-12-09 07:33:31,006::train::INFO] [Train] Iter 3186 | Loss 0.028496 | Grad 0.0422 \n","[2023-12-09 07:33:31,093::train::INFO] [Train] Iter 3187 | Loss 0.026734 | Grad 0.0268 \n","[2023-12-09 07:33:31,175::train::INFO] [Train] Iter 3188 | Loss 0.027852 | Grad 0.0356 \n","[2023-12-09 07:33:31,257::train::INFO] [Train] Iter 3189 | Loss 0.028908 | Grad 0.0400 \n","[2023-12-09 07:33:31,342::train::INFO] [Train] Iter 3190 | Loss 0.026447 | Grad 0.0433 \n","[2023-12-09 07:33:31,433::train::INFO] [Train] Iter 3191 | Loss 0.029065 | Grad 0.0307 \n","[2023-12-09 07:33:31,527::train::INFO] [Train] Iter 3192 | Loss 0.028896 | Grad 0.0394 \n","[2023-12-09 07:33:31,619::train::INFO] [Train] Iter 3193 | Loss 0.027973 | Grad 0.0325 \n","[2023-12-09 07:33:31,708::train::INFO] [Train] Iter 3194 | Loss 0.026822 | Grad 0.0509 \n","[2023-12-09 07:33:31,799::train::INFO] [Train] Iter 3195 | Loss 0.027283 | Grad 0.0299 \n","[2023-12-09 07:33:31,889::train::INFO] [Train] Iter 3196 | Loss 0.026484 | Grad 0.0621 \n","[2023-12-09 07:33:31,979::train::INFO] [Train] Iter 3197 | Loss 0.027415 | Grad 0.0534 \n","[2023-12-09 07:33:32,071::train::INFO] [Train] Iter 3198 | Loss 0.027646 | Grad 0.0669 \n","[2023-12-09 07:33:32,162::train::INFO] [Train] Iter 3199 | Loss 0.028408 | Grad 0.0616 \n","[2023-12-09 07:33:32,256::train::INFO] [Train] Iter 3200 | Loss 0.028433 | Grad 0.0530 \n","[2023-12-09 07:33:32,348::train::INFO] [Train] Iter 3201 | Loss 0.029260 | Grad 0.0631 \n","[2023-12-09 07:33:32,438::train::INFO] [Train] Iter 3202 | Loss 0.028074 | Grad 0.0406 \n","[2023-12-09 07:33:32,528::train::INFO] [Train] Iter 3203 | Loss 0.030291 | Grad 0.0415 \n","[2023-12-09 07:33:32,620::train::INFO] [Train] Iter 3204 | Loss 0.028615 | Grad 0.0608 \n","[2023-12-09 07:33:32,710::train::INFO] [Train] Iter 3205 | Loss 0.031036 | Grad 0.0423 \n","[2023-12-09 07:33:32,807::train::INFO] [Train] Iter 3206 | Loss 0.029256 | Grad 0.0393 \n","[2023-12-09 07:33:32,897::train::INFO] [Train] Iter 3207 | Loss 0.027969 | Grad 0.0430 \n","[2023-12-09 07:33:32,987::train::INFO] [Train] Iter 3208 | Loss 0.028933 | Grad 0.0510 \n","[2023-12-09 07:33:33,079::train::INFO] [Train] Iter 3209 | Loss 0.029472 | Grad 0.0360 \n","[2023-12-09 07:33:33,173::train::INFO] [Train] Iter 3210 | Loss 0.030602 | Grad 0.0463 \n","[2023-12-09 07:33:33,263::train::INFO] [Train] Iter 3211 | Loss 0.030674 | Grad 0.0429 \n","[2023-12-09 07:33:33,353::train::INFO] [Train] Iter 3212 | Loss 0.029949 | Grad 0.0543 \n","[2023-12-09 07:33:33,452::train::INFO] [Train] Iter 3213 | Loss 0.027816 | Grad 0.0350 \n","[2023-12-09 07:33:33,542::train::INFO] [Train] Iter 3214 | Loss 0.027711 | Grad 0.0552 \n","[2023-12-09 07:33:33,631::train::INFO] [Train] Iter 3215 | Loss 0.028637 | Grad 0.0364 \n","[2023-12-09 07:33:33,722::train::INFO] [Train] Iter 3216 | Loss 0.029488 | Grad 0.0289 \n","[2023-12-09 07:33:33,823::train::INFO] [Train] Iter 3217 | Loss 0.026183 | Grad 0.0378 \n","[2023-12-09 07:33:33,913::train::INFO] [Train] Iter 3218 | Loss 0.028429 | Grad 0.0428 \n","[2023-12-09 07:33:34,008::train::INFO] [Train] Iter 3219 | Loss 0.026237 | Grad 0.0433 \n","[2023-12-09 07:33:34,103::train::INFO] [Train] Iter 3220 | Loss 0.027487 | Grad 0.0432 \n","[2023-12-09 07:33:34,193::train::INFO] [Train] Iter 3221 | Loss 0.027763 | Grad 0.0387 \n","[2023-12-09 07:33:34,283::train::INFO] [Train] Iter 3222 | Loss 0.029031 | Grad 0.0427 \n","[2023-12-09 07:33:34,374::train::INFO] [Train] Iter 3223 | Loss 0.030232 | Grad 0.0591 \n","[2023-12-09 07:33:34,463::train::INFO] [Train] Iter 3224 | Loss 0.029822 | Grad 0.0651 \n","[2023-12-09 07:33:34,554::train::INFO] [Train] Iter 3225 | Loss 0.027378 | Grad 0.0413 \n","[2023-12-09 07:33:34,644::train::INFO] [Train] Iter 3226 | Loss 0.028849 | Grad 0.0541 \n","[2023-12-09 07:33:34,735::train::INFO] [Train] Iter 3227 | Loss 0.027903 | Grad 0.0427 \n","[2023-12-09 07:33:34,825::train::INFO] [Train] Iter 3228 | Loss 0.029952 | Grad 0.0754 \n","[2023-12-09 07:33:34,916::train::INFO] [Train] Iter 3229 | Loss 0.026033 | Grad 0.0443 \n","[2023-12-09 07:33:35,006::train::INFO] [Train] Iter 3230 | Loss 0.026253 | Grad 0.0432 \n","[2023-12-09 07:33:35,097::train::INFO] [Train] Iter 3231 | Loss 0.027461 | Grad 0.0371 \n","[2023-12-09 07:33:35,187::train::INFO] [Train] Iter 3232 | Loss 0.031294 | Grad 0.0400 \n","[2023-12-09 07:33:35,279::train::INFO] [Train] Iter 3233 | Loss 0.030568 | Grad 0.0574 \n","[2023-12-09 07:33:35,369::train::INFO] [Train] Iter 3234 | Loss 0.027722 | Grad 0.0404 \n","[2023-12-09 07:33:35,458::train::INFO] [Train] Iter 3235 | Loss 0.028470 | Grad 0.0355 \n","[2023-12-09 07:33:35,546::train::INFO] [Train] Iter 3236 | Loss 0.026905 | Grad 0.0416 \n","[2023-12-09 07:33:35,635::train::INFO] [Train] Iter 3237 | Loss 0.026997 | Grad 0.0293 \n","[2023-12-09 07:33:35,725::train::INFO] [Train] Iter 3238 | Loss 0.026152 | Grad 0.0521 \n","[2023-12-09 07:33:35,816::train::INFO] [Train] Iter 3239 | Loss 0.026250 | Grad 0.0328 \n","[2023-12-09 07:33:35,906::train::INFO] [Train] Iter 3240 | Loss 0.029412 | Grad 0.0380 \n","[2023-12-09 07:33:35,998::train::INFO] [Train] Iter 3241 | Loss 0.030513 | Grad 0.0487 \n","[2023-12-09 07:33:36,093::train::INFO] [Train] Iter 3242 | Loss 0.027075 | Grad 0.0388 \n","[2023-12-09 07:33:36,184::train::INFO] [Train] Iter 3243 | Loss 0.026081 | Grad 0.0338 \n","[2023-12-09 07:33:36,276::train::INFO] [Train] Iter 3244 | Loss 0.029218 | Grad 0.0477 \n","[2023-12-09 07:33:36,377::train::INFO] [Train] Iter 3245 | Loss 0.026794 | Grad 0.0348 \n","[2023-12-09 07:33:36,467::train::INFO] [Train] Iter 3246 | Loss 0.029158 | Grad 0.0344 \n","[2023-12-09 07:33:36,557::train::INFO] [Train] Iter 3247 | Loss 0.026756 | Grad 0.0283 \n","[2023-12-09 07:33:36,649::train::INFO] [Train] Iter 3248 | Loss 0.029285 | Grad 0.0301 \n","[2023-12-09 07:33:36,739::train::INFO] [Train] Iter 3249 | Loss 0.028459 | Grad 0.0472 \n","[2023-12-09 07:33:36,828::train::INFO] [Train] Iter 3250 | Loss 0.029359 | Grad 0.0380 \n","[2023-12-09 07:33:36,922::train::INFO] [Train] Iter 3251 | Loss 0.029242 | Grad 0.0402 \n","[2023-12-09 07:33:37,023::train::INFO] [Train] Iter 3252 | Loss 0.027430 | Grad 0.0545 \n","[2023-12-09 07:33:37,114::train::INFO] [Train] Iter 3253 | Loss 0.027586 | Grad 0.0408 \n","[2023-12-09 07:33:37,205::train::INFO] [Train] Iter 3254 | Loss 0.027909 | Grad 0.0336 \n","[2023-12-09 07:33:37,305::train::INFO] [Train] Iter 3255 | Loss 0.029667 | Grad 0.0415 \n","[2023-12-09 07:33:37,396::train::INFO] [Train] Iter 3256 | Loss 0.029723 | Grad 0.0302 \n","[2023-12-09 07:33:37,485::train::INFO] [Train] Iter 3257 | Loss 0.027707 | Grad 0.0566 \n","[2023-12-09 07:33:37,576::train::INFO] [Train] Iter 3258 | Loss 0.027160 | Grad 0.0531 \n","[2023-12-09 07:33:37,666::train::INFO] [Train] Iter 3259 | Loss 0.029206 | Grad 0.0329 \n","[2023-12-09 07:33:37,749::train::INFO] [Train] Iter 3260 | Loss 0.025981 | Grad 0.0331 \n","[2023-12-09 07:33:37,831::train::INFO] [Train] Iter 3261 | Loss 0.026753 | Grad 0.0398 \n","[2023-12-09 07:33:37,915::train::INFO] [Train] Iter 3262 | Loss 0.028384 | Grad 0.0374 \n","[2023-12-09 07:33:37,998::train::INFO] [Train] Iter 3263 | Loss 0.029366 | Grad 0.0361 \n","[2023-12-09 07:33:38,082::train::INFO] [Train] Iter 3264 | Loss 0.027901 | Grad 0.0392 \n","[2023-12-09 07:33:38,166::train::INFO] [Train] Iter 3265 | Loss 0.027123 | Grad 0.0422 \n","[2023-12-09 07:33:38,251::train::INFO] [Train] Iter 3266 | Loss 0.027601 | Grad 0.0300 \n","[2023-12-09 07:33:38,335::train::INFO] [Train] Iter 3267 | Loss 0.027826 | Grad 0.0318 \n","[2023-12-09 07:33:38,419::train::INFO] [Train] Iter 3268 | Loss 0.027658 | Grad 0.0391 \n","[2023-12-09 07:33:38,504::train::INFO] [Train] Iter 3269 | Loss 0.026626 | Grad 0.0343 \n","[2023-12-09 07:33:38,589::train::INFO] [Train] Iter 3270 | Loss 0.030014 | Grad 0.0443 \n","[2023-12-09 07:33:38,673::train::INFO] [Train] Iter 3271 | Loss 0.029388 | Grad 0.0354 \n","[2023-12-09 07:33:38,759::train::INFO] [Train] Iter 3272 | Loss 0.027394 | Grad 0.0475 \n","[2023-12-09 07:33:38,843::train::INFO] [Train] Iter 3273 | Loss 0.028270 | Grad 0.0375 \n","[2023-12-09 07:33:38,927::train::INFO] [Train] Iter 3274 | Loss 0.029071 | Grad 0.0313 \n","[2023-12-09 07:33:39,010::train::INFO] [Train] Iter 3275 | Loss 0.026898 | Grad 0.0479 \n","[2023-12-09 07:33:39,100::train::INFO] [Train] Iter 3276 | Loss 0.029840 | Grad 0.0327 \n","[2023-12-09 07:33:39,185::train::INFO] [Train] Iter 3277 | Loss 0.027251 | Grad 0.0353 \n","[2023-12-09 07:33:39,269::train::INFO] [Train] Iter 3278 | Loss 0.030866 | Grad 0.0303 \n","[2023-12-09 07:33:39,354::train::INFO] [Train] Iter 3279 | Loss 0.027390 | Grad 0.0308 \n","[2023-12-09 07:33:39,437::train::INFO] [Train] Iter 3280 | Loss 0.028860 | Grad 0.0327 \n","[2023-12-09 07:33:39,521::train::INFO] [Train] Iter 3281 | Loss 0.027647 | Grad 0.0400 \n","[2023-12-09 07:33:39,605::train::INFO] [Train] Iter 3282 | Loss 0.027230 | Grad 0.0316 \n","[2023-12-09 07:33:39,694::train::INFO] [Train] Iter 3283 | Loss 0.027771 | Grad 0.0438 \n","[2023-12-09 07:33:39,779::train::INFO] [Train] Iter 3284 | Loss 0.028764 | Grad 0.0672 \n","[2023-12-09 07:33:39,864::train::INFO] [Train] Iter 3285 | Loss 0.028016 | Grad 0.0600 \n","[2023-12-09 07:33:39,947::train::INFO] [Train] Iter 3286 | Loss 0.028913 | Grad 0.0348 \n","[2023-12-09 07:33:40,030::train::INFO] [Train] Iter 3287 | Loss 0.028835 | Grad 0.0367 \n","[2023-12-09 07:33:40,120::train::INFO] [Train] Iter 3288 | Loss 0.026094 | Grad 0.0284 \n","[2023-12-09 07:33:40,205::train::INFO] [Train] Iter 3289 | Loss 0.029253 | Grad 0.0432 \n","[2023-12-09 07:33:40,296::train::INFO] [Train] Iter 3290 | Loss 0.026141 | Grad 0.0300 \n","[2023-12-09 07:33:40,381::train::INFO] [Train] Iter 3291 | Loss 0.029021 | Grad 0.0428 \n","[2023-12-09 07:33:40,467::train::INFO] [Train] Iter 3292 | Loss 0.028028 | Grad 0.0358 \n","[2023-12-09 07:33:40,551::train::INFO] [Train] Iter 3293 | Loss 0.030029 | Grad 0.0325 \n","[2023-12-09 07:33:40,635::train::INFO] [Train] Iter 3294 | Loss 0.027923 | Grad 0.0359 \n","[2023-12-09 07:33:40,718::train::INFO] [Train] Iter 3295 | Loss 0.028206 | Grad 0.0444 \n","[2023-12-09 07:33:40,801::train::INFO] [Train] Iter 3296 | Loss 0.028236 | Grad 0.0386 \n","[2023-12-09 07:33:40,886::train::INFO] [Train] Iter 3297 | Loss 0.027997 | Grad 0.0416 \n","[2023-12-09 07:33:40,969::train::INFO] [Train] Iter 3298 | Loss 0.026665 | Grad 0.0329 \n","[2023-12-09 07:33:41,053::train::INFO] [Train] Iter 3299 | Loss 0.027516 | Grad 0.0324 \n","[2023-12-09 07:33:41,142::train::INFO] [Train] Iter 3300 | Loss 0.027896 | Grad 0.0297 \n","[2023-12-09 07:33:41,229::train::INFO] [Train] Iter 3301 | Loss 0.028577 | Grad 0.0477 \n","[2023-12-09 07:33:41,312::train::INFO] [Train] Iter 3302 | Loss 0.027137 | Grad 0.0363 \n","[2023-12-09 07:33:41,395::train::INFO] [Train] Iter 3303 | Loss 0.028226 | Grad 0.0397 \n","[2023-12-09 07:33:41,480::train::INFO] [Train] Iter 3304 | Loss 0.029966 | Grad 0.0444 \n","[2023-12-09 07:33:41,564::train::INFO] [Train] Iter 3305 | Loss 0.029390 | Grad 0.0385 \n","[2023-12-09 07:33:41,650::train::INFO] [Train] Iter 3306 | Loss 0.027185 | Grad 0.0354 \n","[2023-12-09 07:33:41,734::train::INFO] [Train] Iter 3307 | Loss 0.025546 | Grad 0.0382 \n","[2023-12-09 07:33:41,819::train::INFO] [Train] Iter 3308 | Loss 0.028234 | Grad 0.0309 \n","[2023-12-09 07:33:41,903::train::INFO] [Train] Iter 3309 | Loss 0.025630 | Grad 0.0280 \n","[2023-12-09 07:33:41,986::train::INFO] [Train] Iter 3310 | Loss 0.025454 | Grad 0.0402 \n","[2023-12-09 07:33:42,073::train::INFO] [Train] Iter 3311 | Loss 0.027558 | Grad 0.0412 \n","[2023-12-09 07:33:42,163::train::INFO] [Train] Iter 3312 | Loss 0.027317 | Grad 0.0331 \n","[2023-12-09 07:33:42,247::train::INFO] [Train] Iter 3313 | Loss 0.029430 | Grad 0.0349 \n","[2023-12-09 07:33:42,330::train::INFO] [Train] Iter 3314 | Loss 0.027263 | Grad 0.0427 \n","[2023-12-09 07:33:42,416::train::INFO] [Train] Iter 3315 | Loss 0.026964 | Grad 0.0455 \n","[2023-12-09 07:33:42,500::train::INFO] [Train] Iter 3316 | Loss 0.026521 | Grad 0.0454 \n","[2023-12-09 07:33:42,584::train::INFO] [Train] Iter 3317 | Loss 0.028888 | Grad 0.0373 \n","[2023-12-09 07:33:42,666::train::INFO] [Train] Iter 3318 | Loss 0.028000 | Grad 0.0357 \n","[2023-12-09 07:33:42,750::train::INFO] [Train] Iter 3319 | Loss 0.029962 | Grad 0.0347 \n","[2023-12-09 07:33:42,835::train::INFO] [Train] Iter 3320 | Loss 0.029762 | Grad 0.0440 \n","[2023-12-09 07:33:42,919::train::INFO] [Train] Iter 3321 | Loss 0.028241 | Grad 0.0322 \n","[2023-12-09 07:33:43,007::train::INFO] [Train] Iter 3322 | Loss 0.029655 | Grad 0.0369 \n","[2023-12-09 07:33:43,092::train::INFO] [Train] Iter 3323 | Loss 0.026443 | Grad 0.0331 \n","[2023-12-09 07:33:43,183::train::INFO] [Train] Iter 3324 | Loss 0.027660 | Grad 0.0366 \n","[2023-12-09 07:33:43,268::train::INFO] [Train] Iter 3325 | Loss 0.028040 | Grad 0.0324 \n","[2023-12-09 07:33:43,354::train::INFO] [Train] Iter 3326 | Loss 0.029976 | Grad 0.0297 \n","[2023-12-09 07:33:43,439::train::INFO] [Train] Iter 3327 | Loss 0.028539 | Grad 0.0391 \n","[2023-12-09 07:33:43,523::train::INFO] [Train] Iter 3328 | Loss 0.028367 | Grad 0.0324 \n","[2023-12-09 07:33:43,609::train::INFO] [Train] Iter 3329 | Loss 0.026830 | Grad 0.0358 \n","[2023-12-09 07:33:43,693::train::INFO] [Train] Iter 3330 | Loss 0.029946 | Grad 0.0382 \n","[2023-12-09 07:33:43,779::train::INFO] [Train] Iter 3331 | Loss 0.029157 | Grad 0.0453 \n","[2023-12-09 07:33:43,864::train::INFO] [Train] Iter 3332 | Loss 0.025793 | Grad 0.0325 \n","[2023-12-09 07:33:43,948::train::INFO] [Train] Iter 3333 | Loss 0.025955 | Grad 0.0319 \n","[2023-12-09 07:33:44,032::train::INFO] [Train] Iter 3334 | Loss 0.027415 | Grad 0.0437 \n","[2023-12-09 07:33:44,122::train::INFO] [Train] Iter 3335 | Loss 0.026042 | Grad 0.0438 \n","[2023-12-09 07:33:44,214::train::INFO] [Train] Iter 3336 | Loss 0.027276 | Grad 0.0336 \n","[2023-12-09 07:33:44,299::train::INFO] [Train] Iter 3337 | Loss 0.027890 | Grad 0.0444 \n","[2023-12-09 07:33:44,383::train::INFO] [Train] Iter 3338 | Loss 0.027155 | Grad 0.0357 \n","[2023-12-09 07:33:44,468::train::INFO] [Train] Iter 3339 | Loss 0.028652 | Grad 0.0417 \n","[2023-12-09 07:33:44,553::train::INFO] [Train] Iter 3340 | Loss 0.027048 | Grad 0.0355 \n","[2023-12-09 07:33:44,638::train::INFO] [Train] Iter 3341 | Loss 0.028316 | Grad 0.0541 \n","[2023-12-09 07:33:44,722::train::INFO] [Train] Iter 3342 | Loss 0.027091 | Grad 0.0401 \n","[2023-12-09 07:33:44,807::train::INFO] [Train] Iter 3343 | Loss 0.026311 | Grad 0.0346 \n","[2023-12-09 07:33:44,892::train::INFO] [Train] Iter 3344 | Loss 0.029129 | Grad 0.0363 \n","[2023-12-09 07:33:44,977::train::INFO] [Train] Iter 3345 | Loss 0.026494 | Grad 0.0412 \n","[2023-12-09 07:33:45,062::train::INFO] [Train] Iter 3346 | Loss 0.026696 | Grad 0.0330 \n","[2023-12-09 07:33:45,150::train::INFO] [Train] Iter 3347 | Loss 0.026136 | Grad 0.0360 \n","[2023-12-09 07:33:45,235::train::INFO] [Train] Iter 3348 | Loss 0.028761 | Grad 0.0427 \n","[2023-12-09 07:33:45,320::train::INFO] [Train] Iter 3349 | Loss 0.027006 | Grad 0.0503 \n","[2023-12-09 07:33:45,404::train::INFO] [Train] Iter 3350 | Loss 0.028175 | Grad 0.0461 \n","[2023-12-09 07:33:45,490::train::INFO] [Train] Iter 3351 | Loss 0.026323 | Grad 0.0403 \n","[2023-12-09 07:33:45,575::train::INFO] [Train] Iter 3352 | Loss 0.027855 | Grad 0.0431 \n","[2023-12-09 07:33:45,658::train::INFO] [Train] Iter 3353 | Loss 0.027568 | Grad 0.0455 \n","[2023-12-09 07:33:45,745::train::INFO] [Train] Iter 3354 | Loss 0.029693 | Grad 0.0440 \n","[2023-12-09 07:33:45,830::train::INFO] [Train] Iter 3355 | Loss 0.027938 | Grad 0.0286 \n","[2023-12-09 07:33:45,915::train::INFO] [Train] Iter 3356 | Loss 0.032014 | Grad 0.0544 \n","[2023-12-09 07:33:46,002::train::INFO] [Train] Iter 3357 | Loss 0.029031 | Grad 0.0425 \n","[2023-12-09 07:33:46,086::train::INFO] [Train] Iter 3358 | Loss 0.024599 | Grad 0.0366 \n","[2023-12-09 07:33:46,172::train::INFO] [Train] Iter 3359 | Loss 0.030476 | Grad 0.0394 \n","[2023-12-09 07:33:46,259::train::INFO] [Train] Iter 3360 | Loss 0.028168 | Grad 0.0430 \n","[2023-12-09 07:33:46,345::train::INFO] [Train] Iter 3361 | Loss 0.025519 | Grad 0.0538 \n","[2023-12-09 07:33:46,429::train::INFO] [Train] Iter 3362 | Loss 0.029017 | Grad 0.0364 \n","[2023-12-09 07:33:46,513::train::INFO] [Train] Iter 3363 | Loss 0.027406 | Grad 0.0517 \n","[2023-12-09 07:33:46,599::train::INFO] [Train] Iter 3364 | Loss 0.027983 | Grad 0.0317 \n","[2023-12-09 07:33:46,684::train::INFO] [Train] Iter 3365 | Loss 0.028573 | Grad 0.0357 \n","[2023-12-09 07:33:46,769::train::INFO] [Train] Iter 3366 | Loss 0.028439 | Grad 0.0335 \n","[2023-12-09 07:33:46,853::train::INFO] [Train] Iter 3367 | Loss 0.027787 | Grad 0.0351 \n","[2023-12-09 07:33:46,941::train::INFO] [Train] Iter 3368 | Loss 0.024656 | Grad 0.0450 \n","[2023-12-09 07:33:47,027::train::INFO] [Train] Iter 3369 | Loss 0.028280 | Grad 0.0376 \n","[2023-12-09 07:33:47,113::train::INFO] [Train] Iter 3370 | Loss 0.029252 | Grad 0.0326 \n","[2023-12-09 07:33:47,199::train::INFO] [Train] Iter 3371 | Loss 0.027328 | Grad 0.0330 \n","[2023-12-09 07:33:47,292::train::INFO] [Train] Iter 3372 | Loss 0.027826 | Grad 0.0368 \n","[2023-12-09 07:33:47,377::train::INFO] [Train] Iter 3373 | Loss 0.028592 | Grad 0.0450 \n","[2023-12-09 07:33:47,462::train::INFO] [Train] Iter 3374 | Loss 0.028428 | Grad 0.0277 \n","[2023-12-09 07:33:47,550::train::INFO] [Train] Iter 3375 | Loss 0.027021 | Grad 0.0454 \n","[2023-12-09 07:33:47,634::train::INFO] [Train] Iter 3376 | Loss 0.027659 | Grad 0.0309 \n","[2023-12-09 07:33:47,731::train::INFO] [Train] Iter 3377 | Loss 0.030076 | Grad 0.0598 \n","[2023-12-09 07:33:47,824::train::INFO] [Train] Iter 3378 | Loss 0.027964 | Grad 0.0420 \n","[2023-12-09 07:33:47,916::train::INFO] [Train] Iter 3379 | Loss 0.028023 | Grad 0.0423 \n","[2023-12-09 07:33:48,008::train::INFO] [Train] Iter 3380 | Loss 0.028730 | Grad 0.0353 \n","[2023-12-09 07:33:48,106::train::INFO] [Train] Iter 3381 | Loss 0.025769 | Grad 0.0311 \n","[2023-12-09 07:33:48,199::train::INFO] [Train] Iter 3382 | Loss 0.030032 | Grad 0.0334 \n","[2023-12-09 07:33:48,299::train::INFO] [Train] Iter 3383 | Loss 0.028359 | Grad 0.0362 \n","[2023-12-09 07:33:48,394::train::INFO] [Train] Iter 3384 | Loss 0.025997 | Grad 0.0384 \n","[2023-12-09 07:33:48,491::train::INFO] [Train] Iter 3385 | Loss 0.028341 | Grad 0.0407 \n","[2023-12-09 07:33:48,583::train::INFO] [Train] Iter 3386 | Loss 0.030690 | Grad 0.0856 \n","[2023-12-09 07:33:48,675::train::INFO] [Train] Iter 3387 | Loss 0.027344 | Grad 0.0345 \n","[2023-12-09 07:33:48,769::train::INFO] [Train] Iter 3388 | Loss 0.028899 | Grad 0.0426 \n","[2023-12-09 07:33:48,862::train::INFO] [Train] Iter 3389 | Loss 0.028323 | Grad 0.0450 \n","[2023-12-09 07:33:48,955::train::INFO] [Train] Iter 3390 | Loss 0.028702 | Grad 0.0421 \n","[2023-12-09 07:33:49,051::train::INFO] [Train] Iter 3391 | Loss 0.025755 | Grad 0.0415 \n","[2023-12-09 07:33:49,144::train::INFO] [Train] Iter 3392 | Loss 0.028246 | Grad 0.0395 \n","[2023-12-09 07:33:49,240::train::INFO] [Train] Iter 3393 | Loss 0.028365 | Grad 0.0491 \n","[2023-12-09 07:33:49,335::train::INFO] [Train] Iter 3394 | Loss 0.029414 | Grad 0.0382 \n","[2023-12-09 07:33:49,428::train::INFO] [Train] Iter 3395 | Loss 0.025699 | Grad 0.0357 \n","[2023-12-09 07:33:49,520::train::INFO] [Train] Iter 3396 | Loss 0.029932 | Grad 0.0432 \n","[2023-12-09 07:33:49,614::train::INFO] [Train] Iter 3397 | Loss 0.030165 | Grad 0.0372 \n","[2023-12-09 07:33:49,705::train::INFO] [Train] Iter 3398 | Loss 0.025654 | Grad 0.0387 \n","[2023-12-09 07:33:49,799::train::INFO] [Train] Iter 3399 | Loss 0.026152 | Grad 0.0418 \n","[2023-12-09 07:33:49,850::train::INFO] [Train] Iter 3400 | Loss 0.026296 | Grad 0.0825 \n","[2023-12-09 07:33:49,945::train::INFO] [Train] Iter 3401 | Loss 0.026139 | Grad 0.0347 \n","[2023-12-09 07:33:50,037::train::INFO] [Train] Iter 3402 | Loss 0.029380 | Grad 0.0409 \n","[2023-12-09 07:33:50,128::train::INFO] [Train] Iter 3403 | Loss 0.027618 | Grad 0.0456 \n","[2023-12-09 07:33:50,219::train::INFO] [Train] Iter 3404 | Loss 0.028954 | Grad 0.0388 \n","[2023-12-09 07:33:50,313::train::INFO] [Train] Iter 3405 | Loss 0.027824 | Grad 0.0374 \n","[2023-12-09 07:33:50,406::train::INFO] [Train] Iter 3406 | Loss 0.030056 | Grad 0.0413 \n","[2023-12-09 07:33:50,504::train::INFO] [Train] Iter 3407 | Loss 0.027988 | Grad 0.0446 \n","[2023-12-09 07:33:50,597::train::INFO] [Train] Iter 3408 | Loss 0.029389 | Grad 0.0305 \n","[2023-12-09 07:33:50,694::train::INFO] [Train] Iter 3409 | Loss 0.028105 | Grad 0.0456 \n","[2023-12-09 07:33:50,790::train::INFO] [Train] Iter 3410 | Loss 0.028925 | Grad 0.0400 \n","[2023-12-09 07:33:50,884::train::INFO] [Train] Iter 3411 | Loss 0.027047 | Grad 0.0449 \n","[2023-12-09 07:33:50,989::train::INFO] [Train] Iter 3412 | Loss 0.029877 | Grad 0.0442 \n","[2023-12-09 07:33:51,084::train::INFO] [Train] Iter 3413 | Loss 0.027758 | Grad 0.0456 \n","[2023-12-09 07:33:51,177::train::INFO] [Train] Iter 3414 | Loss 0.028169 | Grad 0.0385 \n","[2023-12-09 07:33:51,272::train::INFO] [Train] Iter 3415 | Loss 0.028351 | Grad 0.0331 \n","[2023-12-09 07:33:51,371::train::INFO] [Train] Iter 3416 | Loss 0.027839 | Grad 0.0317 \n","[2023-12-09 07:33:51,465::train::INFO] [Train] Iter 3417 | Loss 0.028312 | Grad 0.0549 \n","[2023-12-09 07:33:51,564::train::INFO] [Train] Iter 3418 | Loss 0.027107 | Grad 0.0373 \n","[2023-12-09 07:33:51,656::train::INFO] [Train] Iter 3419 | Loss 0.029709 | Grad 0.0291 \n","[2023-12-09 07:33:51,749::train::INFO] [Train] Iter 3420 | Loss 0.027148 | Grad 0.0444 \n","[2023-12-09 07:33:51,841::train::INFO] [Train] Iter 3421 | Loss 0.026303 | Grad 0.0446 \n","[2023-12-09 07:33:51,934::train::INFO] [Train] Iter 3422 | Loss 0.029221 | Grad 0.0404 \n","[2023-12-09 07:33:52,025::train::INFO] [Train] Iter 3423 | Loss 0.027229 | Grad 0.0564 \n","[2023-12-09 07:33:52,121::train::INFO] [Train] Iter 3424 | Loss 0.027585 | Grad 0.0508 \n","[2023-12-09 07:33:52,215::train::INFO] [Train] Iter 3425 | Loss 0.027295 | Grad 0.0305 \n","[2023-12-09 07:33:52,309::train::INFO] [Train] Iter 3426 | Loss 0.028051 | Grad 0.0465 \n","[2023-12-09 07:33:52,409::train::INFO] [Train] Iter 3427 | Loss 0.029754 | Grad 0.0456 \n","[2023-12-09 07:33:52,509::train::INFO] [Train] Iter 3428 | Loss 0.028723 | Grad 0.0406 \n","[2023-12-09 07:33:52,602::train::INFO] [Train] Iter 3429 | Loss 0.026844 | Grad 0.0541 \n","[2023-12-09 07:33:52,700::train::INFO] [Train] Iter 3430 | Loss 0.028422 | Grad 0.0430 \n","[2023-12-09 07:33:52,794::train::INFO] [Train] Iter 3431 | Loss 0.030032 | Grad 0.0464 \n","[2023-12-09 07:33:52,885::train::INFO] [Train] Iter 3432 | Loss 0.026676 | Grad 0.0286 \n","[2023-12-09 07:33:52,982::train::INFO] [Train] Iter 3433 | Loss 0.029549 | Grad 0.0554 \n","[2023-12-09 07:33:53,075::train::INFO] [Train] Iter 3434 | Loss 0.028691 | Grad 0.0518 \n","[2023-12-09 07:33:53,168::train::INFO] [Train] Iter 3435 | Loss 0.026113 | Grad 0.0314 \n","[2023-12-09 07:33:53,264::train::INFO] [Train] Iter 3436 | Loss 0.030062 | Grad 0.0334 \n","[2023-12-09 07:33:53,358::train::INFO] [Train] Iter 3437 | Loss 0.028317 | Grad 0.0423 \n","[2023-12-09 07:33:53,451::train::INFO] [Train] Iter 3438 | Loss 0.029897 | Grad 0.0351 \n","[2023-12-09 07:33:53,545::train::INFO] [Train] Iter 3439 | Loss 0.026601 | Grad 0.0264 \n","[2023-12-09 07:33:53,635::train::INFO] [Train] Iter 3440 | Loss 0.027984 | Grad 0.0390 \n","[2023-12-09 07:33:53,726::train::INFO] [Train] Iter 3441 | Loss 0.028946 | Grad 0.0414 \n","[2023-12-09 07:33:53,826::train::INFO] [Train] Iter 3442 | Loss 0.028232 | Grad 0.0302 \n","[2023-12-09 07:33:53,918::train::INFO] [Train] Iter 3443 | Loss 0.027880 | Grad 0.0385 \n","[2023-12-09 07:33:54,011::train::INFO] [Train] Iter 3444 | Loss 0.027240 | Grad 0.0382 \n","[2023-12-09 07:33:54,103::train::INFO] [Train] Iter 3445 | Loss 0.028240 | Grad 0.0317 \n","[2023-12-09 07:33:54,186::train::INFO] [Train] Iter 3446 | Loss 0.028436 | Grad 0.0408 \n","[2023-12-09 07:33:54,272::train::INFO] [Train] Iter 3447 | Loss 0.026174 | Grad 0.0350 \n","[2023-12-09 07:33:54,357::train::INFO] [Train] Iter 3448 | Loss 0.026891 | Grad 0.0459 \n","[2023-12-09 07:33:54,443::train::INFO] [Train] Iter 3449 | Loss 0.028840 | Grad 0.0347 \n","[2023-12-09 07:33:54,528::train::INFO] [Train] Iter 3450 | Loss 0.026409 | Grad 0.0360 \n","[2023-12-09 07:33:54,617::train::INFO] [Train] Iter 3451 | Loss 0.030258 | Grad 0.0388 \n","[2023-12-09 07:33:54,703::train::INFO] [Train] Iter 3452 | Loss 0.027391 | Grad 0.0317 \n","[2023-12-09 07:33:54,788::train::INFO] [Train] Iter 3453 | Loss 0.028646 | Grad 0.0380 \n","[2023-12-09 07:33:54,872::train::INFO] [Train] Iter 3454 | Loss 0.027093 | Grad 0.0312 \n","[2023-12-09 07:33:54,959::train::INFO] [Train] Iter 3455 | Loss 0.028431 | Grad 0.0341 \n","[2023-12-09 07:33:55,046::train::INFO] [Train] Iter 3456 | Loss 0.030722 | Grad 0.0539 \n","[2023-12-09 07:33:55,132::train::INFO] [Train] Iter 3457 | Loss 0.027828 | Grad 0.0375 \n","[2023-12-09 07:33:55,217::train::INFO] [Train] Iter 3458 | Loss 0.027775 | Grad 0.0420 \n","[2023-12-09 07:33:55,303::train::INFO] [Train] Iter 3459 | Loss 0.026805 | Grad 0.0393 \n","[2023-12-09 07:33:55,388::train::INFO] [Train] Iter 3460 | Loss 0.025929 | Grad 0.0374 \n","[2023-12-09 07:33:55,472::train::INFO] [Train] Iter 3461 | Loss 0.029329 | Grad 0.0494 \n","[2023-12-09 07:33:55,562::train::INFO] [Train] Iter 3462 | Loss 0.030406 | Grad 0.0380 \n","[2023-12-09 07:33:55,647::train::INFO] [Train] Iter 3463 | Loss 0.027675 | Grad 0.0385 \n","[2023-12-09 07:33:55,731::train::INFO] [Train] Iter 3464 | Loss 0.029710 | Grad 0.0388 \n","[2023-12-09 07:33:55,816::train::INFO] [Train] Iter 3465 | Loss 0.029631 | Grad 0.0362 \n","[2023-12-09 07:33:55,904::train::INFO] [Train] Iter 3466 | Loss 0.027476 | Grad 0.0489 \n","[2023-12-09 07:33:55,989::train::INFO] [Train] Iter 3467 | Loss 0.028157 | Grad 0.0281 \n","[2023-12-09 07:33:56,074::train::INFO] [Train] Iter 3468 | Loss 0.026004 | Grad 0.0310 \n","[2023-12-09 07:33:56,159::train::INFO] [Train] Iter 3469 | Loss 0.028220 | Grad 0.0365 \n","[2023-12-09 07:33:56,245::train::INFO] [Train] Iter 3470 | Loss 0.027836 | Grad 0.0345 \n","[2023-12-09 07:33:56,329::train::INFO] [Train] Iter 3471 | Loss 0.028024 | Grad 0.0283 \n","[2023-12-09 07:33:56,414::train::INFO] [Train] Iter 3472 | Loss 0.027519 | Grad 0.0457 \n","[2023-12-09 07:33:56,501::train::INFO] [Train] Iter 3473 | Loss 0.027931 | Grad 0.0452 \n","[2023-12-09 07:33:56,585::train::INFO] [Train] Iter 3474 | Loss 0.026962 | Grad 0.0323 \n","[2023-12-09 07:33:56,671::train::INFO] [Train] Iter 3475 | Loss 0.028070 | Grad 0.0390 \n","[2023-12-09 07:33:56,758::train::INFO] [Train] Iter 3476 | Loss 0.027139 | Grad 0.0426 \n","[2023-12-09 07:33:56,844::train::INFO] [Train] Iter 3477 | Loss 0.027072 | Grad 0.0306 \n","[2023-12-09 07:33:56,929::train::INFO] [Train] Iter 3478 | Loss 0.026993 | Grad 0.0399 \n","[2023-12-09 07:33:57,014::train::INFO] [Train] Iter 3479 | Loss 0.028472 | Grad 0.0433 \n","[2023-12-09 07:33:57,099::train::INFO] [Train] Iter 3480 | Loss 0.026831 | Grad 0.0400 \n","[2023-12-09 07:33:57,186::train::INFO] [Train] Iter 3481 | Loss 0.027919 | Grad 0.0452 \n","[2023-12-09 07:33:57,273::train::INFO] [Train] Iter 3482 | Loss 0.025588 | Grad 0.0342 \n","[2023-12-09 07:33:57,357::train::INFO] [Train] Iter 3483 | Loss 0.026637 | Grad 0.0387 \n","[2023-12-09 07:33:57,441::train::INFO] [Train] Iter 3484 | Loss 0.028807 | Grad 0.0335 \n","[2023-12-09 07:33:57,526::train::INFO] [Train] Iter 3485 | Loss 0.028200 | Grad 0.0418 \n","[2023-12-09 07:33:57,611::train::INFO] [Train] Iter 3486 | Loss 0.028642 | Grad 0.0464 \n","[2023-12-09 07:33:57,695::train::INFO] [Train] Iter 3487 | Loss 0.027721 | Grad 0.0434 \n","[2023-12-09 07:33:57,780::train::INFO] [Train] Iter 3488 | Loss 0.029595 | Grad 0.0335 \n","[2023-12-09 07:33:57,864::train::INFO] [Train] Iter 3489 | Loss 0.027667 | Grad 0.0356 \n","[2023-12-09 07:33:57,949::train::INFO] [Train] Iter 3490 | Loss 0.029198 | Grad 0.0482 \n","[2023-12-09 07:33:58,035::train::INFO] [Train] Iter 3491 | Loss 0.026676 | Grad 0.0342 \n","[2023-12-09 07:33:58,127::train::INFO] [Train] Iter 3492 | Loss 0.027792 | Grad 0.0282 \n","[2023-12-09 07:33:58,212::train::INFO] [Train] Iter 3493 | Loss 0.027770 | Grad 0.0400 \n","[2023-12-09 07:33:58,296::train::INFO] [Train] Iter 3494 | Loss 0.027818 | Grad 0.0570 \n","[2023-12-09 07:33:58,384::train::INFO] [Train] Iter 3495 | Loss 0.030201 | Grad 0.0300 \n","[2023-12-09 07:33:58,468::train::INFO] [Train] Iter 3496 | Loss 0.024807 | Grad 0.0387 \n","[2023-12-09 07:33:58,552::train::INFO] [Train] Iter 3497 | Loss 0.028169 | Grad 0.0377 \n","[2023-12-09 07:33:58,638::train::INFO] [Train] Iter 3498 | Loss 0.027117 | Grad 0.0375 \n","[2023-12-09 07:33:58,729::train::INFO] [Train] Iter 3499 | Loss 0.026591 | Grad 0.0392 \n","[2023-12-09 07:33:58,814::train::INFO] [Train] Iter 3500 | Loss 0.029659 | Grad 0.0376 \n","Validate: 100% 241/241 [00:04<00:00, 59.42it/s]\n","val loss list [tensor(0.0303, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0235, device='cuda:0'), tensor(0.0226, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0239, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0267, device='cuda:0'), tensor(0.0247, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0242, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0243, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0242, device='cuda:0'), tensor(0.0319, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0240, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0326, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0235, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0336, device='cuda:0'), tensor(0.0329, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0236, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0298, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0311, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0340, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0319, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0249, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0241, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0246, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0237, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0244, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0230, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0315, device='cuda:0'), tensor(0.0256, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0251, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0206, device='cuda:0'), tensor(0.0246, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0219, device='cuda:0'), tensor(0.0331, device='cuda:0'), tensor(0.0249, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0247, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0247, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0249, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0331, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0256, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0329, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0239, device='cuda:0'), tensor(0.0298, device='cuda:0'), tensor(0.0267, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0336, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0330, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0256, device='cuda:0'), tensor(0.0256, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0267, device='cuda:0'), tensor(0.0326, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0244, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0326, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0240, device='cuda:0'), tensor(0.0240, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0240, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0315, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0246, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0194, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0205, device='cuda:0'), tensor(0.0242, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0325, device='cuda:0')]\n","[2023-12-09 07:34:03,140::train::INFO] [Train] Iter 3501 | Loss 0.027677 | Grad 0.0309 \n","[2023-12-09 07:34:03,226::train::INFO] [Train] Iter 3502 | Loss 0.027455 | Grad 0.0371 \n","[2023-12-09 07:34:03,311::train::INFO] [Train] Iter 3503 | Loss 0.027345 | Grad 0.0394 \n","[2023-12-09 07:34:03,395::train::INFO] [Train] Iter 3504 | Loss 0.027508 | Grad 0.0298 \n","[2023-12-09 07:34:03,484::train::INFO] [Train] Iter 3505 | Loss 0.028257 | Grad 0.0345 \n","[2023-12-09 07:34:03,569::train::INFO] [Train] Iter 3506 | Loss 0.029207 | Grad 0.0433 \n","[2023-12-09 07:34:03,653::train::INFO] [Train] Iter 3507 | Loss 0.025137 | Grad 0.0385 \n","[2023-12-09 07:34:03,738::train::INFO] [Train] Iter 3508 | Loss 0.028786 | Grad 0.0269 \n","[2023-12-09 07:34:03,825::train::INFO] [Train] Iter 3509 | Loss 0.031415 | Grad 0.0543 \n","[2023-12-09 07:34:03,909::train::INFO] [Train] Iter 3510 | Loss 0.027308 | Grad 0.0363 \n","[2023-12-09 07:34:03,993::train::INFO] [Train] Iter 3511 | Loss 0.029321 | Grad 0.0301 \n","[2023-12-09 07:34:04,082::train::INFO] [Train] Iter 3512 | Loss 0.027459 | Grad 0.0421 \n","[2023-12-09 07:34:04,175::train::INFO] [Train] Iter 3513 | Loss 0.027346 | Grad 0.0350 \n","[2023-12-09 07:34:04,270::train::INFO] [Train] Iter 3514 | Loss 0.028025 | Grad 0.0410 \n","[2023-12-09 07:34:04,373::train::INFO] [Train] Iter 3515 | Loss 0.027468 | Grad 0.0344 \n","[2023-12-09 07:34:04,466::train::INFO] [Train] Iter 3516 | Loss 0.028232 | Grad 0.0497 \n","[2023-12-09 07:34:04,559::train::INFO] [Train] Iter 3517 | Loss 0.028328 | Grad 0.0314 \n","[2023-12-09 07:34:04,655::train::INFO] [Train] Iter 3518 | Loss 0.027502 | Grad 0.0461 \n","[2023-12-09 07:34:04,747::train::INFO] [Train] Iter 3519 | Loss 0.024296 | Grad 0.0293 \n","[2023-12-09 07:34:04,846::train::INFO] [Train] Iter 3520 | Loss 0.028936 | Grad 0.0363 \n","[2023-12-09 07:34:04,938::train::INFO] [Train] Iter 3521 | Loss 0.026992 | Grad 0.0340 \n","[2023-12-09 07:34:05,031::train::INFO] [Train] Iter 3522 | Loss 0.025085 | Grad 0.0319 \n","[2023-12-09 07:34:05,123::train::INFO] [Train] Iter 3523 | Loss 0.026236 | Grad 0.0325 \n","[2023-12-09 07:34:05,213::train::INFO] [Train] Iter 3524 | Loss 0.028221 | Grad 0.0434 \n","[2023-12-09 07:34:05,306::train::INFO] [Train] Iter 3525 | Loss 0.027678 | Grad 0.0440 \n","[2023-12-09 07:34:05,401::train::INFO] [Train] Iter 3526 | Loss 0.028044 | Grad 0.0395 \n","[2023-12-09 07:34:05,497::train::INFO] [Train] Iter 3527 | Loss 0.026239 | Grad 0.0278 \n","[2023-12-09 07:34:05,598::train::INFO] [Train] Iter 3528 | Loss 0.027404 | Grad 0.0326 \n","[2023-12-09 07:34:05,689::train::INFO] [Train] Iter 3529 | Loss 0.028449 | Grad 0.0353 \n","[2023-12-09 07:34:05,782::train::INFO] [Train] Iter 3530 | Loss 0.026003 | Grad 0.0478 \n","[2023-12-09 07:34:05,881::train::INFO] [Train] Iter 3531 | Loss 0.028598 | Grad 0.0283 \n","[2023-12-09 07:34:05,974::train::INFO] [Train] Iter 3532 | Loss 0.028503 | Grad 0.0389 \n","[2023-12-09 07:34:06,063::train::INFO] [Train] Iter 3533 | Loss 0.027527 | Grad 0.0283 \n","[2023-12-09 07:34:06,156::train::INFO] [Train] Iter 3534 | Loss 0.026292 | Grad 0.0481 \n","[2023-12-09 07:34:06,247::train::INFO] [Train] Iter 3535 | Loss 0.026823 | Grad 0.0277 \n","[2023-12-09 07:34:06,339::train::INFO] [Train] Iter 3536 | Loss 0.025996 | Grad 0.0543 \n","[2023-12-09 07:34:06,431::train::INFO] [Train] Iter 3537 | Loss 0.026839 | Grad 0.0469 \n","[2023-12-09 07:34:06,524::train::INFO] [Train] Iter 3538 | Loss 0.027114 | Grad 0.0573 \n","[2023-12-09 07:34:06,612::train::INFO] [Train] Iter 3539 | Loss 0.027909 | Grad 0.0550 \n","[2023-12-09 07:34:06,704::train::INFO] [Train] Iter 3540 | Loss 0.028012 | Grad 0.0581 \n","[2023-12-09 07:34:06,797::train::INFO] [Train] Iter 3541 | Loss 0.028766 | Grad 0.0588 \n","[2023-12-09 07:34:06,889::train::INFO] [Train] Iter 3542 | Loss 0.027574 | Grad 0.0305 \n","[2023-12-09 07:34:06,986::train::INFO] [Train] Iter 3543 | Loss 0.029827 | Grad 0.0357 \n","[2023-12-09 07:34:07,083::train::INFO] [Train] Iter 3544 | Loss 0.027983 | Grad 0.0467 \n","[2023-12-09 07:34:07,176::train::INFO] [Train] Iter 3545 | Loss 0.030672 | Grad 0.0420 \n","[2023-12-09 07:34:07,274::train::INFO] [Train] Iter 3546 | Loss 0.028884 | Grad 0.0386 \n","[2023-12-09 07:34:07,371::train::INFO] [Train] Iter 3547 | Loss 0.027472 | Grad 0.0400 \n","[2023-12-09 07:34:07,463::train::INFO] [Train] Iter 3548 | Loss 0.028399 | Grad 0.0386 \n","[2023-12-09 07:34:07,556::train::INFO] [Train] Iter 3549 | Loss 0.029108 | Grad 0.0342 \n","[2023-12-09 07:34:07,652::train::INFO] [Train] Iter 3550 | Loss 0.030239 | Grad 0.0407 \n","[2023-12-09 07:34:07,754::train::INFO] [Train] Iter 3551 | Loss 0.030229 | Grad 0.0399 \n","[2023-12-09 07:34:07,846::train::INFO] [Train] Iter 3552 | Loss 0.029397 | Grad 0.0450 \n","[2023-12-09 07:34:07,936::train::INFO] [Train] Iter 3553 | Loss 0.027425 | Grad 0.0291 \n","[2023-12-09 07:34:08,029::train::INFO] [Train] Iter 3554 | Loss 0.027167 | Grad 0.0504 \n","[2023-12-09 07:34:08,121::train::INFO] [Train] Iter 3555 | Loss 0.028336 | Grad 0.0388 \n","[2023-12-09 07:34:08,213::train::INFO] [Train] Iter 3556 | Loss 0.029102 | Grad 0.0316 \n","[2023-12-09 07:34:08,305::train::INFO] [Train] Iter 3557 | Loss 0.025696 | Grad 0.0354 \n","[2023-12-09 07:34:08,399::train::INFO] [Train] Iter 3558 | Loss 0.027928 | Grad 0.0413 \n","[2023-12-09 07:34:08,492::train::INFO] [Train] Iter 3559 | Loss 0.025653 | Grad 0.0381 \n","[2023-12-09 07:34:08,589::train::INFO] [Train] Iter 3560 | Loss 0.026886 | Grad 0.0369 \n","[2023-12-09 07:34:08,681::train::INFO] [Train] Iter 3561 | Loss 0.027306 | Grad 0.0307 \n","[2023-12-09 07:34:08,773::train::INFO] [Train] Iter 3562 | Loss 0.028699 | Grad 0.0403 \n","[2023-12-09 07:34:08,868::train::INFO] [Train] Iter 3563 | Loss 0.029750 | Grad 0.0462 \n","[2023-12-09 07:34:08,961::train::INFO] [Train] Iter 3564 | Loss 0.029318 | Grad 0.0467 \n","[2023-12-09 07:34:09,057::train::INFO] [Train] Iter 3565 | Loss 0.026917 | Grad 0.0354 \n","[2023-12-09 07:34:09,149::train::INFO] [Train] Iter 3566 | Loss 0.028414 | Grad 0.0486 \n","[2023-12-09 07:34:09,241::train::INFO] [Train] Iter 3567 | Loss 0.027451 | Grad 0.0423 \n","[2023-12-09 07:34:09,333::train::INFO] [Train] Iter 3568 | Loss 0.029593 | Grad 0.0770 \n","[2023-12-09 07:34:09,423::train::INFO] [Train] Iter 3569 | Loss 0.025567 | Grad 0.0453 \n","[2023-12-09 07:34:09,517::train::INFO] [Train] Iter 3570 | Loss 0.025819 | Grad 0.0429 \n","[2023-12-09 07:34:09,609::train::INFO] [Train] Iter 3571 | Loss 0.027092 | Grad 0.0466 \n","[2023-12-09 07:34:09,702::train::INFO] [Train] Iter 3572 | Loss 0.030976 | Grad 0.0388 \n","[2023-12-09 07:34:09,799::train::INFO] [Train] Iter 3573 | Loss 0.030245 | Grad 0.0607 \n","[2023-12-09 07:34:09,892::train::INFO] [Train] Iter 3574 | Loss 0.027266 | Grad 0.0448 \n","[2023-12-09 07:34:09,984::train::INFO] [Train] Iter 3575 | Loss 0.028191 | Grad 0.0399 \n","[2023-12-09 07:34:10,079::train::INFO] [Train] Iter 3576 | Loss 0.026540 | Grad 0.0431 \n","[2023-12-09 07:34:10,175::train::INFO] [Train] Iter 3577 | Loss 0.026684 | Grad 0.0298 \n","[2023-12-09 07:34:10,268::train::INFO] [Train] Iter 3578 | Loss 0.025684 | Grad 0.0405 \n","[2023-12-09 07:34:10,367::train::INFO] [Train] Iter 3579 | Loss 0.025981 | Grad 0.0391 \n","[2023-12-09 07:34:10,452::train::INFO] [Train] Iter 3580 | Loss 0.029130 | Grad 0.0447 \n","[2023-12-09 07:34:10,537::train::INFO] [Train] Iter 3581 | Loss 0.030182 | Grad 0.0502 \n","[2023-12-09 07:34:10,621::train::INFO] [Train] Iter 3582 | Loss 0.026584 | Grad 0.0333 \n","[2023-12-09 07:34:10,709::train::INFO] [Train] Iter 3583 | Loss 0.025741 | Grad 0.0360 \n","[2023-12-09 07:34:10,794::train::INFO] [Train] Iter 3584 | Loss 0.028927 | Grad 0.0527 \n","[2023-12-09 07:34:10,878::train::INFO] [Train] Iter 3585 | Loss 0.026359 | Grad 0.0323 \n","[2023-12-09 07:34:10,964::train::INFO] [Train] Iter 3586 | Loss 0.028701 | Grad 0.0292 \n","[2023-12-09 07:34:11,048::train::INFO] [Train] Iter 3587 | Loss 0.026463 | Grad 0.0296 \n","[2023-12-09 07:34:11,133::train::INFO] [Train] Iter 3588 | Loss 0.028998 | Grad 0.0303 \n","[2023-12-09 07:34:11,216::train::INFO] [Train] Iter 3589 | Loss 0.028013 | Grad 0.0423 \n","[2023-12-09 07:34:11,306::train::INFO] [Train] Iter 3590 | Loss 0.028966 | Grad 0.0322 \n","[2023-12-09 07:34:11,391::train::INFO] [Train] Iter 3591 | Loss 0.028873 | Grad 0.0388 \n","[2023-12-09 07:34:11,476::train::INFO] [Train] Iter 3592 | Loss 0.027015 | Grad 0.0541 \n","[2023-12-09 07:34:11,561::train::INFO] [Train] Iter 3593 | Loss 0.027180 | Grad 0.0412 \n","[2023-12-09 07:34:11,646::train::INFO] [Train] Iter 3594 | Loss 0.027514 | Grad 0.0343 \n","[2023-12-09 07:34:11,731::train::INFO] [Train] Iter 3595 | Loss 0.029198 | Grad 0.0380 \n","[2023-12-09 07:34:11,819::train::INFO] [Train] Iter 3596 | Loss 0.029375 | Grad 0.0308 \n","[2023-12-09 07:34:11,910::train::INFO] [Train] Iter 3597 | Loss 0.027346 | Grad 0.0539 \n","[2023-12-09 07:34:11,994::train::INFO] [Train] Iter 3598 | Loss 0.026751 | Grad 0.0421 \n","[2023-12-09 07:34:12,080::train::INFO] [Train] Iter 3599 | Loss 0.028920 | Grad 0.0318 \n","[2023-12-09 07:34:12,168::train::INFO] [Train] Iter 3600 | Loss 0.025640 | Grad 0.0367 \n","[2023-12-09 07:34:12,253::train::INFO] [Train] Iter 3601 | Loss 0.026370 | Grad 0.0348 \n","[2023-12-09 07:34:12,347::train::INFO] [Train] Iter 3602 | Loss 0.028008 | Grad 0.0349 \n","[2023-12-09 07:34:12,431::train::INFO] [Train] Iter 3603 | Loss 0.029042 | Grad 0.0363 \n","[2023-12-09 07:34:12,519::train::INFO] [Train] Iter 3604 | Loss 0.027575 | Grad 0.0376 \n","[2023-12-09 07:34:12,603::train::INFO] [Train] Iter 3605 | Loss 0.026710 | Grad 0.0436 \n","[2023-12-09 07:34:12,688::train::INFO] [Train] Iter 3606 | Loss 0.027249 | Grad 0.0293 \n","[2023-12-09 07:34:12,772::train::INFO] [Train] Iter 3607 | Loss 0.027426 | Grad 0.0351 \n","[2023-12-09 07:34:12,856::train::INFO] [Train] Iter 3608 | Loss 0.027308 | Grad 0.0427 \n","[2023-12-09 07:34:12,940::train::INFO] [Train] Iter 3609 | Loss 0.026296 | Grad 0.0339 \n","[2023-12-09 07:34:13,026::train::INFO] [Train] Iter 3610 | Loss 0.029553 | Grad 0.0407 \n","[2023-12-09 07:34:13,119::train::INFO] [Train] Iter 3611 | Loss 0.029018 | Grad 0.0364 \n","[2023-12-09 07:34:13,206::train::INFO] [Train] Iter 3612 | Loss 0.027092 | Grad 0.0395 \n","[2023-12-09 07:34:13,290::train::INFO] [Train] Iter 3613 | Loss 0.027926 | Grad 0.0345 \n","[2023-12-09 07:34:13,375::train::INFO] [Train] Iter 3614 | Loss 0.028704 | Grad 0.0338 \n","[2023-12-09 07:34:13,460::train::INFO] [Train] Iter 3615 | Loss 0.026460 | Grad 0.0358 \n","[2023-12-09 07:34:13,544::train::INFO] [Train] Iter 3616 | Loss 0.029504 | Grad 0.0325 \n","[2023-12-09 07:34:13,629::train::INFO] [Train] Iter 3617 | Loss 0.026814 | Grad 0.0329 \n","[2023-12-09 07:34:13,721::train::INFO] [Train] Iter 3618 | Loss 0.030475 | Grad 0.0293 \n","[2023-12-09 07:34:13,805::train::INFO] [Train] Iter 3619 | Loss 0.027014 | Grad 0.0279 \n","[2023-12-09 07:34:13,889::train::INFO] [Train] Iter 3620 | Loss 0.028456 | Grad 0.0299 \n","[2023-12-09 07:34:13,978::train::INFO] [Train] Iter 3621 | Loss 0.027272 | Grad 0.0379 \n","[2023-12-09 07:34:14,063::train::INFO] [Train] Iter 3622 | Loss 0.026787 | Grad 0.0283 \n","[2023-12-09 07:34:14,147::train::INFO] [Train] Iter 3623 | Loss 0.027405 | Grad 0.0431 \n","[2023-12-09 07:34:14,234::train::INFO] [Train] Iter 3624 | Loss 0.028383 | Grad 0.0630 \n","[2023-12-09 07:34:14,326::train::INFO] [Train] Iter 3625 | Loss 0.027534 | Grad 0.0484 \n","[2023-12-09 07:34:14,412::train::INFO] [Train] Iter 3626 | Loss 0.028484 | Grad 0.0328 \n","[2023-12-09 07:34:14,495::train::INFO] [Train] Iter 3627 | Loss 0.028413 | Grad 0.0330 \n","[2023-12-09 07:34:14,580::train::INFO] [Train] Iter 3628 | Loss 0.025666 | Grad 0.0260 \n","[2023-12-09 07:34:14,667::train::INFO] [Train] Iter 3629 | Loss 0.028941 | Grad 0.0459 \n","[2023-12-09 07:34:14,751::train::INFO] [Train] Iter 3630 | Loss 0.025773 | Grad 0.0302 \n","[2023-12-09 07:34:14,836::train::INFO] [Train] Iter 3631 | Loss 0.028640 | Grad 0.0400 \n","[2023-12-09 07:34:14,929::train::INFO] [Train] Iter 3632 | Loss 0.027580 | Grad 0.0345 \n","[2023-12-09 07:34:15,013::train::INFO] [Train] Iter 3633 | Loss 0.029628 | Grad 0.0290 \n","[2023-12-09 07:34:15,098::train::INFO] [Train] Iter 3634 | Loss 0.027535 | Grad 0.0359 \n","[2023-12-09 07:34:15,183::train::INFO] [Train] Iter 3635 | Loss 0.027817 | Grad 0.0368 \n","[2023-12-09 07:34:15,268::train::INFO] [Train] Iter 3636 | Loss 0.027822 | Grad 0.0385 \n","[2023-12-09 07:34:15,352::train::INFO] [Train] Iter 3637 | Loss 0.027652 | Grad 0.0431 \n","[2023-12-09 07:34:15,437::train::INFO] [Train] Iter 3638 | Loss 0.026299 | Grad 0.0329 \n","[2023-12-09 07:34:15,529::train::INFO] [Train] Iter 3639 | Loss 0.027205 | Grad 0.0324 \n","[2023-12-09 07:34:15,613::train::INFO] [Train] Iter 3640 | Loss 0.027583 | Grad 0.0303 \n","[2023-12-09 07:34:15,697::train::INFO] [Train] Iter 3641 | Loss 0.028164 | Grad 0.0438 \n","[2023-12-09 07:34:15,781::train::INFO] [Train] Iter 3642 | Loss 0.026803 | Grad 0.0319 \n","[2023-12-09 07:34:15,865::train::INFO] [Train] Iter 3643 | Loss 0.027840 | Grad 0.0364 \n","[2023-12-09 07:34:15,951::train::INFO] [Train] Iter 3644 | Loss 0.029518 | Grad 0.0373 \n","[2023-12-09 07:34:16,036::train::INFO] [Train] Iter 3645 | Loss 0.029001 | Grad 0.0395 \n","[2023-12-09 07:34:16,122::train::INFO] [Train] Iter 3646 | Loss 0.026787 | Grad 0.0377 \n","[2023-12-09 07:34:16,206::train::INFO] [Train] Iter 3647 | Loss 0.025108 | Grad 0.0367 \n","[2023-12-09 07:34:16,291::train::INFO] [Train] Iter 3648 | Loss 0.027777 | Grad 0.0300 \n","[2023-12-09 07:34:16,378::train::INFO] [Train] Iter 3649 | Loss 0.025220 | Grad 0.0272 \n","[2023-12-09 07:34:16,464::train::INFO] [Train] Iter 3650 | Loss 0.025079 | Grad 0.0380 \n","[2023-12-09 07:34:16,548::train::INFO] [Train] Iter 3651 | Loss 0.027171 | Grad 0.0382 \n","[2023-12-09 07:34:16,634::train::INFO] [Train] Iter 3652 | Loss 0.026895 | Grad 0.0328 \n","[2023-12-09 07:34:16,717::train::INFO] [Train] Iter 3653 | Loss 0.028950 | Grad 0.0348 \n","[2023-12-09 07:34:16,800::train::INFO] [Train] Iter 3654 | Loss 0.026789 | Grad 0.0371 \n","[2023-12-09 07:34:16,884::train::INFO] [Train] Iter 3655 | Loss 0.026605 | Grad 0.0398 \n","[2023-12-09 07:34:16,974::train::INFO] [Train] Iter 3656 | Loss 0.026166 | Grad 0.0411 \n","[2023-12-09 07:34:17,057::train::INFO] [Train] Iter 3657 | Loss 0.028487 | Grad 0.0365 \n","[2023-12-09 07:34:17,143::train::INFO] [Train] Iter 3658 | Loss 0.027627 | Grad 0.0333 \n","[2023-12-09 07:34:17,227::train::INFO] [Train] Iter 3659 | Loss 0.029588 | Grad 0.0342 \n","[2023-12-09 07:34:17,313::train::INFO] [Train] Iter 3660 | Loss 0.029274 | Grad 0.0393 \n","[2023-12-09 07:34:17,398::train::INFO] [Train] Iter 3661 | Loss 0.027870 | Grad 0.0305 \n","[2023-12-09 07:34:17,482::train::INFO] [Train] Iter 3662 | Loss 0.029250 | Grad 0.0339 \n","[2023-12-09 07:34:17,566::train::INFO] [Train] Iter 3663 | Loss 0.026086 | Grad 0.0366 \n","[2023-12-09 07:34:17,649::train::INFO] [Train] Iter 3664 | Loss 0.027255 | Grad 0.0368 \n","[2023-12-09 07:34:17,733::train::INFO] [Train] Iter 3665 | Loss 0.027757 | Grad 0.0327 \n","[2023-12-09 07:34:17,815::train::INFO] [Train] Iter 3666 | Loss 0.029665 | Grad 0.0295 \n","[2023-12-09 07:34:17,899::train::INFO] [Train] Iter 3667 | Loss 0.028130 | Grad 0.0359 \n","[2023-12-09 07:34:17,983::train::INFO] [Train] Iter 3668 | Loss 0.027963 | Grad 0.0297 \n","[2023-12-09 07:34:18,070::train::INFO] [Train] Iter 3669 | Loss 0.026443 | Grad 0.0327 \n","[2023-12-09 07:34:18,154::train::INFO] [Train] Iter 3670 | Loss 0.029552 | Grad 0.0359 \n","[2023-12-09 07:34:18,239::train::INFO] [Train] Iter 3671 | Loss 0.028770 | Grad 0.0393 \n","[2023-12-09 07:34:18,327::train::INFO] [Train] Iter 3672 | Loss 0.025339 | Grad 0.0292 \n","[2023-12-09 07:34:18,411::train::INFO] [Train] Iter 3673 | Loss 0.025593 | Grad 0.0331 \n","[2023-12-09 07:34:18,495::train::INFO] [Train] Iter 3674 | Loss 0.027022 | Grad 0.0378 \n","[2023-12-09 07:34:18,578::train::INFO] [Train] Iter 3675 | Loss 0.025624 | Grad 0.0422 \n","[2023-12-09 07:34:18,666::train::INFO] [Train] Iter 3676 | Loss 0.026933 | Grad 0.0321 \n","[2023-12-09 07:34:18,750::train::INFO] [Train] Iter 3677 | Loss 0.027469 | Grad 0.0362 \n","[2023-12-09 07:34:18,837::train::INFO] [Train] Iter 3678 | Loss 0.026705 | Grad 0.0381 \n","[2023-12-09 07:34:18,921::train::INFO] [Train] Iter 3679 | Loss 0.028296 | Grad 0.0455 \n","[2023-12-09 07:34:19,006::train::INFO] [Train] Iter 3680 | Loss 0.026673 | Grad 0.0339 \n","[2023-12-09 07:34:19,092::train::INFO] [Train] Iter 3681 | Loss 0.028046 | Grad 0.0483 \n","[2023-12-09 07:34:19,176::train::INFO] [Train] Iter 3682 | Loss 0.026754 | Grad 0.0415 \n","[2023-12-09 07:34:19,266::train::INFO] [Train] Iter 3683 | Loss 0.026034 | Grad 0.0392 \n","[2023-12-09 07:34:19,353::train::INFO] [Train] Iter 3684 | Loss 0.028795 | Grad 0.0352 \n","[2023-12-09 07:34:19,438::train::INFO] [Train] Iter 3685 | Loss 0.026079 | Grad 0.0424 \n","[2023-12-09 07:34:19,522::train::INFO] [Train] Iter 3686 | Loss 0.026409 | Grad 0.0343 \n","[2023-12-09 07:34:19,608::train::INFO] [Train] Iter 3687 | Loss 0.025815 | Grad 0.0358 \n","[2023-12-09 07:34:19,693::train::INFO] [Train] Iter 3688 | Loss 0.028490 | Grad 0.0506 \n","[2023-12-09 07:34:19,777::train::INFO] [Train] Iter 3689 | Loss 0.026647 | Grad 0.0505 \n","[2023-12-09 07:34:19,867::train::INFO] [Train] Iter 3690 | Loss 0.027820 | Grad 0.0427 \n","[2023-12-09 07:34:19,951::train::INFO] [Train] Iter 3691 | Loss 0.025926 | Grad 0.0392 \n","[2023-12-09 07:34:20,036::train::INFO] [Train] Iter 3692 | Loss 0.027572 | Grad 0.0401 \n","[2023-12-09 07:34:20,120::train::INFO] [Train] Iter 3693 | Loss 0.027214 | Grad 0.0473 \n","[2023-12-09 07:34:20,204::train::INFO] [Train] Iter 3694 | Loss 0.029490 | Grad 0.0450 \n","[2023-12-09 07:34:20,288::train::INFO] [Train] Iter 3695 | Loss 0.027624 | Grad 0.0294 \n","[2023-12-09 07:34:20,376::train::INFO] [Train] Iter 3696 | Loss 0.031718 | Grad 0.0504 \n","[2023-12-09 07:34:20,478::train::INFO] [Train] Iter 3697 | Loss 0.028750 | Grad 0.0414 \n","[2023-12-09 07:34:20,572::train::INFO] [Train] Iter 3698 | Loss 0.024370 | Grad 0.0420 \n","[2023-12-09 07:34:20,665::train::INFO] [Train] Iter 3699 | Loss 0.030158 | Grad 0.0322 \n","[2023-12-09 07:34:20,760::train::INFO] [Train] Iter 3700 | Loss 0.027795 | Grad 0.0360 \n","[2023-12-09 07:34:20,853::train::INFO] [Train] Iter 3701 | Loss 0.025122 | Grad 0.0499 \n","[2023-12-09 07:34:20,948::train::INFO] [Train] Iter 3702 | Loss 0.028712 | Grad 0.0317 \n","[2023-12-09 07:34:21,043::train::INFO] [Train] Iter 3703 | Loss 0.026931 | Grad 0.0392 \n","[2023-12-09 07:34:21,135::train::INFO] [Train] Iter 3704 | Loss 0.027653 | Grad 0.0323 \n","[2023-12-09 07:34:21,228::train::INFO] [Train] Iter 3705 | Loss 0.028289 | Grad 0.0358 \n","[2023-12-09 07:34:21,320::train::INFO] [Train] Iter 3706 | Loss 0.028037 | Grad 0.0330 \n","[2023-12-09 07:34:21,424::train::INFO] [Train] Iter 3707 | Loss 0.027398 | Grad 0.0323 \n","[2023-12-09 07:34:21,515::train::INFO] [Train] Iter 3708 | Loss 0.024177 | Grad 0.0394 \n","[2023-12-09 07:34:21,607::train::INFO] [Train] Iter 3709 | Loss 0.027956 | Grad 0.0368 \n","[2023-12-09 07:34:21,706::train::INFO] [Train] Iter 3710 | Loss 0.028896 | Grad 0.0341 \n","[2023-12-09 07:34:21,798::train::INFO] [Train] Iter 3711 | Loss 0.027009 | Grad 0.0350 \n","[2023-12-09 07:34:21,891::train::INFO] [Train] Iter 3712 | Loss 0.027469 | Grad 0.0360 \n","[2023-12-09 07:34:21,985::train::INFO] [Train] Iter 3713 | Loss 0.028365 | Grad 0.0519 \n","[2023-12-09 07:34:22,078::train::INFO] [Train] Iter 3714 | Loss 0.028082 | Grad 0.0262 \n","[2023-12-09 07:34:22,174::train::INFO] [Train] Iter 3715 | Loss 0.026696 | Grad 0.0403 \n","[2023-12-09 07:34:22,272::train::INFO] [Train] Iter 3716 | Loss 0.027337 | Grad 0.0329 \n","[2023-12-09 07:34:22,368::train::INFO] [Train] Iter 3717 | Loss 0.029778 | Grad 0.0529 \n","[2023-12-09 07:34:22,460::train::INFO] [Train] Iter 3718 | Loss 0.027622 | Grad 0.0396 \n","[2023-12-09 07:34:22,552::train::INFO] [Train] Iter 3719 | Loss 0.027761 | Grad 0.0365 \n","[2023-12-09 07:34:22,643::train::INFO] [Train] Iter 3720 | Loss 0.028326 | Grad 0.0334 \n","[2023-12-09 07:34:22,735::train::INFO] [Train] Iter 3721 | Loss 0.025457 | Grad 0.0320 \n","[2023-12-09 07:34:22,830::train::INFO] [Train] Iter 3722 | Loss 0.029881 | Grad 0.0426 \n","[2023-12-09 07:34:22,923::train::INFO] [Train] Iter 3723 | Loss 0.027983 | Grad 0.0334 \n","[2023-12-09 07:34:23,016::train::INFO] [Train] Iter 3724 | Loss 0.025636 | Grad 0.0386 \n","[2023-12-09 07:34:23,110::train::INFO] [Train] Iter 3725 | Loss 0.028070 | Grad 0.0400 \n","[2023-12-09 07:34:23,203::train::INFO] [Train] Iter 3726 | Loss 0.030247 | Grad 0.0772 \n","[2023-12-09 07:34:23,296::train::INFO] [Train] Iter 3727 | Loss 0.027070 | Grad 0.0382 \n","[2023-12-09 07:34:23,390::train::INFO] [Train] Iter 3728 | Loss 0.028547 | Grad 0.0417 \n","[2023-12-09 07:34:23,483::train::INFO] [Train] Iter 3729 | Loss 0.027872 | Grad 0.0444 \n","[2023-12-09 07:34:23,576::train::INFO] [Train] Iter 3730 | Loss 0.028375 | Grad 0.0417 \n","[2023-12-09 07:34:23,669::train::INFO] [Train] Iter 3731 | Loss 0.025380 | Grad 0.0413 \n","[2023-12-09 07:34:23,761::train::INFO] [Train] Iter 3732 | Loss 0.027886 | Grad 0.0417 \n","[2023-12-09 07:34:23,854::train::INFO] [Train] Iter 3733 | Loss 0.027953 | Grad 0.0452 \n","[2023-12-09 07:34:23,948::train::INFO] [Train] Iter 3734 | Loss 0.029090 | Grad 0.0365 \n","[2023-12-09 07:34:24,040::train::INFO] [Train] Iter 3735 | Loss 0.025323 | Grad 0.0360 \n","[2023-12-09 07:34:24,133::train::INFO] [Train] Iter 3736 | Loss 0.029602 | Grad 0.0377 \n","[2023-12-09 07:34:24,224::train::INFO] [Train] Iter 3737 | Loss 0.029950 | Grad 0.0406 \n","[2023-12-09 07:34:24,315::train::INFO] [Train] Iter 3738 | Loss 0.025349 | Grad 0.0410 \n","[2023-12-09 07:34:24,408::train::INFO] [Train] Iter 3739 | Loss 0.025716 | Grad 0.0390 \n","[2023-12-09 07:34:24,451::train::INFO] [Train] Iter 3740 | Loss 0.026015 | Grad 0.0816 \n","[2023-12-09 07:34:24,542::train::INFO] [Train] Iter 3741 | Loss 0.025766 | Grad 0.0345 \n","[2023-12-09 07:34:24,634::train::INFO] [Train] Iter 3742 | Loss 0.029074 | Grad 0.0402 \n","[2023-12-09 07:34:24,727::train::INFO] [Train] Iter 3743 | Loss 0.027281 | Grad 0.0449 \n","[2023-12-09 07:34:24,819::train::INFO] [Train] Iter 3744 | Loss 0.028696 | Grad 0.0353 \n","[2023-12-09 07:34:24,912::train::INFO] [Train] Iter 3745 | Loss 0.027488 | Grad 0.0348 \n","[2023-12-09 07:34:25,004::train::INFO] [Train] Iter 3746 | Loss 0.029761 | Grad 0.0370 \n","[2023-12-09 07:34:25,097::train::INFO] [Train] Iter 3747 | Loss 0.027677 | Grad 0.0401 \n","[2023-12-09 07:34:25,189::train::INFO] [Train] Iter 3748 | Loss 0.029057 | Grad 0.0268 \n","[2023-12-09 07:34:25,282::train::INFO] [Train] Iter 3749 | Loss 0.027753 | Grad 0.0424 \n","[2023-12-09 07:34:25,376::train::INFO] [Train] Iter 3750 | Loss 0.028598 | Grad 0.0357 \n","[2023-12-09 07:34:25,470::train::INFO] [Train] Iter 3751 | Loss 0.026606 | Grad 0.0345 \n","[2023-12-09 07:34:25,562::train::INFO] [Train] Iter 3752 | Loss 0.029515 | Grad 0.0368 \n","[2023-12-09 07:34:25,654::train::INFO] [Train] Iter 3753 | Loss 0.027312 | Grad 0.0381 \n","[2023-12-09 07:34:25,747::train::INFO] [Train] Iter 3754 | Loss 0.027879 | Grad 0.0351 \n","[2023-12-09 07:34:25,838::train::INFO] [Train] Iter 3755 | Loss 0.027955 | Grad 0.0316 \n","[2023-12-09 07:34:25,930::train::INFO] [Train] Iter 3756 | Loss 0.027437 | Grad 0.0291 \n","[2023-12-09 07:34:26,021::train::INFO] [Train] Iter 3757 | Loss 0.027874 | Grad 0.0462 \n","[2023-12-09 07:34:26,113::train::INFO] [Train] Iter 3758 | Loss 0.026692 | Grad 0.0350 \n","[2023-12-09 07:34:26,206::train::INFO] [Train] Iter 3759 | Loss 0.029342 | Grad 0.0277 \n","[2023-12-09 07:34:26,299::train::INFO] [Train] Iter 3760 | Loss 0.026817 | Grad 0.0463 \n","[2023-12-09 07:34:26,395::train::INFO] [Train] Iter 3761 | Loss 0.025865 | Grad 0.0402 \n","[2023-12-09 07:34:26,487::train::INFO] [Train] Iter 3762 | Loss 0.028923 | Grad 0.0325 \n","[2023-12-09 07:34:26,581::train::INFO] [Train] Iter 3763 | Loss 0.026842 | Grad 0.0457 \n","[2023-12-09 07:34:26,673::train::INFO] [Train] Iter 3764 | Loss 0.027262 | Grad 0.0480 \n","[2023-12-09 07:34:26,768::train::INFO] [Train] Iter 3765 | Loss 0.027028 | Grad 0.0292 \n","[2023-12-09 07:34:26,853::train::INFO] [Train] Iter 3766 | Loss 0.027744 | Grad 0.0462 \n","[2023-12-09 07:34:26,937::train::INFO] [Train] Iter 3767 | Loss 0.029397 | Grad 0.0435 \n","[2023-12-09 07:34:27,023::train::INFO] [Train] Iter 3768 | Loss 0.028395 | Grad 0.0381 \n","[2023-12-09 07:34:27,108::train::INFO] [Train] Iter 3769 | Loss 0.026372 | Grad 0.0395 \n","[2023-12-09 07:34:27,193::train::INFO] [Train] Iter 3770 | Loss 0.028010 | Grad 0.0356 \n","[2023-12-09 07:34:27,279::train::INFO] [Train] Iter 3771 | Loss 0.029706 | Grad 0.0410 \n","[2023-12-09 07:34:27,366::train::INFO] [Train] Iter 3772 | Loss 0.026409 | Grad 0.0312 \n","[2023-12-09 07:34:27,451::train::INFO] [Train] Iter 3773 | Loss 0.029084 | Grad 0.0455 \n","[2023-12-09 07:34:27,537::train::INFO] [Train] Iter 3774 | Loss 0.028253 | Grad 0.0444 \n","[2023-12-09 07:34:27,623::train::INFO] [Train] Iter 3775 | Loss 0.025686 | Grad 0.0323 \n","[2023-12-09 07:34:27,707::train::INFO] [Train] Iter 3776 | Loss 0.029803 | Grad 0.0339 \n","[2023-12-09 07:34:27,790::train::INFO] [Train] Iter 3777 | Loss 0.027990 | Grad 0.0318 \n","[2023-12-09 07:34:27,875::train::INFO] [Train] Iter 3778 | Loss 0.029637 | Grad 0.0314 \n","[2023-12-09 07:34:27,959::train::INFO] [Train] Iter 3779 | Loss 0.026283 | Grad 0.0271 \n","[2023-12-09 07:34:28,043::train::INFO] [Train] Iter 3780 | Loss 0.027681 | Grad 0.0344 \n","[2023-12-09 07:34:28,129::train::INFO] [Train] Iter 3781 | Loss 0.028584 | Grad 0.0352 \n","[2023-12-09 07:34:28,214::train::INFO] [Train] Iter 3782 | Loss 0.027930 | Grad 0.0275 \n","[2023-12-09 07:34:28,297::train::INFO] [Train] Iter 3783 | Loss 0.027503 | Grad 0.0343 \n","[2023-12-09 07:34:28,383::train::INFO] [Train] Iter 3784 | Loss 0.026966 | Grad 0.0342 \n","[2023-12-09 07:34:28,468::train::INFO] [Train] Iter 3785 | Loss 0.027894 | Grad 0.0293 \n","[2023-12-09 07:34:28,553::train::INFO] [Train] Iter 3786 | Loss 0.028037 | Grad 0.0326 \n","[2023-12-09 07:34:28,641::train::INFO] [Train] Iter 3787 | Loss 0.025845 | Grad 0.0301 \n","[2023-12-09 07:34:28,727::train::INFO] [Train] Iter 3788 | Loss 0.026566 | Grad 0.0364 \n","[2023-12-09 07:34:28,811::train::INFO] [Train] Iter 3789 | Loss 0.028570 | Grad 0.0332 \n","[2023-12-09 07:34:28,898::train::INFO] [Train] Iter 3790 | Loss 0.026011 | Grad 0.0323 \n","[2023-12-09 07:34:28,982::train::INFO] [Train] Iter 3791 | Loss 0.029873 | Grad 0.0360 \n","[2023-12-09 07:34:29,066::train::INFO] [Train] Iter 3792 | Loss 0.027025 | Grad 0.0288 \n","[2023-12-09 07:34:29,149::train::INFO] [Train] Iter 3793 | Loss 0.028391 | Grad 0.0361 \n","[2023-12-09 07:34:29,233::train::INFO] [Train] Iter 3794 | Loss 0.026691 | Grad 0.0305 \n","[2023-12-09 07:34:29,320::train::INFO] [Train] Iter 3795 | Loss 0.027952 | Grad 0.0337 \n","[2023-12-09 07:34:29,404::train::INFO] [Train] Iter 3796 | Loss 0.030413 | Grad 0.0530 \n","[2023-12-09 07:34:29,495::train::INFO] [Train] Iter 3797 | Loss 0.027479 | Grad 0.0329 \n","[2023-12-09 07:34:29,580::train::INFO] [Train] Iter 3798 | Loss 0.027428 | Grad 0.0344 \n","[2023-12-09 07:34:29,669::train::INFO] [Train] Iter 3799 | Loss 0.026500 | Grad 0.0374 \n","[2023-12-09 07:34:29,753::train::INFO] [Train] Iter 3800 | Loss 0.025585 | Grad 0.0370 \n","[2023-12-09 07:34:29,837::train::INFO] [Train] Iter 3801 | Loss 0.028967 | Grad 0.0332 \n","[2023-12-09 07:34:29,923::train::INFO] [Train] Iter 3802 | Loss 0.030164 | Grad 0.0415 \n","[2023-12-09 07:34:30,007::train::INFO] [Train] Iter 3803 | Loss 0.027432 | Grad 0.0486 \n","[2023-12-09 07:34:30,092::train::INFO] [Train] Iter 3804 | Loss 0.029429 | Grad 0.0273 \n","[2023-12-09 07:34:30,177::train::INFO] [Train] Iter 3805 | Loss 0.029291 | Grad 0.0360 \n","[2023-12-09 07:34:30,260::train::INFO] [Train] Iter 3806 | Loss 0.027067 | Grad 0.0432 \n","[2023-12-09 07:34:30,345::train::INFO] [Train] Iter 3807 | Loss 0.027786 | Grad 0.0355 \n","[2023-12-09 07:34:30,434::train::INFO] [Train] Iter 3808 | Loss 0.025664 | Grad 0.0302 \n","[2023-12-09 07:34:30,517::train::INFO] [Train] Iter 3809 | Loss 0.028016 | Grad 0.0375 \n","[2023-12-09 07:34:30,604::train::INFO] [Train] Iter 3810 | Loss 0.027523 | Grad 0.0319 \n","[2023-12-09 07:34:30,689::train::INFO] [Train] Iter 3811 | Loss 0.027729 | Grad 0.0273 \n","[2023-12-09 07:34:30,773::train::INFO] [Train] Iter 3812 | Loss 0.027231 | Grad 0.0468 \n","[2023-12-09 07:34:30,857::train::INFO] [Train] Iter 3813 | Loss 0.027643 | Grad 0.0447 \n","[2023-12-09 07:34:30,941::train::INFO] [Train] Iter 3814 | Loss 0.026638 | Grad 0.0324 \n","[2023-12-09 07:34:31,029::train::INFO] [Train] Iter 3815 | Loss 0.027676 | Grad 0.0377 \n","[2023-12-09 07:34:31,113::train::INFO] [Train] Iter 3816 | Loss 0.026814 | Grad 0.0333 \n","[2023-12-09 07:34:31,197::train::INFO] [Train] Iter 3817 | Loss 0.026748 | Grad 0.0316 \n","[2023-12-09 07:34:31,284::train::INFO] [Train] Iter 3818 | Loss 0.026652 | Grad 0.0373 \n","[2023-12-09 07:34:31,368::train::INFO] [Train] Iter 3819 | Loss 0.028131 | Grad 0.0356 \n","[2023-12-09 07:34:31,453::train::INFO] [Train] Iter 3820 | Loss 0.026490 | Grad 0.0410 \n","[2023-12-09 07:34:31,537::train::INFO] [Train] Iter 3821 | Loss 0.027577 | Grad 0.0419 \n","[2023-12-09 07:34:31,620::train::INFO] [Train] Iter 3822 | Loss 0.025127 | Grad 0.0301 \n","[2023-12-09 07:34:31,707::train::INFO] [Train] Iter 3823 | Loss 0.026345 | Grad 0.0388 \n","[2023-12-09 07:34:31,791::train::INFO] [Train] Iter 3824 | Loss 0.028528 | Grad 0.0371 \n","[2023-12-09 07:34:31,875::train::INFO] [Train] Iter 3825 | Loss 0.027708 | Grad 0.0342 \n","[2023-12-09 07:34:31,962::train::INFO] [Train] Iter 3826 | Loss 0.028368 | Grad 0.0497 \n","[2023-12-09 07:34:32,046::train::INFO] [Train] Iter 3827 | Loss 0.027345 | Grad 0.0399 \n","[2023-12-09 07:34:32,130::train::INFO] [Train] Iter 3828 | Loss 0.029370 | Grad 0.0312 \n","[2023-12-09 07:34:32,216::train::INFO] [Train] Iter 3829 | Loss 0.027335 | Grad 0.0328 \n","[2023-12-09 07:34:32,301::train::INFO] [Train] Iter 3830 | Loss 0.028790 | Grad 0.0459 \n","[2023-12-09 07:34:32,390::train::INFO] [Train] Iter 3831 | Loss 0.026304 | Grad 0.0321 \n","[2023-12-09 07:34:32,477::train::INFO] [Train] Iter 3832 | Loss 0.027469 | Grad 0.0292 \n","[2023-12-09 07:34:32,561::train::INFO] [Train] Iter 3833 | Loss 0.027404 | Grad 0.0314 \n","[2023-12-09 07:34:32,645::train::INFO] [Train] Iter 3834 | Loss 0.027485 | Grad 0.0497 \n","[2023-12-09 07:34:32,733::train::INFO] [Train] Iter 3835 | Loss 0.029859 | Grad 0.0280 \n","[2023-12-09 07:34:32,819::train::INFO] [Train] Iter 3836 | Loss 0.024452 | Grad 0.0333 \n","[2023-12-09 07:34:32,905::train::INFO] [Train] Iter 3837 | Loss 0.027784 | Grad 0.0346 \n","[2023-12-09 07:34:32,989::train::INFO] [Train] Iter 3838 | Loss 0.026700 | Grad 0.0359 \n","[2023-12-09 07:34:33,074::train::INFO] [Train] Iter 3839 | Loss 0.026174 | Grad 0.0283 \n","[2023-12-09 07:34:33,159::train::INFO] [Train] Iter 3840 | Loss 0.029431 | Grad 0.0337 \n","[2023-12-09 07:34:33,243::train::INFO] [Train] Iter 3841 | Loss 0.027279 | Grad 0.0283 \n","[2023-12-09 07:34:33,328::train::INFO] [Train] Iter 3842 | Loss 0.027051 | Grad 0.0314 \n","[2023-12-09 07:34:33,413::train::INFO] [Train] Iter 3843 | Loss 0.026912 | Grad 0.0341 \n","[2023-12-09 07:34:33,499::train::INFO] [Train] Iter 3844 | Loss 0.027184 | Grad 0.0304 \n","[2023-12-09 07:34:33,583::train::INFO] [Train] Iter 3845 | Loss 0.027872 | Grad 0.0370 \n","[2023-12-09 07:34:33,669::train::INFO] [Train] Iter 3846 | Loss 0.028814 | Grad 0.0340 \n","[2023-12-09 07:34:33,755::train::INFO] [Train] Iter 3847 | Loss 0.024642 | Grad 0.0364 \n","[2023-12-09 07:34:33,840::train::INFO] [Train] Iter 3848 | Loss 0.028450 | Grad 0.0295 \n","[2023-12-09 07:34:33,927::train::INFO] [Train] Iter 3849 | Loss 0.030985 | Grad 0.0442 \n","[2023-12-09 07:34:34,013::train::INFO] [Train] Iter 3850 | Loss 0.027042 | Grad 0.0340 \n","[2023-12-09 07:34:34,099::train::INFO] [Train] Iter 3851 | Loss 0.029103 | Grad 0.0308 \n","[2023-12-09 07:34:34,186::train::INFO] [Train] Iter 3852 | Loss 0.027150 | Grad 0.0395 \n","[2023-12-09 07:34:34,270::train::INFO] [Train] Iter 3853 | Loss 0.026954 | Grad 0.0330 \n","[2023-12-09 07:34:34,356::train::INFO] [Train] Iter 3854 | Loss 0.027602 | Grad 0.0365 \n","[2023-12-09 07:34:34,443::train::INFO] [Train] Iter 3855 | Loss 0.027206 | Grad 0.0373 \n","[2023-12-09 07:34:34,527::train::INFO] [Train] Iter 3856 | Loss 0.027880 | Grad 0.0429 \n","[2023-12-09 07:34:34,612::train::INFO] [Train] Iter 3857 | Loss 0.027907 | Grad 0.0259 \n","[2023-12-09 07:34:34,696::train::INFO] [Train] Iter 3858 | Loss 0.027065 | Grad 0.0422 \n","[2023-12-09 07:34:34,784::train::INFO] [Train] Iter 3859 | Loss 0.023966 | Grad 0.0326 \n","[2023-12-09 07:34:34,868::train::INFO] [Train] Iter 3860 | Loss 0.028625 | Grad 0.0366 \n","[2023-12-09 07:34:34,953::train::INFO] [Train] Iter 3861 | Loss 0.026563 | Grad 0.0310 \n","[2023-12-09 07:34:35,039::train::INFO] [Train] Iter 3862 | Loss 0.024746 | Grad 0.0343 \n","[2023-12-09 07:34:35,123::train::INFO] [Train] Iter 3863 | Loss 0.026005 | Grad 0.0286 \n","[2023-12-09 07:34:35,207::train::INFO] [Train] Iter 3864 | Loss 0.027896 | Grad 0.0444 \n","[2023-12-09 07:34:35,292::train::INFO] [Train] Iter 3865 | Loss 0.027396 | Grad 0.0343 \n","[2023-12-09 07:34:35,380::train::INFO] [Train] Iter 3866 | Loss 0.027754 | Grad 0.0353 \n","[2023-12-09 07:34:35,464::train::INFO] [Train] Iter 3867 | Loss 0.025911 | Grad 0.0254 \n","[2023-12-09 07:34:35,549::train::INFO] [Train] Iter 3868 | Loss 0.027108 | Grad 0.0316 \n","[2023-12-09 07:34:35,637::train::INFO] [Train] Iter 3869 | Loss 0.028139 | Grad 0.0352 \n","[2023-12-09 07:34:35,722::train::INFO] [Train] Iter 3870 | Loss 0.025489 | Grad 0.0387 \n","[2023-12-09 07:34:35,806::train::INFO] [Train] Iter 3871 | Loss 0.028252 | Grad 0.0295 \n","[2023-12-09 07:34:35,891::train::INFO] [Train] Iter 3872 | Loss 0.028157 | Grad 0.0386 \n","[2023-12-09 07:34:35,978::train::INFO] [Train] Iter 3873 | Loss 0.027162 | Grad 0.0295 \n","[2023-12-09 07:34:36,064::train::INFO] [Train] Iter 3874 | Loss 0.025957 | Grad 0.0417 \n","[2023-12-09 07:34:36,148::train::INFO] [Train] Iter 3875 | Loss 0.026511 | Grad 0.0276 \n","[2023-12-09 07:34:36,232::train::INFO] [Train] Iter 3876 | Loss 0.025551 | Grad 0.0492 \n","[2023-12-09 07:34:36,316::train::INFO] [Train] Iter 3877 | Loss 0.026386 | Grad 0.0372 \n","[2023-12-09 07:34:36,401::train::INFO] [Train] Iter 3878 | Loss 0.026783 | Grad 0.0562 \n","[2023-12-09 07:34:36,487::train::INFO] [Train] Iter 3879 | Loss 0.027548 | Grad 0.0503 \n","[2023-12-09 07:34:36,579::train::INFO] [Train] Iter 3880 | Loss 0.027630 | Grad 0.0481 \n","[2023-12-09 07:34:36,663::train::INFO] [Train] Iter 3881 | Loss 0.028418 | Grad 0.0567 \n","[2023-12-09 07:34:36,748::train::INFO] [Train] Iter 3882 | Loss 0.027252 | Grad 0.0295 \n","[2023-12-09 07:34:36,837::train::INFO] [Train] Iter 3883 | Loss 0.029397 | Grad 0.0319 \n","[2023-12-09 07:34:36,936::train::INFO] [Train] Iter 3884 | Loss 0.027549 | Grad 0.0453 \n","[2023-12-09 07:34:37,031::train::INFO] [Train] Iter 3885 | Loss 0.030280 | Grad 0.0397 \n","[2023-12-09 07:34:37,129::train::INFO] [Train] Iter 3886 | Loss 0.028433 | Grad 0.0337 \n","[2023-12-09 07:34:37,223::train::INFO] [Train] Iter 3887 | Loss 0.027046 | Grad 0.0360 \n","[2023-12-09 07:34:37,321::train::INFO] [Train] Iter 3888 | Loss 0.027931 | Grad 0.0376 \n","[2023-12-09 07:34:37,414::train::INFO] [Train] Iter 3889 | Loss 0.028674 | Grad 0.0348 \n","[2023-12-09 07:34:37,507::train::INFO] [Train] Iter 3890 | Loss 0.029767 | Grad 0.0387 \n","[2023-12-09 07:34:37,603::train::INFO] [Train] Iter 3891 | Loss 0.029966 | Grad 0.0384 \n","[2023-12-09 07:34:37,695::train::INFO] [Train] Iter 3892 | Loss 0.029006 | Grad 0.0396 \n","[2023-12-09 07:34:37,787::train::INFO] [Train] Iter 3893 | Loss 0.027181 | Grad 0.0303 \n","[2023-12-09 07:34:37,879::train::INFO] [Train] Iter 3894 | Loss 0.026965 | Grad 0.0539 \n","[2023-12-09 07:34:37,970::train::INFO] [Train] Iter 3895 | Loss 0.028002 | Grad 0.0361 \n","[2023-12-09 07:34:38,062::train::INFO] [Train] Iter 3896 | Loss 0.028764 | Grad 0.0291 \n","[2023-12-09 07:34:38,153::train::INFO] [Train] Iter 3897 | Loss 0.025340 | Grad 0.0381 \n","[2023-12-09 07:34:38,246::train::INFO] [Train] Iter 3898 | Loss 0.027613 | Grad 0.0439 \n","[2023-12-09 07:34:38,337::train::INFO] [Train] Iter 3899 | Loss 0.025190 | Grad 0.0386 \n","[2023-12-09 07:34:38,428::train::INFO] [Train] Iter 3900 | Loss 0.026462 | Grad 0.0338 \n","[2023-12-09 07:34:38,523::train::INFO] [Train] Iter 3901 | Loss 0.027024 | Grad 0.0434 \n","[2023-12-09 07:34:38,616::train::INFO] [Train] Iter 3902 | Loss 0.028387 | Grad 0.0317 \n","[2023-12-09 07:34:38,708::train::INFO] [Train] Iter 3903 | Loss 0.029448 | Grad 0.0526 \n","[2023-12-09 07:34:38,800::train::INFO] [Train] Iter 3904 | Loss 0.029030 | Grad 0.0404 \n","[2023-12-09 07:34:38,892::train::INFO] [Train] Iter 3905 | Loss 0.026606 | Grad 0.0377 \n","[2023-12-09 07:34:38,983::train::INFO] [Train] Iter 3906 | Loss 0.028184 | Grad 0.0436 \n","[2023-12-09 07:34:39,074::train::INFO] [Train] Iter 3907 | Loss 0.027094 | Grad 0.0347 \n","[2023-12-09 07:34:39,166::train::INFO] [Train] Iter 3908 | Loss 0.029321 | Grad 0.0724 \n","[2023-12-09 07:34:39,256::train::INFO] [Train] Iter 3909 | Loss 0.025240 | Grad 0.0399 \n","[2023-12-09 07:34:39,348::train::INFO] [Train] Iter 3910 | Loss 0.025466 | Grad 0.0385 \n","[2023-12-09 07:34:39,439::train::INFO] [Train] Iter 3911 | Loss 0.026783 | Grad 0.0520 \n","[2023-12-09 07:34:39,534::train::INFO] [Train] Iter 3912 | Loss 0.030660 | Grad 0.0356 \n","[2023-12-09 07:34:39,625::train::INFO] [Train] Iter 3913 | Loss 0.029997 | Grad 0.0614 \n","[2023-12-09 07:34:39,716::train::INFO] [Train] Iter 3914 | Loss 0.026870 | Grad 0.0416 \n","[2023-12-09 07:34:39,808::train::INFO] [Train] Iter 3915 | Loss 0.027923 | Grad 0.0340 \n","[2023-12-09 07:34:39,906::train::INFO] [Train] Iter 3916 | Loss 0.026197 | Grad 0.0339 \n","[2023-12-09 07:34:39,998::train::INFO] [Train] Iter 3917 | Loss 0.026435 | Grad 0.0299 \n","[2023-12-09 07:34:40,091::train::INFO] [Train] Iter 3918 | Loss 0.025363 | Grad 0.0489 \n","[2023-12-09 07:34:40,184::train::INFO] [Train] Iter 3919 | Loss 0.025760 | Grad 0.0379 \n","[2023-12-09 07:34:40,276::train::INFO] [Train] Iter 3920 | Loss 0.028755 | Grad 0.0382 \n","[2023-12-09 07:34:40,367::train::INFO] [Train] Iter 3921 | Loss 0.029927 | Grad 0.0481 \n","[2023-12-09 07:34:40,459::train::INFO] [Train] Iter 3922 | Loss 0.026166 | Grad 0.0305 \n","[2023-12-09 07:34:40,551::train::INFO] [Train] Iter 3923 | Loss 0.025396 | Grad 0.0332 \n","[2023-12-09 07:34:40,648::train::INFO] [Train] Iter 3924 | Loss 0.028538 | Grad 0.0434 \n","[2023-12-09 07:34:40,739::train::INFO] [Train] Iter 3925 | Loss 0.026077 | Grad 0.0345 \n","[2023-12-09 07:34:40,830::train::INFO] [Train] Iter 3926 | Loss 0.028436 | Grad 0.0308 \n","[2023-12-09 07:34:40,930::train::INFO] [Train] Iter 3927 | Loss 0.026168 | Grad 0.0274 \n","[2023-12-09 07:34:41,028::train::INFO] [Train] Iter 3928 | Loss 0.028772 | Grad 0.0320 \n","[2023-12-09 07:34:41,126::train::INFO] [Train] Iter 3929 | Loss 0.027788 | Grad 0.0457 \n","[2023-12-09 07:34:41,220::train::INFO] [Train] Iter 3930 | Loss 0.028656 | Grad 0.0316 \n","[2023-12-09 07:34:41,316::train::INFO] [Train] Iter 3931 | Loss 0.028586 | Grad 0.0385 \n","[2023-12-09 07:34:41,407::train::INFO] [Train] Iter 3932 | Loss 0.026712 | Grad 0.0532 \n","[2023-12-09 07:34:41,502::train::INFO] [Train] Iter 3933 | Loss 0.026927 | Grad 0.0401 \n","[2023-12-09 07:34:41,593::train::INFO] [Train] Iter 3934 | Loss 0.027133 | Grad 0.0299 \n","[2023-12-09 07:34:41,689::train::INFO] [Train] Iter 3935 | Loss 0.028930 | Grad 0.0401 \n","[2023-12-09 07:34:41,785::train::INFO] [Train] Iter 3936 | Loss 0.029077 | Grad 0.0310 \n","[2023-12-09 07:34:41,876::train::INFO] [Train] Iter 3937 | Loss 0.027041 | Grad 0.0522 \n","[2023-12-09 07:34:41,972::train::INFO] [Train] Iter 3938 | Loss 0.026417 | Grad 0.0387 \n","[2023-12-09 07:34:42,070::train::INFO] [Train] Iter 3939 | Loss 0.028691 | Grad 0.0322 \n","[2023-12-09 07:34:42,162::train::INFO] [Train] Iter 3940 | Loss 0.025259 | Grad 0.0327 \n","[2023-12-09 07:34:42,254::train::INFO] [Train] Iter 3941 | Loss 0.026135 | Grad 0.0400 \n","[2023-12-09 07:34:42,346::train::INFO] [Train] Iter 3942 | Loss 0.027765 | Grad 0.0351 \n","[2023-12-09 07:34:42,438::train::INFO] [Train] Iter 3943 | Loss 0.028735 | Grad 0.0356 \n","[2023-12-09 07:34:42,534::train::INFO] [Train] Iter 3944 | Loss 0.027162 | Grad 0.0350 \n","[2023-12-09 07:34:42,627::train::INFO] [Train] Iter 3945 | Loss 0.026262 | Grad 0.0388 \n","[2023-12-09 07:34:42,718::train::INFO] [Train] Iter 3946 | Loss 0.026983 | Grad 0.0309 \n","[2023-12-09 07:34:42,810::train::INFO] [Train] Iter 3947 | Loss 0.027042 | Grad 0.0313 \n","[2023-12-09 07:34:42,902::train::INFO] [Train] Iter 3948 | Loss 0.026967 | Grad 0.0404 \n","[2023-12-09 07:34:42,994::train::INFO] [Train] Iter 3949 | Loss 0.025958 | Grad 0.0356 \n","[2023-12-09 07:34:43,097::train::INFO] [Train] Iter 3950 | Loss 0.029079 | Grad 0.0366 \n","[2023-12-09 07:34:43,188::train::INFO] [Train] Iter 3951 | Loss 0.028711 | Grad 0.0353 \n","[2023-12-09 07:34:43,279::train::INFO] [Train] Iter 3952 | Loss 0.026824 | Grad 0.0439 \n","[2023-12-09 07:34:43,372::train::INFO] [Train] Iter 3953 | Loss 0.027665 | Grad 0.0375 \n","[2023-12-09 07:34:43,464::train::INFO] [Train] Iter 3954 | Loss 0.028391 | Grad 0.0325 \n","[2023-12-09 07:34:43,554::train::INFO] [Train] Iter 3955 | Loss 0.026168 | Grad 0.0411 \n","[2023-12-09 07:34:43,645::train::INFO] [Train] Iter 3956 | Loss 0.029198 | Grad 0.0293 \n","[2023-12-09 07:34:43,742::train::INFO] [Train] Iter 3957 | Loss 0.026454 | Grad 0.0325 \n","[2023-12-09 07:34:43,833::train::INFO] [Train] Iter 3958 | Loss 0.030255 | Grad 0.0318 \n","[2023-12-09 07:34:43,925::train::INFO] [Train] Iter 3959 | Loss 0.026758 | Grad 0.0311 \n","[2023-12-09 07:34:44,017::train::INFO] [Train] Iter 3960 | Loss 0.028187 | Grad 0.0299 \n","[2023-12-09 07:34:44,118::train::INFO] [Train] Iter 3961 | Loss 0.026982 | Grad 0.0380 \n","[2023-12-09 07:34:44,215::train::INFO] [Train] Iter 3962 | Loss 0.026497 | Grad 0.0310 \n","[2023-12-09 07:34:44,314::train::INFO] [Train] Iter 3963 | Loss 0.027095 | Grad 0.0408 \n","[2023-12-09 07:34:44,406::train::INFO] [Train] Iter 3964 | Loss 0.028140 | Grad 0.0611 \n","[2023-12-09 07:34:44,503::train::INFO] [Train] Iter 3965 | Loss 0.027167 | Grad 0.0376 \n","[2023-12-09 07:34:44,598::train::INFO] [Train] Iter 3966 | Loss 0.028168 | Grad 0.0333 \n","[2023-12-09 07:34:44,696::train::INFO] [Train] Iter 3967 | Loss 0.028049 | Grad 0.0267 \n","[2023-12-09 07:34:44,791::train::INFO] [Train] Iter 3968 | Loss 0.025379 | Grad 0.0270 \n","[2023-12-09 07:34:44,883::train::INFO] [Train] Iter 3969 | Loss 0.028684 | Grad 0.0419 \n","[2023-12-09 07:34:44,983::train::INFO] [Train] Iter 3970 | Loss 0.025561 | Grad 0.0285 \n","[2023-12-09 07:34:45,089::train::INFO] [Train] Iter 3971 | Loss 0.028350 | Grad 0.0376 \n","[2023-12-09 07:34:45,192::train::INFO] [Train] Iter 3972 | Loss 0.027269 | Grad 0.0338 \n","[2023-12-09 07:34:45,290::train::INFO] [Train] Iter 3973 | Loss 0.029385 | Grad 0.0272 \n","[2023-12-09 07:34:45,397::train::INFO] [Train] Iter 3974 | Loss 0.027376 | Grad 0.0327 \n","[2023-12-09 07:34:45,499::train::INFO] [Train] Iter 3975 | Loss 0.027511 | Grad 0.0297 \n","[2023-12-09 07:34:45,603::train::INFO] [Train] Iter 3976 | Loss 0.027576 | Grad 0.0392 \n","[2023-12-09 07:34:45,701::train::INFO] [Train] Iter 3977 | Loss 0.027320 | Grad 0.0379 \n","[2023-12-09 07:34:45,801::train::INFO] [Train] Iter 3978 | Loss 0.025912 | Grad 0.0294 \n","[2023-12-09 07:34:45,893::train::INFO] [Train] Iter 3979 | Loss 0.026898 | Grad 0.0303 \n","[2023-12-09 07:34:45,984::train::INFO] [Train] Iter 3980 | Loss 0.027246 | Grad 0.0258 \n","[2023-12-09 07:34:46,074::train::INFO] [Train] Iter 3981 | Loss 0.027774 | Grad 0.0412 \n","[2023-12-09 07:34:46,177::train::INFO] [Train] Iter 3982 | Loss 0.026487 | Grad 0.0338 \n","[2023-12-09 07:34:46,269::train::INFO] [Train] Iter 3983 | Loss 0.027471 | Grad 0.0350 \n","[2023-12-09 07:34:46,367::train::INFO] [Train] Iter 3984 | Loss 0.029206 | Grad 0.0330 \n","[2023-12-09 07:34:46,464::train::INFO] [Train] Iter 3985 | Loss 0.028701 | Grad 0.0408 \n","[2023-12-09 07:34:46,557::train::INFO] [Train] Iter 3986 | Loss 0.026498 | Grad 0.0338 \n","[2023-12-09 07:34:46,649::train::INFO] [Train] Iter 3987 | Loss 0.024765 | Grad 0.0336 \n","[2023-12-09 07:34:46,746::train::INFO] [Train] Iter 3988 | Loss 0.027433 | Grad 0.0280 \n","[2023-12-09 07:34:46,839::train::INFO] [Train] Iter 3989 | Loss 0.024963 | Grad 0.0274 \n","[2023-12-09 07:34:46,930::train::INFO] [Train] Iter 3990 | Loss 0.024696 | Grad 0.0360 \n","[2023-12-09 07:34:47,024::train::INFO] [Train] Iter 3991 | Loss 0.026880 | Grad 0.0344 \n","[2023-12-09 07:34:47,117::train::INFO] [Train] Iter 3992 | Loss 0.026539 | Grad 0.0312 \n","[2023-12-09 07:34:47,208::train::INFO] [Train] Iter 3993 | Loss 0.028679 | Grad 0.0341 \n","[2023-12-09 07:34:47,303::train::INFO] [Train] Iter 3994 | Loss 0.026573 | Grad 0.0362 \n","[2023-12-09 07:34:47,402::train::INFO] [Train] Iter 3995 | Loss 0.026326 | Grad 0.0418 \n","[2023-12-09 07:34:47,494::train::INFO] [Train] Iter 3996 | Loss 0.025885 | Grad 0.0380 \n","[2023-12-09 07:34:47,587::train::INFO] [Train] Iter 3997 | Loss 0.028211 | Grad 0.0342 \n","[2023-12-09 07:34:47,683::train::INFO] [Train] Iter 3998 | Loss 0.027358 | Grad 0.0312 \n","[2023-12-09 07:34:47,776::train::INFO] [Train] Iter 3999 | Loss 0.029262 | Grad 0.0325 \n","[2023-12-09 07:34:47,868::train::INFO] [Train] Iter 4000 | Loss 0.028959 | Grad 0.0358 \n","Validate: 100% 241/241 [00:04<00:00, 54.82it/s]\n","val loss list [tensor(0.0300, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0258, device='cuda:0'), tensor(0.0234, device='cuda:0'), tensor(0.0221, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0236, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0267, device='cuda:0'), tensor(0.0239, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0240, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0298, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0240, device='cuda:0'), tensor(0.0258, device='cuda:0'), tensor(0.0267, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0237, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0267, device='cuda:0'), tensor(0.0235, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0248, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0231, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0319, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0334, device='cuda:0'), tensor(0.0325, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0231, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0267, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0258, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0334, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0311, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0245, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0240, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0243, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0251, device='cuda:0'), tensor(0.0236, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0238, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0267, device='cuda:0'), tensor(0.0225, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0312, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0244, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0201, device='cuda:0'), tensor(0.0245, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0215, device='cuda:0'), tensor(0.0332, device='cuda:0'), tensor(0.0243, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0243, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0243, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0243, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0328, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0249, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0321, device='cuda:0'), tensor(0.0321, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0237, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0303, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0330, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0245, device='cuda:0'), tensor(0.0327, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0251, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0239, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0321, device='cuda:0'), tensor(0.0303, device='cuda:0'), tensor(0.0240, device='cuda:0'), tensor(0.0237, device='cuda:0'), tensor(0.0298, device='cuda:0'), tensor(0.0233, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0312, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0258, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0298, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0241, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0187, device='cuda:0'), tensor(0.0247, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0205, device='cuda:0'), tensor(0.0237, device='cuda:0'), tensor(0.0247, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0321, device='cuda:0')]\n","[2023-12-09 07:34:52,533::train::INFO] [Train] Iter 4001 | Loss 0.027586 | Grad 0.0307 \n","[2023-12-09 07:34:52,629::train::INFO] [Train] Iter 4002 | Loss 0.028961 | Grad 0.0301 \n","[2023-12-09 07:34:52,714::train::INFO] [Train] Iter 4003 | Loss 0.025706 | Grad 0.0282 \n","[2023-12-09 07:34:52,799::train::INFO] [Train] Iter 4004 | Loss 0.026938 | Grad 0.0346 \n","[2023-12-09 07:34:52,889::train::INFO] [Train] Iter 4005 | Loss 0.027443 | Grad 0.0275 \n","[2023-12-09 07:34:52,974::train::INFO] [Train] Iter 4006 | Loss 0.029396 | Grad 0.0266 \n","[2023-12-09 07:34:53,060::train::INFO] [Train] Iter 4007 | Loss 0.027774 | Grad 0.0345 \n","[2023-12-09 07:34:53,145::train::INFO] [Train] Iter 4008 | Loss 0.027653 | Grad 0.0313 \n","[2023-12-09 07:34:53,230::train::INFO] [Train] Iter 4009 | Loss 0.026082 | Grad 0.0408 \n","[2023-12-09 07:34:53,315::train::INFO] [Train] Iter 4010 | Loss 0.029146 | Grad 0.0349 \n","[2023-12-09 07:34:53,404::train::INFO] [Train] Iter 4011 | Loss 0.028501 | Grad 0.0379 \n","[2023-12-09 07:34:53,490::train::INFO] [Train] Iter 4012 | Loss 0.025070 | Grad 0.0307 \n","[2023-12-09 07:34:53,576::train::INFO] [Train] Iter 4013 | Loss 0.025311 | Grad 0.0315 \n","[2023-12-09 07:34:53,664::train::INFO] [Train] Iter 4014 | Loss 0.026710 | Grad 0.0346 \n","[2023-12-09 07:34:53,749::train::INFO] [Train] Iter 4015 | Loss 0.025328 | Grad 0.0396 \n","[2023-12-09 07:34:53,833::train::INFO] [Train] Iter 4016 | Loss 0.026594 | Grad 0.0320 \n","[2023-12-09 07:34:53,918::train::INFO] [Train] Iter 4017 | Loss 0.027072 | Grad 0.0337 \n","[2023-12-09 07:34:54,004::train::INFO] [Train] Iter 4018 | Loss 0.026359 | Grad 0.0361 \n","[2023-12-09 07:34:54,089::train::INFO] [Train] Iter 4019 | Loss 0.027967 | Grad 0.0429 \n","[2023-12-09 07:34:54,173::train::INFO] [Train] Iter 4020 | Loss 0.026364 | Grad 0.0350 \n","[2023-12-09 07:34:54,258::train::INFO] [Train] Iter 4021 | Loss 0.027875 | Grad 0.0483 \n","[2023-12-09 07:34:54,343::train::INFO] [Train] Iter 4022 | Loss 0.026595 | Grad 0.0426 \n","[2023-12-09 07:34:54,429::train::INFO] [Train] Iter 4023 | Loss 0.025740 | Grad 0.0378 \n","[2023-12-09 07:34:54,514::train::INFO] [Train] Iter 4024 | Loss 0.028476 | Grad 0.0328 \n","[2023-12-09 07:34:54,599::train::INFO] [Train] Iter 4025 | Loss 0.025740 | Grad 0.0388 \n","[2023-12-09 07:34:54,696::train::INFO] [Train] Iter 4026 | Loss 0.026264 | Grad 0.0376 \n","[2023-12-09 07:34:54,782::train::INFO] [Train] Iter 4027 | Loss 0.025610 | Grad 0.0357 \n","[2023-12-09 07:34:54,866::train::INFO] [Train] Iter 4028 | Loss 0.028214 | Grad 0.0465 \n","[2023-12-09 07:34:54,952::train::INFO] [Train] Iter 4029 | Loss 0.026347 | Grad 0.0491 \n","[2023-12-09 07:34:55,037::train::INFO] [Train] Iter 4030 | Loss 0.027577 | Grad 0.0463 \n","[2023-12-09 07:34:55,121::train::INFO] [Train] Iter 4031 | Loss 0.025643 | Grad 0.0444 \n","[2023-12-09 07:34:55,207::train::INFO] [Train] Iter 4032 | Loss 0.027234 | Grad 0.0356 \n","[2023-12-09 07:34:55,300::train::INFO] [Train] Iter 4033 | Loss 0.026928 | Grad 0.0488 \n","[2023-12-09 07:34:55,386::train::INFO] [Train] Iter 4034 | Loss 0.029424 | Grad 0.0587 \n","[2023-12-09 07:34:55,473::train::INFO] [Train] Iter 4035 | Loss 0.027409 | Grad 0.0339 \n","[2023-12-09 07:34:55,557::train::INFO] [Train] Iter 4036 | Loss 0.031409 | Grad 0.0454 \n","[2023-12-09 07:34:55,642::train::INFO] [Train] Iter 4037 | Loss 0.028484 | Grad 0.0385 \n","[2023-12-09 07:34:55,728::train::INFO] [Train] Iter 4038 | Loss 0.024145 | Grad 0.0442 \n","[2023-12-09 07:34:55,820::train::INFO] [Train] Iter 4039 | Loss 0.029949 | Grad 0.0368 \n","[2023-12-09 07:34:55,918::train::INFO] [Train] Iter 4040 | Loss 0.027493 | Grad 0.0318 \n","[2023-12-09 07:34:56,009::train::INFO] [Train] Iter 4041 | Loss 0.024777 | Grad 0.0502 \n","[2023-12-09 07:34:56,105::train::INFO] [Train] Iter 4042 | Loss 0.028420 | Grad 0.0304 \n","[2023-12-09 07:34:56,198::train::INFO] [Train] Iter 4043 | Loss 0.026617 | Grad 0.0360 \n","[2023-12-09 07:34:56,291::train::INFO] [Train] Iter 4044 | Loss 0.027421 | Grad 0.0337 \n","[2023-12-09 07:34:56,385::train::INFO] [Train] Iter 4045 | Loss 0.028058 | Grad 0.0357 \n","[2023-12-09 07:34:56,477::train::INFO] [Train] Iter 4046 | Loss 0.027788 | Grad 0.0398 \n","[2023-12-09 07:34:56,569::train::INFO] [Train] Iter 4047 | Loss 0.027098 | Grad 0.0325 \n","[2023-12-09 07:34:56,661::train::INFO] [Train] Iter 4048 | Loss 0.023744 | Grad 0.0358 \n","[2023-12-09 07:34:56,757::train::INFO] [Train] Iter 4049 | Loss 0.027631 | Grad 0.0327 \n","[2023-12-09 07:34:56,849::train::INFO] [Train] Iter 4050 | Loss 0.028643 | Grad 0.0374 \n","[2023-12-09 07:34:56,940::train::INFO] [Train] Iter 4051 | Loss 0.026718 | Grad 0.0295 \n","[2023-12-09 07:34:57,040::train::INFO] [Train] Iter 4052 | Loss 0.027122 | Grad 0.0351 \n","[2023-12-09 07:34:57,131::train::INFO] [Train] Iter 4053 | Loss 0.027992 | Grad 0.0470 \n","[2023-12-09 07:34:57,223::train::INFO] [Train] Iter 4054 | Loss 0.027713 | Grad 0.0256 \n","[2023-12-09 07:34:57,316::train::INFO] [Train] Iter 4055 | Loss 0.026290 | Grad 0.0336 \n","[2023-12-09 07:34:57,407::train::INFO] [Train] Iter 4056 | Loss 0.027015 | Grad 0.0329 \n","[2023-12-09 07:34:57,499::train::INFO] [Train] Iter 4057 | Loss 0.029335 | Grad 0.0414 \n","[2023-12-09 07:34:57,591::train::INFO] [Train] Iter 4058 | Loss 0.027329 | Grad 0.0355 \n","[2023-12-09 07:34:57,683::train::INFO] [Train] Iter 4059 | Loss 0.027473 | Grad 0.0369 \n","[2023-12-09 07:34:57,777::train::INFO] [Train] Iter 4060 | Loss 0.028012 | Grad 0.0302 \n","[2023-12-09 07:34:57,870::train::INFO] [Train] Iter 4061 | Loss 0.025112 | Grad 0.0277 \n","[2023-12-09 07:34:57,962::train::INFO] [Train] Iter 4062 | Loss 0.029610 | Grad 0.0409 \n","[2023-12-09 07:34:58,051::train::INFO] [Train] Iter 4063 | Loss 0.027673 | Grad 0.0344 \n","[2023-12-09 07:34:58,141::train::INFO] [Train] Iter 4064 | Loss 0.025269 | Grad 0.0336 \n","[2023-12-09 07:34:58,232::train::INFO] [Train] Iter 4065 | Loss 0.027781 | Grad 0.0372 \n","[2023-12-09 07:34:58,326::train::INFO] [Train] Iter 4066 | Loss 0.029971 | Grad 0.0784 \n","[2023-12-09 07:34:58,417::train::INFO] [Train] Iter 4067 | Loss 0.026702 | Grad 0.0334 \n","[2023-12-09 07:34:58,510::train::INFO] [Train] Iter 4068 | Loss 0.028341 | Grad 0.0399 \n","[2023-12-09 07:34:58,601::train::INFO] [Train] Iter 4069 | Loss 0.027575 | Grad 0.0420 \n","[2023-12-09 07:34:58,693::train::INFO] [Train] Iter 4070 | Loss 0.028018 | Grad 0.0332 \n","[2023-12-09 07:34:58,786::train::INFO] [Train] Iter 4071 | Loss 0.025007 | Grad 0.0366 \n","[2023-12-09 07:34:58,878::train::INFO] [Train] Iter 4072 | Loss 0.027625 | Grad 0.0380 \n","[2023-12-09 07:34:58,970::train::INFO] [Train] Iter 4073 | Loss 0.027722 | Grad 0.0418 \n","[2023-12-09 07:34:59,065::train::INFO] [Train] Iter 4074 | Loss 0.028872 | Grad 0.0342 \n","[2023-12-09 07:34:59,160::train::INFO] [Train] Iter 4075 | Loss 0.025020 | Grad 0.0345 \n","[2023-12-09 07:34:59,256::train::INFO] [Train] Iter 4076 | Loss 0.029283 | Grad 0.0345 \n","[2023-12-09 07:34:59,350::train::INFO] [Train] Iter 4077 | Loss 0.029619 | Grad 0.0339 \n","[2023-12-09 07:34:59,444::train::INFO] [Train] Iter 4078 | Loss 0.024987 | Grad 0.0372 \n","[2023-12-09 07:34:59,536::train::INFO] [Train] Iter 4079 | Loss 0.025431 | Grad 0.0386 \n","[2023-12-09 07:34:59,580::train::INFO] [Train] Iter 4080 | Loss 0.025882 | Grad 0.0851 \n","[2023-12-09 07:34:59,672::train::INFO] [Train] Iter 4081 | Loss 0.025406 | Grad 0.0304 \n","[2023-12-09 07:34:59,766::train::INFO] [Train] Iter 4082 | Loss 0.028785 | Grad 0.0387 \n","[2023-12-09 07:34:59,859::train::INFO] [Train] Iter 4083 | Loss 0.026936 | Grad 0.0451 \n","[2023-12-09 07:34:59,952::train::INFO] [Train] Iter 4084 | Loss 0.028469 | Grad 0.0374 \n","[2023-12-09 07:35:00,061::train::INFO] [Train] Iter 4085 | Loss 0.027201 | Grad 0.0359 \n","[2023-12-09 07:35:00,153::train::INFO] [Train] Iter 4086 | Loss 0.029503 | Grad 0.0349 \n","[2023-12-09 07:35:00,246::train::INFO] [Train] Iter 4087 | Loss 0.027406 | Grad 0.0390 \n","[2023-12-09 07:35:00,339::train::INFO] [Train] Iter 4088 | Loss 0.028678 | Grad 0.0276 \n","[2023-12-09 07:35:00,442::train::INFO] [Train] Iter 4089 | Loss 0.027392 | Grad 0.0377 \n","[2023-12-09 07:35:00,534::train::INFO] [Train] Iter 4090 | Loss 0.028362 | Grad 0.0359 \n","[2023-12-09 07:35:00,627::train::INFO] [Train] Iter 4091 | Loss 0.026348 | Grad 0.0386 \n","[2023-12-09 07:35:00,729::train::INFO] [Train] Iter 4092 | Loss 0.029127 | Grad 0.0325 \n","[2023-12-09 07:35:00,838::train::INFO] [Train] Iter 4093 | Loss 0.026954 | Grad 0.0393 \n","[2023-12-09 07:35:00,932::train::INFO] [Train] Iter 4094 | Loss 0.027635 | Grad 0.0356 \n","[2023-12-09 07:35:01,026::train::INFO] [Train] Iter 4095 | Loss 0.027712 | Grad 0.0270 \n","[2023-12-09 07:35:01,118::train::INFO] [Train] Iter 4096 | Loss 0.027168 | Grad 0.0288 \n","[2023-12-09 07:35:01,209::train::INFO] [Train] Iter 4097 | Loss 0.027579 | Grad 0.0448 \n","[2023-12-09 07:35:01,300::train::INFO] [Train] Iter 4098 | Loss 0.026371 | Grad 0.0326 \n","[2023-12-09 07:35:01,392::train::INFO] [Train] Iter 4099 | Loss 0.029068 | Grad 0.0271 \n","[2023-12-09 07:35:01,484::train::INFO] [Train] Iter 4100 | Loss 0.026453 | Grad 0.0383 \n","[2023-12-09 07:35:01,576::train::INFO] [Train] Iter 4101 | Loss 0.025493 | Grad 0.0368 \n","[2023-12-09 07:35:01,670::train::INFO] [Train] Iter 4102 | Loss 0.028581 | Grad 0.0336 \n","[2023-12-09 07:35:01,763::train::INFO] [Train] Iter 4103 | Loss 0.026456 | Grad 0.0451 \n","[2023-12-09 07:35:01,855::train::INFO] [Train] Iter 4104 | Loss 0.026931 | Grad 0.0444 \n","[2023-12-09 07:35:01,950::train::INFO] [Train] Iter 4105 | Loss 0.026620 | Grad 0.0263 \n","[2023-12-09 07:35:02,047::train::INFO] [Train] Iter 4106 | Loss 0.027431 | Grad 0.0417 \n","[2023-12-09 07:35:02,142::train::INFO] [Train] Iter 4107 | Loss 0.029141 | Grad 0.0363 \n","[2023-12-09 07:35:02,236::train::INFO] [Train] Iter 4108 | Loss 0.028041 | Grad 0.0346 \n","[2023-12-09 07:35:02,325::train::INFO] [Train] Iter 4109 | Loss 0.025976 | Grad 0.0377 \n","[2023-12-09 07:35:02,411::train::INFO] [Train] Iter 4110 | Loss 0.027674 | Grad 0.0322 \n","[2023-12-09 07:35:02,495::train::INFO] [Train] Iter 4111 | Loss 0.029399 | Grad 0.0394 \n","[2023-12-09 07:35:02,580::train::INFO] [Train] Iter 4112 | Loss 0.026070 | Grad 0.0267 \n","[2023-12-09 07:35:02,666::train::INFO] [Train] Iter 4113 | Loss 0.028883 | Grad 0.0401 \n","[2023-12-09 07:35:02,752::train::INFO] [Train] Iter 4114 | Loss 0.027932 | Grad 0.0429 \n","[2023-12-09 07:35:02,843::train::INFO] [Train] Iter 4115 | Loss 0.025400 | Grad 0.0287 \n","[2023-12-09 07:35:02,928::train::INFO] [Train] Iter 4116 | Loss 0.029468 | Grad 0.0336 \n","[2023-12-09 07:35:03,015::train::INFO] [Train] Iter 4117 | Loss 0.027673 | Grad 0.0313 \n","[2023-12-09 07:35:03,101::train::INFO] [Train] Iter 4118 | Loss 0.029301 | Grad 0.0319 \n","[2023-12-09 07:35:03,186::train::INFO] [Train] Iter 4119 | Loss 0.025878 | Grad 0.0240 \n","[2023-12-09 07:35:03,269::train::INFO] [Train] Iter 4120 | Loss 0.027346 | Grad 0.0314 \n","[2023-12-09 07:35:03,354::train::INFO] [Train] Iter 4121 | Loss 0.028326 | Grad 0.0328 \n","[2023-12-09 07:35:03,443::train::INFO] [Train] Iter 4122 | Loss 0.027705 | Grad 0.0275 \n","[2023-12-09 07:35:03,528::train::INFO] [Train] Iter 4123 | Loss 0.027165 | Grad 0.0299 \n","[2023-12-09 07:35:03,613::train::INFO] [Train] Iter 4124 | Loss 0.026677 | Grad 0.0306 \n","[2023-12-09 07:35:03,697::train::INFO] [Train] Iter 4125 | Loss 0.027633 | Grad 0.0276 \n","[2023-12-09 07:35:03,781::train::INFO] [Train] Iter 4126 | Loss 0.027803 | Grad 0.0327 \n","[2023-12-09 07:35:03,865::train::INFO] [Train] Iter 4127 | Loss 0.025497 | Grad 0.0257 \n","[2023-12-09 07:35:03,949::train::INFO] [Train] Iter 4128 | Loss 0.026305 | Grad 0.0327 \n","[2023-12-09 07:35:04,034::train::INFO] [Train] Iter 4129 | Loss 0.028190 | Grad 0.0320 \n","[2023-12-09 07:35:04,119::train::INFO] [Train] Iter 4130 | Loss 0.025637 | Grad 0.0311 \n","[2023-12-09 07:35:04,202::train::INFO] [Train] Iter 4131 | Loss 0.029554 | Grad 0.0378 \n","[2023-12-09 07:35:04,286::train::INFO] [Train] Iter 4132 | Loss 0.026738 | Grad 0.0271 \n","[2023-12-09 07:35:04,375::train::INFO] [Train] Iter 4133 | Loss 0.027987 | Grad 0.0320 \n","[2023-12-09 07:35:04,461::train::INFO] [Train] Iter 4134 | Loss 0.026381 | Grad 0.0361 \n","[2023-12-09 07:35:04,546::train::INFO] [Train] Iter 4135 | Loss 0.027550 | Grad 0.0291 \n","[2023-12-09 07:35:04,632::train::INFO] [Train] Iter 4136 | Loss 0.030134 | Grad 0.0522 \n","[2023-12-09 07:35:04,717::train::INFO] [Train] Iter 4137 | Loss 0.027124 | Grad 0.0317 \n","[2023-12-09 07:35:04,801::train::INFO] [Train] Iter 4138 | Loss 0.027085 | Grad 0.0350 \n","[2023-12-09 07:35:04,885::train::INFO] [Train] Iter 4139 | Loss 0.026139 | Grad 0.0362 \n","[2023-12-09 07:35:04,971::train::INFO] [Train] Iter 4140 | Loss 0.025280 | Grad 0.0364 \n","[2023-12-09 07:35:05,055::train::INFO] [Train] Iter 4141 | Loss 0.028673 | Grad 0.0332 \n","[2023-12-09 07:35:05,142::train::INFO] [Train] Iter 4142 | Loss 0.029804 | Grad 0.0372 \n","[2023-12-09 07:35:05,227::train::INFO] [Train] Iter 4143 | Loss 0.027051 | Grad 0.0341 \n","[2023-12-09 07:35:05,312::train::INFO] [Train] Iter 4144 | Loss 0.029128 | Grad 0.0312 \n","[2023-12-09 07:35:05,397::train::INFO] [Train] Iter 4145 | Loss 0.028944 | Grad 0.0321 \n","[2023-12-09 07:35:05,481::train::INFO] [Train] Iter 4146 | Loss 0.026899 | Grad 0.0512 \n","[2023-12-09 07:35:05,566::train::INFO] [Train] Iter 4147 | Loss 0.027455 | Grad 0.0304 \n","[2023-12-09 07:35:05,650::train::INFO] [Train] Iter 4148 | Loss 0.025358 | Grad 0.0285 \n","[2023-12-09 07:35:05,734::train::INFO] [Train] Iter 4149 | Loss 0.027680 | Grad 0.0326 \n","[2023-12-09 07:35:05,818::train::INFO] [Train] Iter 4150 | Loss 0.027209 | Grad 0.0346 \n","[2023-12-09 07:35:05,901::train::INFO] [Train] Iter 4151 | Loss 0.027438 | Grad 0.0278 \n","[2023-12-09 07:35:05,985::train::INFO] [Train] Iter 4152 | Loss 0.026871 | Grad 0.0399 \n","[2023-12-09 07:35:06,069::train::INFO] [Train] Iter 4153 | Loss 0.027284 | Grad 0.0370 \n","[2023-12-09 07:35:06,158::train::INFO] [Train] Iter 4154 | Loss 0.026370 | Grad 0.0315 \n","[2023-12-09 07:35:06,242::train::INFO] [Train] Iter 4155 | Loss 0.027371 | Grad 0.0360 \n","[2023-12-09 07:35:06,325::train::INFO] [Train] Iter 4156 | Loss 0.026570 | Grad 0.0366 \n","[2023-12-09 07:35:06,408::train::INFO] [Train] Iter 4157 | Loss 0.026453 | Grad 0.0307 \n","[2023-12-09 07:35:06,492::train::INFO] [Train] Iter 4158 | Loss 0.026345 | Grad 0.0378 \n","[2023-12-09 07:35:06,578::train::INFO] [Train] Iter 4159 | Loss 0.027802 | Grad 0.0349 \n","[2023-12-09 07:35:06,663::train::INFO] [Train] Iter 4160 | Loss 0.026157 | Grad 0.0394 \n","[2023-12-09 07:35:06,748::train::INFO] [Train] Iter 4161 | Loss 0.027291 | Grad 0.0448 \n","[2023-12-09 07:35:06,831::train::INFO] [Train] Iter 4162 | Loss 0.024809 | Grad 0.0324 \n","[2023-12-09 07:35:06,914::train::INFO] [Train] Iter 4163 | Loss 0.025987 | Grad 0.0387 \n","[2023-12-09 07:35:06,999::train::INFO] [Train] Iter 4164 | Loss 0.028155 | Grad 0.0358 \n","[2023-12-09 07:35:07,086::train::INFO] [Train] Iter 4165 | Loss 0.027415 | Grad 0.0321 \n","[2023-12-09 07:35:07,170::train::INFO] [Train] Iter 4166 | Loss 0.027975 | Grad 0.0424 \n","[2023-12-09 07:35:07,253::train::INFO] [Train] Iter 4167 | Loss 0.027069 | Grad 0.0377 \n","[2023-12-09 07:35:07,337::train::INFO] [Train] Iter 4168 | Loss 0.029092 | Grad 0.0326 \n","[2023-12-09 07:35:07,421::train::INFO] [Train] Iter 4169 | Loss 0.027108 | Grad 0.0342 \n","[2023-12-09 07:35:07,505::train::INFO] [Train] Iter 4170 | Loss 0.028550 | Grad 0.0457 \n","[2023-12-09 07:35:07,588::train::INFO] [Train] Iter 4171 | Loss 0.026021 | Grad 0.0316 \n","[2023-12-09 07:35:07,673::train::INFO] [Train] Iter 4172 | Loss 0.027224 | Grad 0.0304 \n","[2023-12-09 07:35:07,756::train::INFO] [Train] Iter 4173 | Loss 0.027113 | Grad 0.0295 \n","[2023-12-09 07:35:07,840::train::INFO] [Train] Iter 4174 | Loss 0.027162 | Grad 0.0532 \n","[2023-12-09 07:35:07,924::train::INFO] [Train] Iter 4175 | Loss 0.029612 | Grad 0.0288 \n","[2023-12-09 07:35:08,009::train::INFO] [Train] Iter 4176 | Loss 0.024058 | Grad 0.0327 \n","[2023-12-09 07:35:08,096::train::INFO] [Train] Iter 4177 | Loss 0.027492 | Grad 0.0325 \n","[2023-12-09 07:35:08,186::train::INFO] [Train] Iter 4178 | Loss 0.026311 | Grad 0.0334 \n","[2023-12-09 07:35:08,273::train::INFO] [Train] Iter 4179 | Loss 0.025984 | Grad 0.0292 \n","[2023-12-09 07:35:08,359::train::INFO] [Train] Iter 4180 | Loss 0.029169 | Grad 0.0327 \n","[2023-12-09 07:35:08,444::train::INFO] [Train] Iter 4181 | Loss 0.026968 | Grad 0.0273 \n","[2023-12-09 07:35:08,528::train::INFO] [Train] Iter 4182 | Loss 0.026751 | Grad 0.0293 \n","[2023-12-09 07:35:08,612::train::INFO] [Train] Iter 4183 | Loss 0.026501 | Grad 0.0301 \n","[2023-12-09 07:35:08,696::train::INFO] [Train] Iter 4184 | Loss 0.026866 | Grad 0.0294 \n","[2023-12-09 07:35:08,785::train::INFO] [Train] Iter 4185 | Loss 0.027569 | Grad 0.0330 \n","[2023-12-09 07:35:08,869::train::INFO] [Train] Iter 4186 | Loss 0.028623 | Grad 0.0334 \n","[2023-12-09 07:35:08,953::train::INFO] [Train] Iter 4187 | Loss 0.024299 | Grad 0.0302 \n","[2023-12-09 07:35:09,040::train::INFO] [Train] Iter 4188 | Loss 0.028175 | Grad 0.0284 \n","[2023-12-09 07:35:09,124::train::INFO] [Train] Iter 4189 | Loss 0.030731 | Grad 0.0410 \n","[2023-12-09 07:35:09,210::train::INFO] [Train] Iter 4190 | Loss 0.026721 | Grad 0.0316 \n","[2023-12-09 07:35:09,294::train::INFO] [Train] Iter 4191 | Loss 0.028836 | Grad 0.0286 \n","[2023-12-09 07:35:09,382::train::INFO] [Train] Iter 4192 | Loss 0.026902 | Grad 0.0396 \n","[2023-12-09 07:35:09,467::train::INFO] [Train] Iter 4193 | Loss 0.026659 | Grad 0.0327 \n","[2023-12-09 07:35:09,550::train::INFO] [Train] Iter 4194 | Loss 0.027323 | Grad 0.0360 \n","[2023-12-09 07:35:09,634::train::INFO] [Train] Iter 4195 | Loss 0.026827 | Grad 0.0381 \n","[2023-12-09 07:35:09,719::train::INFO] [Train] Iter 4196 | Loss 0.027697 | Grad 0.0471 \n","[2023-12-09 07:35:09,804::train::INFO] [Train] Iter 4197 | Loss 0.027589 | Grad 0.0266 \n","[2023-12-09 07:35:09,889::train::INFO] [Train] Iter 4198 | Loss 0.026793 | Grad 0.0435 \n","[2023-12-09 07:35:09,986::train::INFO] [Train] Iter 4199 | Loss 0.023516 | Grad 0.0267 \n","[2023-12-09 07:35:10,071::train::INFO] [Train] Iter 4200 | Loss 0.028399 | Grad 0.0344 \n","[2023-12-09 07:35:10,158::train::INFO] [Train] Iter 4201 | Loss 0.026233 | Grad 0.0305 \n","[2023-12-09 07:35:10,245::train::INFO] [Train] Iter 4202 | Loss 0.024428 | Grad 0.0305 \n","[2023-12-09 07:35:10,330::train::INFO] [Train] Iter 4203 | Loss 0.025758 | Grad 0.0314 \n","[2023-12-09 07:35:10,414::train::INFO] [Train] Iter 4204 | Loss 0.027620 | Grad 0.0399 \n","[2023-12-09 07:35:10,501::train::INFO] [Train] Iter 4205 | Loss 0.027084 | Grad 0.0327 \n","[2023-12-09 07:35:10,586::train::INFO] [Train] Iter 4206 | Loss 0.027358 | Grad 0.0316 \n","[2023-12-09 07:35:10,671::train::INFO] [Train] Iter 4207 | Loss 0.025659 | Grad 0.0274 \n","[2023-12-09 07:35:10,756::train::INFO] [Train] Iter 4208 | Loss 0.026773 | Grad 0.0325 \n","[2023-12-09 07:35:10,840::train::INFO] [Train] Iter 4209 | Loss 0.027847 | Grad 0.0334 \n","[2023-12-09 07:35:10,929::train::INFO] [Train] Iter 4210 | Loss 0.025222 | Grad 0.0382 \n","[2023-12-09 07:35:11,015::train::INFO] [Train] Iter 4211 | Loss 0.028023 | Grad 0.0396 \n","[2023-12-09 07:35:11,100::train::INFO] [Train] Iter 4212 | Loss 0.027907 | Grad 0.0377 \n","[2023-12-09 07:35:11,186::train::INFO] [Train] Iter 4213 | Loss 0.026975 | Grad 0.0319 \n","[2023-12-09 07:35:11,274::train::INFO] [Train] Iter 4214 | Loss 0.025771 | Grad 0.0391 \n","[2023-12-09 07:35:11,360::train::INFO] [Train] Iter 4215 | Loss 0.026313 | Grad 0.0287 \n","[2023-12-09 07:35:11,446::train::INFO] [Train] Iter 4216 | Loss 0.025205 | Grad 0.0405 \n","[2023-12-09 07:35:11,532::train::INFO] [Train] Iter 4217 | Loss 0.026056 | Grad 0.0340 \n","[2023-12-09 07:35:11,618::train::INFO] [Train] Iter 4218 | Loss 0.026481 | Grad 0.0444 \n","[2023-12-09 07:35:11,714::train::INFO] [Train] Iter 4219 | Loss 0.027377 | Grad 0.0478 \n","[2023-12-09 07:35:11,801::train::INFO] [Train] Iter 4220 | Loss 0.027332 | Grad 0.0365 \n","[2023-12-09 07:35:11,886::train::INFO] [Train] Iter 4221 | Loss 0.028012 | Grad 0.0454 \n","[2023-12-09 07:35:11,973::train::INFO] [Train] Iter 4222 | Loss 0.027030 | Grad 0.0349 \n","[2023-12-09 07:35:12,058::train::INFO] [Train] Iter 4223 | Loss 0.029149 | Grad 0.0293 \n","[2023-12-09 07:35:12,144::train::INFO] [Train] Iter 4224 | Loss 0.027107 | Grad 0.0382 \n","[2023-12-09 07:35:12,231::train::INFO] [Train] Iter 4225 | Loss 0.029909 | Grad 0.0340 \n","[2023-12-09 07:35:12,325::train::INFO] [Train] Iter 4226 | Loss 0.028089 | Grad 0.0332 \n","[2023-12-09 07:35:12,418::train::INFO] [Train] Iter 4227 | Loss 0.026751 | Grad 0.0318 \n","[2023-12-09 07:35:12,512::train::INFO] [Train] Iter 4228 | Loss 0.027566 | Grad 0.0302 \n","[2023-12-09 07:35:12,602::train::INFO] [Train] Iter 4229 | Loss 0.028306 | Grad 0.0298 \n","[2023-12-09 07:35:12,694::train::INFO] [Train] Iter 4230 | Loss 0.029465 | Grad 0.0358 \n","[2023-12-09 07:35:12,787::train::INFO] [Train] Iter 4231 | Loss 0.029677 | Grad 0.0362 \n","[2023-12-09 07:35:12,881::train::INFO] [Train] Iter 4232 | Loss 0.028805 | Grad 0.0417 \n","[2023-12-09 07:35:12,973::train::INFO] [Train] Iter 4233 | Loss 0.026856 | Grad 0.0269 \n","[2023-12-09 07:35:13,066::train::INFO] [Train] Iter 4234 | Loss 0.026600 | Grad 0.0504 \n","[2023-12-09 07:35:13,159::train::INFO] [Train] Iter 4235 | Loss 0.027716 | Grad 0.0390 \n","[2023-12-09 07:35:13,252::train::INFO] [Train] Iter 4236 | Loss 0.028445 | Grad 0.0300 \n","[2023-12-09 07:35:13,345::train::INFO] [Train] Iter 4237 | Loss 0.025052 | Grad 0.0352 \n","[2023-12-09 07:35:13,437::train::INFO] [Train] Iter 4238 | Loss 0.027275 | Grad 0.0361 \n","[2023-12-09 07:35:13,529::train::INFO] [Train] Iter 4239 | Loss 0.024838 | Grad 0.0359 \n","[2023-12-09 07:35:13,622::train::INFO] [Train] Iter 4240 | Loss 0.026097 | Grad 0.0314 \n","[2023-12-09 07:35:13,715::train::INFO] [Train] Iter 4241 | Loss 0.026648 | Grad 0.0289 \n","[2023-12-09 07:35:13,807::train::INFO] [Train] Iter 4242 | Loss 0.028124 | Grad 0.0321 \n","[2023-12-09 07:35:13,900::train::INFO] [Train] Iter 4243 | Loss 0.029279 | Grad 0.0549 \n","[2023-12-09 07:35:13,993::train::INFO] [Train] Iter 4244 | Loss 0.028833 | Grad 0.0444 \n","[2023-12-09 07:35:14,087::train::INFO] [Train] Iter 4245 | Loss 0.026287 | Grad 0.0331 \n","[2023-12-09 07:35:14,181::train::INFO] [Train] Iter 4246 | Loss 0.027965 | Grad 0.0421 \n","[2023-12-09 07:35:14,273::train::INFO] [Train] Iter 4247 | Loss 0.026917 | Grad 0.0358 \n","[2023-12-09 07:35:14,377::train::INFO] [Train] Iter 4248 | Loss 0.029105 | Grad 0.0596 \n","[2023-12-09 07:35:14,476::train::INFO] [Train] Iter 4249 | Loss 0.024994 | Grad 0.0352 \n","[2023-12-09 07:35:14,569::train::INFO] [Train] Iter 4250 | Loss 0.025246 | Grad 0.0402 \n","[2023-12-09 07:35:14,662::train::INFO] [Train] Iter 4251 | Loss 0.026439 | Grad 0.0357 \n","[2023-12-09 07:35:14,756::train::INFO] [Train] Iter 4252 | Loss 0.030437 | Grad 0.0356 \n","[2023-12-09 07:35:14,851::train::INFO] [Train] Iter 4253 | Loss 0.029761 | Grad 0.0595 \n","[2023-12-09 07:35:14,948::train::INFO] [Train] Iter 4254 | Loss 0.026567 | Grad 0.0373 \n","[2023-12-09 07:35:15,042::train::INFO] [Train] Iter 4255 | Loss 0.027692 | Grad 0.0325 \n","[2023-12-09 07:35:15,135::train::INFO] [Train] Iter 4256 | Loss 0.025899 | Grad 0.0319 \n","[2023-12-09 07:35:15,235::train::INFO] [Train] Iter 4257 | Loss 0.026205 | Grad 0.0328 \n","[2023-12-09 07:35:15,331::train::INFO] [Train] Iter 4258 | Loss 0.024889 | Grad 0.0398 \n","[2023-12-09 07:35:15,428::train::INFO] [Train] Iter 4259 | Loss 0.025479 | Grad 0.0374 \n","[2023-12-09 07:35:15,520::train::INFO] [Train] Iter 4260 | Loss 0.028377 | Grad 0.0326 \n","[2023-12-09 07:35:15,612::train::INFO] [Train] Iter 4261 | Loss 0.029485 | Grad 0.0406 \n","[2023-12-09 07:35:15,705::train::INFO] [Train] Iter 4262 | Loss 0.025741 | Grad 0.0283 \n","[2023-12-09 07:35:15,798::train::INFO] [Train] Iter 4263 | Loss 0.025064 | Grad 0.0315 \n","[2023-12-09 07:35:15,898::train::INFO] [Train] Iter 4264 | Loss 0.028093 | Grad 0.0389 \n","[2023-12-09 07:35:15,993::train::INFO] [Train] Iter 4265 | Loss 0.025791 | Grad 0.0326 \n","[2023-12-09 07:35:16,085::train::INFO] [Train] Iter 4266 | Loss 0.028104 | Grad 0.0300 \n","[2023-12-09 07:35:16,177::train::INFO] [Train] Iter 4267 | Loss 0.025892 | Grad 0.0270 \n","[2023-12-09 07:35:16,271::train::INFO] [Train] Iter 4268 | Loss 0.028488 | Grad 0.0268 \n","[2023-12-09 07:35:16,362::train::INFO] [Train] Iter 4269 | Loss 0.027431 | Grad 0.0388 \n","[2023-12-09 07:35:16,460::train::INFO] [Train] Iter 4270 | Loss 0.028279 | Grad 0.0288 \n","[2023-12-09 07:35:16,551::train::INFO] [Train] Iter 4271 | Loss 0.028269 | Grad 0.0334 \n","[2023-12-09 07:35:16,642::train::INFO] [Train] Iter 4272 | Loss 0.026298 | Grad 0.0408 \n","[2023-12-09 07:35:16,735::train::INFO] [Train] Iter 4273 | Loss 0.026499 | Grad 0.0339 \n","[2023-12-09 07:35:16,828::train::INFO] [Train] Iter 4274 | Loss 0.026769 | Grad 0.0261 \n","[2023-12-09 07:35:16,922::train::INFO] [Train] Iter 4275 | Loss 0.028560 | Grad 0.0290 \n","[2023-12-09 07:35:17,017::train::INFO] [Train] Iter 4276 | Loss 0.028806 | Grad 0.0287 \n","[2023-12-09 07:35:17,110::train::INFO] [Train] Iter 4277 | Loss 0.026670 | Grad 0.0481 \n","[2023-12-09 07:35:17,204::train::INFO] [Train] Iter 4278 | Loss 0.026108 | Grad 0.0356 \n","[2023-12-09 07:35:17,303::train::INFO] [Train] Iter 4279 | Loss 0.028397 | Grad 0.0295 \n","[2023-12-09 07:35:17,399::train::INFO] [Train] Iter 4280 | Loss 0.024972 | Grad 0.0319 \n","[2023-12-09 07:35:17,494::train::INFO] [Train] Iter 4281 | Loss 0.025781 | Grad 0.0284 \n","[2023-12-09 07:35:17,587::train::INFO] [Train] Iter 4282 | Loss 0.027449 | Grad 0.0316 \n","[2023-12-09 07:35:17,686::train::INFO] [Train] Iter 4283 | Loss 0.028520 | Grad 0.0331 \n","[2023-12-09 07:35:17,781::train::INFO] [Train] Iter 4284 | Loss 0.027001 | Grad 0.0364 \n","[2023-12-09 07:35:17,875::train::INFO] [Train] Iter 4285 | Loss 0.026015 | Grad 0.0375 \n","[2023-12-09 07:35:17,967::train::INFO] [Train] Iter 4286 | Loss 0.026741 | Grad 0.0270 \n","[2023-12-09 07:35:18,060::train::INFO] [Train] Iter 4287 | Loss 0.026772 | Grad 0.0293 \n","[2023-12-09 07:35:18,155::train::INFO] [Train] Iter 4288 | Loss 0.026683 | Grad 0.0377 \n","[2023-12-09 07:35:18,248::train::INFO] [Train] Iter 4289 | Loss 0.025767 | Grad 0.0326 \n","[2023-12-09 07:35:18,340::train::INFO] [Train] Iter 4290 | Loss 0.028856 | Grad 0.0361 \n","[2023-12-09 07:35:18,437::train::INFO] [Train] Iter 4291 | Loss 0.028365 | Grad 0.0307 \n","[2023-12-09 07:35:18,531::train::INFO] [Train] Iter 4292 | Loss 0.026555 | Grad 0.0360 \n","[2023-12-09 07:35:18,629::train::INFO] [Train] Iter 4293 | Loss 0.027362 | Grad 0.0334 \n","[2023-12-09 07:35:18,719::train::INFO] [Train] Iter 4294 | Loss 0.027952 | Grad 0.0314 \n","[2023-12-09 07:35:18,811::train::INFO] [Train] Iter 4295 | Loss 0.025832 | Grad 0.0366 \n","[2023-12-09 07:35:18,896::train::INFO] [Train] Iter 4296 | Loss 0.028856 | Grad 0.0278 \n","[2023-12-09 07:35:18,980::train::INFO] [Train] Iter 4297 | Loss 0.026124 | Grad 0.0305 \n","[2023-12-09 07:35:19,067::train::INFO] [Train] Iter 4298 | Loss 0.029953 | Grad 0.0272 \n","[2023-12-09 07:35:19,152::train::INFO] [Train] Iter 4299 | Loss 0.026423 | Grad 0.0255 \n","[2023-12-09 07:35:19,237::train::INFO] [Train] Iter 4300 | Loss 0.027892 | Grad 0.0276 \n","[2023-12-09 07:35:19,321::train::INFO] [Train] Iter 4301 | Loss 0.026635 | Grad 0.0322 \n","[2023-12-09 07:35:19,405::train::INFO] [Train] Iter 4302 | Loss 0.026195 | Grad 0.0253 \n","[2023-12-09 07:35:19,489::train::INFO] [Train] Iter 4303 | Loss 0.026754 | Grad 0.0378 \n","[2023-12-09 07:35:19,575::train::INFO] [Train] Iter 4304 | Loss 0.027757 | Grad 0.0488 \n","[2023-12-09 07:35:19,663::train::INFO] [Train] Iter 4305 | Loss 0.026822 | Grad 0.0383 \n","[2023-12-09 07:35:19,747::train::INFO] [Train] Iter 4306 | Loss 0.027887 | Grad 0.0315 \n","[2023-12-09 07:35:19,831::train::INFO] [Train] Iter 4307 | Loss 0.027777 | Grad 0.0255 \n","[2023-12-09 07:35:19,918::train::INFO] [Train] Iter 4308 | Loss 0.025047 | Grad 0.0247 \n","[2023-12-09 07:35:20,002::train::INFO] [Train] Iter 4309 | Loss 0.028425 | Grad 0.0378 \n","[2023-12-09 07:35:20,086::train::INFO] [Train] Iter 4310 | Loss 0.025265 | Grad 0.0292 \n","[2023-12-09 07:35:20,175::train::INFO] [Train] Iter 4311 | Loss 0.027933 | Grad 0.0317 \n","[2023-12-09 07:35:20,259::train::INFO] [Train] Iter 4312 | Loss 0.026910 | Grad 0.0289 \n","[2023-12-09 07:35:20,344::train::INFO] [Train] Iter 4313 | Loss 0.029121 | Grad 0.0281 \n","[2023-12-09 07:35:20,428::train::INFO] [Train] Iter 4314 | Loss 0.027008 | Grad 0.0323 \n","[2023-12-09 07:35:20,512::train::INFO] [Train] Iter 4315 | Loss 0.027277 | Grad 0.0322 \n","[2023-12-09 07:35:20,597::train::INFO] [Train] Iter 4316 | Loss 0.027192 | Grad 0.0328 \n","[2023-12-09 07:35:20,684::train::INFO] [Train] Iter 4317 | Loss 0.026995 | Grad 0.0373 \n","[2023-12-09 07:35:20,770::train::INFO] [Train] Iter 4318 | Loss 0.025579 | Grad 0.0297 \n","[2023-12-09 07:35:20,855::train::INFO] [Train] Iter 4319 | Loss 0.026543 | Grad 0.0292 \n","[2023-12-09 07:35:20,940::train::INFO] [Train] Iter 4320 | Loss 0.026928 | Grad 0.0242 \n","[2023-12-09 07:35:21,024::train::INFO] [Train] Iter 4321 | Loss 0.027481 | Grad 0.0404 \n","[2023-12-09 07:35:21,109::train::INFO] [Train] Iter 4322 | Loss 0.026195 | Grad 0.0315 \n","[2023-12-09 07:35:21,195::train::INFO] [Train] Iter 4323 | Loss 0.027153 | Grad 0.0301 \n","[2023-12-09 07:35:21,278::train::INFO] [Train] Iter 4324 | Loss 0.028855 | Grad 0.0335 \n","[2023-12-09 07:35:21,367::train::INFO] [Train] Iter 4325 | Loss 0.028297 | Grad 0.0318 \n","[2023-12-09 07:35:21,451::train::INFO] [Train] Iter 4326 | Loss 0.026192 | Grad 0.0329 \n","[2023-12-09 07:35:21,536::train::INFO] [Train] Iter 4327 | Loss 0.024473 | Grad 0.0319 \n","[2023-12-09 07:35:21,624::train::INFO] [Train] Iter 4328 | Loss 0.027053 | Grad 0.0272 \n","[2023-12-09 07:35:21,708::train::INFO] [Train] Iter 4329 | Loss 0.024658 | Grad 0.0284 \n","[2023-12-09 07:35:21,792::train::INFO] [Train] Iter 4330 | Loss 0.024405 | Grad 0.0349 \n","[2023-12-09 07:35:21,878::train::INFO] [Train] Iter 4331 | Loss 0.026498 | Grad 0.0324 \n","[2023-12-09 07:35:21,965::train::INFO] [Train] Iter 4332 | Loss 0.026167 | Grad 0.0302 \n","[2023-12-09 07:35:22,049::train::INFO] [Train] Iter 4333 | Loss 0.028333 | Grad 0.0345 \n","[2023-12-09 07:35:22,135::train::INFO] [Train] Iter 4334 | Loss 0.026165 | Grad 0.0308 \n","[2023-12-09 07:35:22,220::train::INFO] [Train] Iter 4335 | Loss 0.026013 | Grad 0.0403 \n","[2023-12-09 07:35:22,309::train::INFO] [Train] Iter 4336 | Loss 0.025712 | Grad 0.0416 \n","[2023-12-09 07:35:22,393::train::INFO] [Train] Iter 4337 | Loss 0.027833 | Grad 0.0318 \n","[2023-12-09 07:35:22,480::train::INFO] [Train] Iter 4338 | Loss 0.026982 | Grad 0.0277 \n","[2023-12-09 07:35:22,565::train::INFO] [Train] Iter 4339 | Loss 0.029030 | Grad 0.0384 \n","[2023-12-09 07:35:22,650::train::INFO] [Train] Iter 4340 | Loss 0.028583 | Grad 0.0341 \n","[2023-12-09 07:35:22,735::train::INFO] [Train] Iter 4341 | Loss 0.027302 | Grad 0.0302 \n","[2023-12-09 07:35:22,820::train::INFO] [Train] Iter 4342 | Loss 0.028592 | Grad 0.0288 \n","[2023-12-09 07:35:22,906::train::INFO] [Train] Iter 4343 | Loss 0.025327 | Grad 0.0278 \n","[2023-12-09 07:35:22,992::train::INFO] [Train] Iter 4344 | Loss 0.026672 | Grad 0.0354 \n","[2023-12-09 07:35:23,080::train::INFO] [Train] Iter 4345 | Loss 0.027217 | Grad 0.0281 \n","[2023-12-09 07:35:23,165::train::INFO] [Train] Iter 4346 | Loss 0.029175 | Grad 0.0265 \n","[2023-12-09 07:35:23,248::train::INFO] [Train] Iter 4347 | Loss 0.027490 | Grad 0.0302 \n","[2023-12-09 07:35:23,334::train::INFO] [Train] Iter 4348 | Loss 0.027353 | Grad 0.0307 \n","[2023-12-09 07:35:23,418::train::INFO] [Train] Iter 4349 | Loss 0.025753 | Grad 0.0353 \n","[2023-12-09 07:35:23,504::train::INFO] [Train] Iter 4350 | Loss 0.028753 | Grad 0.0320 \n","[2023-12-09 07:35:23,590::train::INFO] [Train] Iter 4351 | Loss 0.028297 | Grad 0.0394 \n","[2023-12-09 07:35:23,676::train::INFO] [Train] Iter 4352 | Loss 0.024788 | Grad 0.0312 \n","[2023-12-09 07:35:23,761::train::INFO] [Train] Iter 4353 | Loss 0.025033 | Grad 0.0283 \n","[2023-12-09 07:35:23,851::train::INFO] [Train] Iter 4354 | Loss 0.026438 | Grad 0.0299 \n","[2023-12-09 07:35:23,936::train::INFO] [Train] Iter 4355 | Loss 0.025071 | Grad 0.0375 \n","[2023-12-09 07:35:24,021::train::INFO] [Train] Iter 4356 | Loss 0.026357 | Grad 0.0334 \n","[2023-12-09 07:35:24,105::train::INFO] [Train] Iter 4357 | Loss 0.026725 | Grad 0.0297 \n","[2023-12-09 07:35:24,190::train::INFO] [Train] Iter 4358 | Loss 0.026004 | Grad 0.0335 \n","[2023-12-09 07:35:24,276::train::INFO] [Train] Iter 4359 | Loss 0.027704 | Grad 0.0413 \n","[2023-12-09 07:35:24,363::train::INFO] [Train] Iter 4360 | Loss 0.026165 | Grad 0.0360 \n","[2023-12-09 07:35:24,447::train::INFO] [Train] Iter 4361 | Loss 0.027598 | Grad 0.0440 \n","[2023-12-09 07:35:24,531::train::INFO] [Train] Iter 4362 | Loss 0.026218 | Grad 0.0397 \n","[2023-12-09 07:35:24,615::train::INFO] [Train] Iter 4363 | Loss 0.025428 | Grad 0.0371 \n","[2023-12-09 07:35:24,703::train::INFO] [Train] Iter 4364 | Loss 0.028215 | Grad 0.0314 \n","[2023-12-09 07:35:24,789::train::INFO] [Train] Iter 4365 | Loss 0.025445 | Grad 0.0364 \n","[2023-12-09 07:35:24,874::train::INFO] [Train] Iter 4366 | Loss 0.025933 | Grad 0.0338 \n","[2023-12-09 07:35:24,963::train::INFO] [Train] Iter 4367 | Loss 0.025304 | Grad 0.0343 \n","[2023-12-09 07:35:25,048::train::INFO] [Train] Iter 4368 | Loss 0.027827 | Grad 0.0384 \n","[2023-12-09 07:35:25,133::train::INFO] [Train] Iter 4369 | Loss 0.026070 | Grad 0.0453 \n","[2023-12-09 07:35:25,218::train::INFO] [Train] Iter 4370 | Loss 0.027157 | Grad 0.0424 \n","[2023-12-09 07:35:25,306::train::INFO] [Train] Iter 4371 | Loss 0.025419 | Grad 0.0388 \n","[2023-12-09 07:35:25,392::train::INFO] [Train] Iter 4372 | Loss 0.026970 | Grad 0.0333 \n","[2023-12-09 07:35:25,477::train::INFO] [Train] Iter 4373 | Loss 0.026478 | Grad 0.0403 \n","[2023-12-09 07:35:25,564::train::INFO] [Train] Iter 4374 | Loss 0.029094 | Grad 0.0423 \n","[2023-12-09 07:35:25,649::train::INFO] [Train] Iter 4375 | Loss 0.027167 | Grad 0.0312 \n","[2023-12-09 07:35:25,734::train::INFO] [Train] Iter 4376 | Loss 0.031084 | Grad 0.0386 \n","[2023-12-09 07:35:25,820::train::INFO] [Train] Iter 4377 | Loss 0.028156 | Grad 0.0350 \n","[2023-12-09 07:35:25,908::train::INFO] [Train] Iter 4378 | Loss 0.023741 | Grad 0.0378 \n","[2023-12-09 07:35:25,991::train::INFO] [Train] Iter 4379 | Loss 0.029622 | Grad 0.0338 \n","[2023-12-09 07:35:26,076::train::INFO] [Train] Iter 4380 | Loss 0.027207 | Grad 0.0314 \n","[2023-12-09 07:35:26,160::train::INFO] [Train] Iter 4381 | Loss 0.024579 | Grad 0.0481 \n","[2023-12-09 07:35:26,244::train::INFO] [Train] Iter 4382 | Loss 0.028125 | Grad 0.0285 \n","[2023-12-09 07:35:26,329::train::INFO] [Train] Iter 4383 | Loss 0.026312 | Grad 0.0340 \n","[2023-12-09 07:35:26,418::train::INFO] [Train] Iter 4384 | Loss 0.027071 | Grad 0.0306 \n","[2023-12-09 07:35:26,503::train::INFO] [Train] Iter 4385 | Loss 0.027756 | Grad 0.0332 \n","[2023-12-09 07:35:26,587::train::INFO] [Train] Iter 4386 | Loss 0.027428 | Grad 0.0306 \n","[2023-12-09 07:35:26,671::train::INFO] [Train] Iter 4387 | Loss 0.026795 | Grad 0.0303 \n","[2023-12-09 07:35:26,758::train::INFO] [Train] Iter 4388 | Loss 0.023382 | Grad 0.0316 \n","[2023-12-09 07:35:26,843::train::INFO] [Train] Iter 4389 | Loss 0.027350 | Grad 0.0336 \n","[2023-12-09 07:35:26,930::train::INFO] [Train] Iter 4390 | Loss 0.028260 | Grad 0.0326 \n","[2023-12-09 07:35:27,015::train::INFO] [Train] Iter 4391 | Loss 0.026510 | Grad 0.0307 \n","[2023-12-09 07:35:27,101::train::INFO] [Train] Iter 4392 | Loss 0.026869 | Grad 0.0329 \n","[2023-12-09 07:35:27,187::train::INFO] [Train] Iter 4393 | Loss 0.027790 | Grad 0.0538 \n","[2023-12-09 07:35:27,271::train::INFO] [Train] Iter 4394 | Loss 0.027413 | Grad 0.0260 \n","[2023-12-09 07:35:27,356::train::INFO] [Train] Iter 4395 | Loss 0.026022 | Grad 0.0304 \n","[2023-12-09 07:35:27,440::train::INFO] [Train] Iter 4396 | Loss 0.026661 | Grad 0.0317 \n","[2023-12-09 07:35:27,526::train::INFO] [Train] Iter 4397 | Loss 0.029118 | Grad 0.0426 \n","[2023-12-09 07:35:27,609::train::INFO] [Train] Iter 4398 | Loss 0.026993 | Grad 0.0318 \n","[2023-12-09 07:35:27,695::train::INFO] [Train] Iter 4399 | Loss 0.027331 | Grad 0.0382 \n","[2023-12-09 07:35:27,780::train::INFO] [Train] Iter 4400 | Loss 0.027702 | Grad 0.0302 \n","[2023-12-09 07:35:27,864::train::INFO] [Train] Iter 4401 | Loss 0.024917 | Grad 0.0324 \n","[2023-12-09 07:35:27,948::train::INFO] [Train] Iter 4402 | Loss 0.029390 | Grad 0.0394 \n","[2023-12-09 07:35:28,032::train::INFO] [Train] Iter 4403 | Loss 0.027419 | Grad 0.0313 \n","[2023-12-09 07:35:28,119::train::INFO] [Train] Iter 4404 | Loss 0.025056 | Grad 0.0318 \n","[2023-12-09 07:35:28,202::train::INFO] [Train] Iter 4405 | Loss 0.027594 | Grad 0.0345 \n","[2023-12-09 07:35:28,285::train::INFO] [Train] Iter 4406 | Loss 0.029647 | Grad 0.0703 \n","[2023-12-09 07:35:28,369::train::INFO] [Train] Iter 4407 | Loss 0.026532 | Grad 0.0339 \n","[2023-12-09 07:35:28,452::train::INFO] [Train] Iter 4408 | Loss 0.028070 | Grad 0.0387 \n","[2023-12-09 07:35:28,535::train::INFO] [Train] Iter 4409 | Loss 0.027352 | Grad 0.0430 \n","[2023-12-09 07:35:28,617::train::INFO] [Train] Iter 4410 | Loss 0.027731 | Grad 0.0354 \n","[2023-12-09 07:35:28,700::train::INFO] [Train] Iter 4411 | Loss 0.024761 | Grad 0.0360 \n","[2023-12-09 07:35:28,784::train::INFO] [Train] Iter 4412 | Loss 0.027318 | Grad 0.0363 \n","[2023-12-09 07:35:28,874::train::INFO] [Train] Iter 4413 | Loss 0.027456 | Grad 0.0417 \n","[2023-12-09 07:35:28,962::train::INFO] [Train] Iter 4414 | Loss 0.028593 | Grad 0.0349 \n","[2023-12-09 07:35:29,052::train::INFO] [Train] Iter 4415 | Loss 0.024664 | Grad 0.0330 \n","[2023-12-09 07:35:29,142::train::INFO] [Train] Iter 4416 | Loss 0.029034 | Grad 0.0312 \n","[2023-12-09 07:35:29,232::train::INFO] [Train] Iter 4417 | Loss 0.029392 | Grad 0.0299 \n","[2023-12-09 07:35:29,323::train::INFO] [Train] Iter 4418 | Loss 0.024719 | Grad 0.0370 \n","[2023-12-09 07:35:29,413::train::INFO] [Train] Iter 4419 | Loss 0.025103 | Grad 0.0360 \n","[2023-12-09 07:35:29,454::train::INFO] [Train] Iter 4420 | Loss 0.025432 | Grad 0.0784 \n","[2023-12-09 07:35:29,543::train::INFO] [Train] Iter 4421 | Loss 0.025073 | Grad 0.0293 \n","[2023-12-09 07:35:29,634::train::INFO] [Train] Iter 4422 | Loss 0.028626 | Grad 0.0389 \n","[2023-12-09 07:35:29,732::train::INFO] [Train] Iter 4423 | Loss 0.026564 | Grad 0.0415 \n","[2023-12-09 07:35:29,825::train::INFO] [Train] Iter 4424 | Loss 0.028264 | Grad 0.0363 \n","[2023-12-09 07:35:29,914::train::INFO] [Train] Iter 4425 | Loss 0.026883 | Grad 0.0321 \n","[2023-12-09 07:35:30,003::train::INFO] [Train] Iter 4426 | Loss 0.029220 | Grad 0.0342 \n","[2023-12-09 07:35:30,094::train::INFO] [Train] Iter 4427 | Loss 0.027092 | Grad 0.0360 \n","[2023-12-09 07:35:30,184::train::INFO] [Train] Iter 4428 | Loss 0.028373 | Grad 0.0279 \n","[2023-12-09 07:35:30,275::train::INFO] [Train] Iter 4429 | Loss 0.027057 | Grad 0.0346 \n","[2023-12-09 07:35:30,376::train::INFO] [Train] Iter 4430 | Loss 0.028097 | Grad 0.0332 \n","[2023-12-09 07:35:30,467::train::INFO] [Train] Iter 4431 | Loss 0.026076 | Grad 0.0353 \n","[2023-12-09 07:35:30,557::train::INFO] [Train] Iter 4432 | Loss 0.028813 | Grad 0.0293 \n","[2023-12-09 07:35:30,656::train::INFO] [Train] Iter 4433 | Loss 0.026645 | Grad 0.0348 \n","[2023-12-09 07:35:30,747::train::INFO] [Train] Iter 4434 | Loss 0.027369 | Grad 0.0328 \n","[2023-12-09 07:35:30,844::train::INFO] [Train] Iter 4435 | Loss 0.027371 | Grad 0.0249 \n","[2023-12-09 07:35:30,934::train::INFO] [Train] Iter 4436 | Loss 0.026872 | Grad 0.0267 \n","[2023-12-09 07:35:31,026::train::INFO] [Train] Iter 4437 | Loss 0.027321 | Grad 0.0391 \n","[2023-12-09 07:35:31,117::train::INFO] [Train] Iter 4438 | Loss 0.026048 | Grad 0.0308 \n","[2023-12-09 07:35:31,206::train::INFO] [Train] Iter 4439 | Loss 0.028796 | Grad 0.0247 \n","[2023-12-09 07:35:31,297::train::INFO] [Train] Iter 4440 | Loss 0.026133 | Grad 0.0342 \n","[2023-12-09 07:35:31,392::train::INFO] [Train] Iter 4441 | Loss 0.025229 | Grad 0.0316 \n","[2023-12-09 07:35:31,486::train::INFO] [Train] Iter 4442 | Loss 0.028398 | Grad 0.0315 \n","[2023-12-09 07:35:31,577::train::INFO] [Train] Iter 4443 | Loss 0.026175 | Grad 0.0460 \n","[2023-12-09 07:35:31,668::train::INFO] [Train] Iter 4444 | Loss 0.026639 | Grad 0.0427 \n","[2023-12-09 07:35:31,760::train::INFO] [Train] Iter 4445 | Loss 0.026388 | Grad 0.0265 \n","[2023-12-09 07:35:31,851::train::INFO] [Train] Iter 4446 | Loss 0.027101 | Grad 0.0425 \n","[2023-12-09 07:35:31,950::train::INFO] [Train] Iter 4447 | Loss 0.028866 | Grad 0.0315 \n","[2023-12-09 07:35:32,042::train::INFO] [Train] Iter 4448 | Loss 0.027797 | Grad 0.0327 \n","[2023-12-09 07:35:32,134::train::INFO] [Train] Iter 4449 | Loss 0.025666 | Grad 0.0344 \n","[2023-12-09 07:35:32,226::train::INFO] [Train] Iter 4450 | Loss 0.027488 | Grad 0.0318 \n","[2023-12-09 07:35:32,324::train::INFO] [Train] Iter 4451 | Loss 0.029193 | Grad 0.0384 \n","[2023-12-09 07:35:32,413::train::INFO] [Train] Iter 4452 | Loss 0.025879 | Grad 0.0276 \n","[2023-12-09 07:35:32,504::train::INFO] [Train] Iter 4453 | Loss 0.028585 | Grad 0.0353 \n","[2023-12-09 07:35:32,593::train::INFO] [Train] Iter 4454 | Loss 0.027566 | Grad 0.0394 \n","[2023-12-09 07:35:32,682::train::INFO] [Train] Iter 4455 | Loss 0.025157 | Grad 0.0269 \n","[2023-12-09 07:35:32,773::train::INFO] [Train] Iter 4456 | Loss 0.029208 | Grad 0.0343 \n","[2023-12-09 07:35:32,872::train::INFO] [Train] Iter 4457 | Loss 0.027484 | Grad 0.0298 \n","[2023-12-09 07:35:32,973::train::INFO] [Train] Iter 4458 | Loss 0.029132 | Grad 0.0305 \n","[2023-12-09 07:35:33,064::train::INFO] [Train] Iter 4459 | Loss 0.025695 | Grad 0.0279 \n","[2023-12-09 07:35:33,164::train::INFO] [Train] Iter 4460 | Loss 0.027122 | Grad 0.0289 \n","[2023-12-09 07:35:33,255::train::INFO] [Train] Iter 4461 | Loss 0.028098 | Grad 0.0307 \n","[2023-12-09 07:35:33,347::train::INFO] [Train] Iter 4462 | Loss 0.027527 | Grad 0.0290 \n","[2023-12-09 07:35:33,439::train::INFO] [Train] Iter 4463 | Loss 0.026906 | Grad 0.0278 \n","[2023-12-09 07:35:33,531::train::INFO] [Train] Iter 4464 | Loss 0.026444 | Grad 0.0290 \n","[2023-12-09 07:35:33,623::train::INFO] [Train] Iter 4465 | Loss 0.027390 | Grad 0.0254 \n","[2023-12-09 07:35:33,715::train::INFO] [Train] Iter 4466 | Loss 0.027501 | Grad 0.0284 \n","[2023-12-09 07:35:33,811::train::INFO] [Train] Iter 4467 | Loss 0.025219 | Grad 0.0290 \n","[2023-12-09 07:35:33,905::train::INFO] [Train] Iter 4468 | Loss 0.026063 | Grad 0.0323 \n","[2023-12-09 07:35:34,003::train::INFO] [Train] Iter 4469 | Loss 0.027962 | Grad 0.0316 \n","[2023-12-09 07:35:34,096::train::INFO] [Train] Iter 4470 | Loss 0.025295 | Grad 0.0295 \n","[2023-12-09 07:35:34,187::train::INFO] [Train] Iter 4471 | Loss 0.029357 | Grad 0.0387 \n","[2023-12-09 07:35:34,278::train::INFO] [Train] Iter 4472 | Loss 0.026451 | Grad 0.0277 \n","[2023-12-09 07:35:34,371::train::INFO] [Train] Iter 4473 | Loss 0.027913 | Grad 0.0337 \n","[2023-12-09 07:35:34,465::train::INFO] [Train] Iter 4474 | Loss 0.026108 | Grad 0.0331 \n","[2023-12-09 07:35:34,558::train::INFO] [Train] Iter 4475 | Loss 0.027284 | Grad 0.0304 \n","[2023-12-09 07:35:34,648::train::INFO] [Train] Iter 4476 | Loss 0.029861 | Grad 0.0468 \n","[2023-12-09 07:35:34,738::train::INFO] [Train] Iter 4477 | Loss 0.026982 | Grad 0.0296 \n","[2023-12-09 07:35:34,830::train::INFO] [Train] Iter 4478 | Loss 0.026816 | Grad 0.0287 \n","[2023-12-09 07:35:34,922::train::INFO] [Train] Iter 4479 | Loss 0.025849 | Grad 0.0329 \n","[2023-12-09 07:35:35,020::train::INFO] [Train] Iter 4480 | Loss 0.025037 | Grad 0.0350 \n","[2023-12-09 07:35:35,113::train::INFO] [Train] Iter 4481 | Loss 0.028376 | Grad 0.0261 \n","[2023-12-09 07:35:35,198::train::INFO] [Train] Iter 4482 | Loss 0.029510 | Grad 0.0327 \n","[2023-12-09 07:35:35,282::train::INFO] [Train] Iter 4483 | Loss 0.026829 | Grad 0.0339 \n","[2023-12-09 07:35:35,375::train::INFO] [Train] Iter 4484 | Loss 0.028871 | Grad 0.0247 \n","[2023-12-09 07:35:35,458::train::INFO] [Train] Iter 4485 | Loss 0.028670 | Grad 0.0303 \n","[2023-12-09 07:35:35,542::train::INFO] [Train] Iter 4486 | Loss 0.026663 | Grad 0.0481 \n","[2023-12-09 07:35:35,625::train::INFO] [Train] Iter 4487 | Loss 0.027208 | Grad 0.0306 \n","[2023-12-09 07:35:35,709::train::INFO] [Train] Iter 4488 | Loss 0.025083 | Grad 0.0261 \n","[2023-12-09 07:35:35,796::train::INFO] [Train] Iter 4489 | Loss 0.027478 | Grad 0.0314 \n","[2023-12-09 07:35:35,880::train::INFO] [Train] Iter 4490 | Loss 0.026986 | Grad 0.0311 \n","[2023-12-09 07:35:35,963::train::INFO] [Train] Iter 4491 | Loss 0.027179 | Grad 0.0268 \n","[2023-12-09 07:35:36,047::train::INFO] [Train] Iter 4492 | Loss 0.026666 | Grad 0.0392 \n","[2023-12-09 07:35:36,132::train::INFO] [Train] Iter 4493 | Loss 0.027097 | Grad 0.0357 \n","[2023-12-09 07:35:36,215::train::INFO] [Train] Iter 4494 | Loss 0.026127 | Grad 0.0311 \n","[2023-12-09 07:35:36,307::train::INFO] [Train] Iter 4495 | Loss 0.027067 | Grad 0.0329 \n","[2023-12-09 07:35:36,393::train::INFO] [Train] Iter 4496 | Loss 0.026360 | Grad 0.0318 \n","[2023-12-09 07:35:36,477::train::INFO] [Train] Iter 4497 | Loss 0.026199 | Grad 0.0304 \n","[2023-12-09 07:35:36,560::train::INFO] [Train] Iter 4498 | Loss 0.026079 | Grad 0.0354 \n","[2023-12-09 07:35:36,645::train::INFO] [Train] Iter 4499 | Loss 0.027608 | Grad 0.0298 \n","[2023-12-09 07:35:36,729::train::INFO] [Train] Iter 4500 | Loss 0.025943 | Grad 0.0389 \n","Validate: 100% 241/241 [00:03<00:00, 61.65it/s]\n","val loss list [tensor(0.0293, device='cuda:0'), tensor(0.0249, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0230, device='cuda:0'), tensor(0.0211, device='cuda:0'), tensor(0.0238, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0235, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0239, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0233, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0238, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0231, device='cuda:0'), tensor(0.0312, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0231, device='cuda:0'), tensor(0.0298, device='cuda:0'), tensor(0.0243, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0249, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0248, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0227, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0247, device='cuda:0'), tensor(0.0243, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0267, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0328, device='cuda:0'), tensor(0.0320, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0223, device='cuda:0'), tensor(0.0241, device='cuda:0'), tensor(0.0256, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0249, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0251, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0309, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0267, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0333, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0306, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0307, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0313, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0240, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0234, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0237, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0242, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0230, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0237, device='cuda:0'), tensor(0.0248, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0214, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0245, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0243, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0192, device='cuda:0'), tensor(0.0241, device='cuda:0'), tensor(0.0301, device='cuda:0'), tensor(0.0211, device='cuda:0'), tensor(0.0327, device='cuda:0'), tensor(0.0239, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0242, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0237, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0246, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0285, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0237, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0258, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0246, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0319, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0231, device='cuda:0'), tensor(0.0295, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0258, device='cuda:0'), tensor(0.0246, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0244, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0292, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0326, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0241, device='cuda:0'), tensor(0.0323, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0248, device='cuda:0'), tensor(0.0245, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0319, device='cuda:0'), tensor(0.0244, device='cuda:0'), tensor(0.0237, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0317, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0239, device='cuda:0'), tensor(0.0225, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0229, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0242, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0312, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0251, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0234, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0179, device='cuda:0'), tensor(0.0246, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0302, device='cuda:0'), tensor(0.0299, device='cuda:0'), tensor(0.0196, device='cuda:0'), tensor(0.0233, device='cuda:0'), tensor(0.0247, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0322, device='cuda:0')]\n","[2023-12-09 07:35:40,906::train::INFO] [Train] Iter 4501 | Loss 0.027037 | Grad 0.0396 \n","[2023-12-09 07:35:40,992::train::INFO] [Train] Iter 4502 | Loss 0.024480 | Grad 0.0299 \n","[2023-12-09 07:35:41,077::train::INFO] [Train] Iter 4503 | Loss 0.025701 | Grad 0.0324 \n","[2023-12-09 07:35:41,162::train::INFO] [Train] Iter 4504 | Loss 0.027898 | Grad 0.0331 \n","[2023-12-09 07:35:41,246::train::INFO] [Train] Iter 4505 | Loss 0.027030 | Grad 0.0298 \n","[2023-12-09 07:35:41,331::train::INFO] [Train] Iter 4506 | Loss 0.027799 | Grad 0.0419 \n","[2023-12-09 07:35:41,416::train::INFO] [Train] Iter 4507 | Loss 0.026795 | Grad 0.0339 \n","[2023-12-09 07:35:41,503::train::INFO] [Train] Iter 4508 | Loss 0.028845 | Grad 0.0289 \n","[2023-12-09 07:35:41,588::train::INFO] [Train] Iter 4509 | Loss 0.026791 | Grad 0.0310 \n","[2023-12-09 07:35:41,674::train::INFO] [Train] Iter 4510 | Loss 0.028251 | Grad 0.0433 \n","[2023-12-09 07:35:41,760::train::INFO] [Train] Iter 4511 | Loss 0.025698 | Grad 0.0276 \n","[2023-12-09 07:35:41,846::train::INFO] [Train] Iter 4512 | Loss 0.026919 | Grad 0.0269 \n","[2023-12-09 07:35:41,930::train::INFO] [Train] Iter 4513 | Loss 0.026863 | Grad 0.0308 \n","[2023-12-09 07:35:42,017::train::INFO] [Train] Iter 4514 | Loss 0.026830 | Grad 0.0481 \n","[2023-12-09 07:35:42,105::train::INFO] [Train] Iter 4515 | Loss 0.029313 | Grad 0.0262 \n","[2023-12-09 07:35:42,191::train::INFO] [Train] Iter 4516 | Loss 0.023800 | Grad 0.0290 \n","[2023-12-09 07:35:42,275::train::INFO] [Train] Iter 4517 | Loss 0.027288 | Grad 0.0299 \n","[2023-12-09 07:35:42,361::train::INFO] [Train] Iter 4518 | Loss 0.026067 | Grad 0.0330 \n","[2023-12-09 07:35:42,446::train::INFO] [Train] Iter 4519 | Loss 0.025734 | Grad 0.0285 \n","[2023-12-09 07:35:42,531::train::INFO] [Train] Iter 4520 | Loss 0.028932 | Grad 0.0292 \n","[2023-12-09 07:35:42,616::train::INFO] [Train] Iter 4521 | Loss 0.026687 | Grad 0.0260 \n","[2023-12-09 07:35:42,700::train::INFO] [Train] Iter 4522 | Loss 0.026495 | Grad 0.0301 \n","[2023-12-09 07:35:42,784::train::INFO] [Train] Iter 4523 | Loss 0.026227 | Grad 0.0293 \n","[2023-12-09 07:35:42,868::train::INFO] [Train] Iter 4524 | Loss 0.026599 | Grad 0.0266 \n","[2023-12-09 07:35:42,952::train::INFO] [Train] Iter 4525 | Loss 0.027343 | Grad 0.0349 \n","[2023-12-09 07:35:43,039::train::INFO] [Train] Iter 4526 | Loss 0.028328 | Grad 0.0319 \n","[2023-12-09 07:35:43,122::train::INFO] [Train] Iter 4527 | Loss 0.024032 | Grad 0.0289 \n","[2023-12-09 07:35:43,206::train::INFO] [Train] Iter 4528 | Loss 0.028049 | Grad 0.0316 \n","[2023-12-09 07:35:43,290::train::INFO] [Train] Iter 4529 | Loss 0.030454 | Grad 0.0401 \n","[2023-12-09 07:35:43,374::train::INFO] [Train] Iter 4530 | Loss 0.026414 | Grad 0.0274 \n","[2023-12-09 07:35:43,459::train::INFO] [Train] Iter 4531 | Loss 0.028688 | Grad 0.0299 \n","[2023-12-09 07:35:43,543::train::INFO] [Train] Iter 4532 | Loss 0.026749 | Grad 0.0345 \n","[2023-12-09 07:35:43,628::train::INFO] [Train] Iter 4533 | Loss 0.026422 | Grad 0.0313 \n","[2023-12-09 07:35:43,712::train::INFO] [Train] Iter 4534 | Loss 0.027148 | Grad 0.0369 \n","[2023-12-09 07:35:43,796::train::INFO] [Train] Iter 4535 | Loss 0.026563 | Grad 0.0317 \n","[2023-12-09 07:35:43,884::train::INFO] [Train] Iter 4536 | Loss 0.027440 | Grad 0.0419 \n","[2023-12-09 07:35:43,969::train::INFO] [Train] Iter 4537 | Loss 0.027274 | Grad 0.0257 \n","[2023-12-09 07:35:44,053::train::INFO] [Train] Iter 4538 | Loss 0.026577 | Grad 0.0404 \n","[2023-12-09 07:35:44,137::train::INFO] [Train] Iter 4539 | Loss 0.023357 | Grad 0.0321 \n","[2023-12-09 07:35:44,225::train::INFO] [Train] Iter 4540 | Loss 0.028129 | Grad 0.0356 \n","[2023-12-09 07:35:44,309::train::INFO] [Train] Iter 4541 | Loss 0.025879 | Grad 0.0263 \n","[2023-12-09 07:35:44,393::train::INFO] [Train] Iter 4542 | Loss 0.024133 | Grad 0.0271 \n","[2023-12-09 07:35:44,478::train::INFO] [Train] Iter 4543 | Loss 0.025570 | Grad 0.0289 \n","[2023-12-09 07:35:44,565::train::INFO] [Train] Iter 4544 | Loss 0.027401 | Grad 0.0352 \n","[2023-12-09 07:35:44,650::train::INFO] [Train] Iter 4545 | Loss 0.026924 | Grad 0.0269 \n","[2023-12-09 07:35:44,734::train::INFO] [Train] Iter 4546 | Loss 0.027116 | Grad 0.0264 \n","[2023-12-09 07:35:44,822::train::INFO] [Train] Iter 4547 | Loss 0.025450 | Grad 0.0276 \n","[2023-12-09 07:35:44,905::train::INFO] [Train] Iter 4548 | Loss 0.026582 | Grad 0.0335 \n","[2023-12-09 07:35:44,988::train::INFO] [Train] Iter 4549 | Loss 0.027641 | Grad 0.0303 \n","[2023-12-09 07:35:45,073::train::INFO] [Train] Iter 4550 | Loss 0.024976 | Grad 0.0331 \n","[2023-12-09 07:35:45,167::train::INFO] [Train] Iter 4551 | Loss 0.027696 | Grad 0.0233 \n","[2023-12-09 07:35:45,261::train::INFO] [Train] Iter 4552 | Loss 0.027732 | Grad 0.0361 \n","[2023-12-09 07:35:45,355::train::INFO] [Train] Iter 4553 | Loss 0.026678 | Grad 0.0268 \n","[2023-12-09 07:35:45,454::train::INFO] [Train] Iter 4554 | Loss 0.025382 | Grad 0.0322 \n","[2023-12-09 07:35:45,546::train::INFO] [Train] Iter 4555 | Loss 0.025991 | Grad 0.0264 \n","[2023-12-09 07:35:45,639::train::INFO] [Train] Iter 4556 | Loss 0.024927 | Grad 0.0407 \n","[2023-12-09 07:35:45,732::train::INFO] [Train] Iter 4557 | Loss 0.025710 | Grad 0.0306 \n","[2023-12-09 07:35:45,826::train::INFO] [Train] Iter 4558 | Loss 0.026234 | Grad 0.0406 \n","[2023-12-09 07:35:45,921::train::INFO] [Train] Iter 4559 | Loss 0.027138 | Grad 0.0449 \n","[2023-12-09 07:35:46,013::train::INFO] [Train] Iter 4560 | Loss 0.026973 | Grad 0.0353 \n","[2023-12-09 07:35:46,105::train::INFO] [Train] Iter 4561 | Loss 0.027713 | Grad 0.0437 \n","[2023-12-09 07:35:46,202::train::INFO] [Train] Iter 4562 | Loss 0.026783 | Grad 0.0298 \n","[2023-12-09 07:35:46,293::train::INFO] [Train] Iter 4563 | Loss 0.028858 | Grad 0.0273 \n","[2023-12-09 07:35:46,384::train::INFO] [Train] Iter 4564 | Loss 0.026812 | Grad 0.0364 \n","[2023-12-09 07:35:46,474::train::INFO] [Train] Iter 4565 | Loss 0.029635 | Grad 0.0319 \n","[2023-12-09 07:35:46,568::train::INFO] [Train] Iter 4566 | Loss 0.027792 | Grad 0.0300 \n","[2023-12-09 07:35:46,661::train::INFO] [Train] Iter 4567 | Loss 0.026529 | Grad 0.0291 \n","[2023-12-09 07:35:46,753::train::INFO] [Train] Iter 4568 | Loss 0.027248 | Grad 0.0305 \n","[2023-12-09 07:35:46,850::train::INFO] [Train] Iter 4569 | Loss 0.027949 | Grad 0.0280 \n","[2023-12-09 07:35:46,945::train::INFO] [Train] Iter 4570 | Loss 0.029164 | Grad 0.0335 \n","[2023-12-09 07:35:47,037::train::INFO] [Train] Iter 4571 | Loss 0.029517 | Grad 0.0329 \n","[2023-12-09 07:35:47,129::train::INFO] [Train] Iter 4572 | Loss 0.028523 | Grad 0.0385 \n","[2023-12-09 07:35:47,221::train::INFO] [Train] Iter 4573 | Loss 0.026658 | Grad 0.0267 \n","[2023-12-09 07:35:47,314::train::INFO] [Train] Iter 4574 | Loss 0.026321 | Grad 0.0433 \n","[2023-12-09 07:35:47,442::train::INFO] [Train] Iter 4575 | Loss 0.027504 | Grad 0.0352 \n","[2023-12-09 07:35:47,532::train::INFO] [Train] Iter 4576 | Loss 0.028157 | Grad 0.0277 \n","[2023-12-09 07:35:47,622::train::INFO] [Train] Iter 4577 | Loss 0.024797 | Grad 0.0331 \n","[2023-12-09 07:35:47,713::train::INFO] [Train] Iter 4578 | Loss 0.027098 | Grad 0.0328 \n","[2023-12-09 07:35:47,804::train::INFO] [Train] Iter 4579 | Loss 0.024496 | Grad 0.0331 \n","[2023-12-09 07:35:47,895::train::INFO] [Train] Iter 4580 | Loss 0.025809 | Grad 0.0320 \n","[2023-12-09 07:35:47,987::train::INFO] [Train] Iter 4581 | Loss 0.026365 | Grad 0.0282 \n","[2023-12-09 07:35:48,078::train::INFO] [Train] Iter 4582 | Loss 0.027820 | Grad 0.0294 \n","[2023-12-09 07:35:48,171::train::INFO] [Train] Iter 4583 | Loss 0.029034 | Grad 0.0465 \n","[2023-12-09 07:35:48,263::train::INFO] [Train] Iter 4584 | Loss 0.028620 | Grad 0.0372 \n","[2023-12-09 07:35:48,355::train::INFO] [Train] Iter 4585 | Loss 0.026021 | Grad 0.0317 \n","[2023-12-09 07:35:48,449::train::INFO] [Train] Iter 4586 | Loss 0.027679 | Grad 0.0375 \n","[2023-12-09 07:35:48,542::train::INFO] [Train] Iter 4587 | Loss 0.026588 | Grad 0.0304 \n","[2023-12-09 07:35:48,637::train::INFO] [Train] Iter 4588 | Loss 0.028925 | Grad 0.0593 \n","[2023-12-09 07:35:48,728::train::INFO] [Train] Iter 4589 | Loss 0.024841 | Grad 0.0336 \n","[2023-12-09 07:35:48,818::train::INFO] [Train] Iter 4590 | Loss 0.024924 | Grad 0.0363 \n","[2023-12-09 07:35:48,910::train::INFO] [Train] Iter 4591 | Loss 0.026185 | Grad 0.0341 \n","[2023-12-09 07:35:49,003::train::INFO] [Train] Iter 4592 | Loss 0.030243 | Grad 0.0354 \n","[2023-12-09 07:35:49,096::train::INFO] [Train] Iter 4593 | Loss 0.029690 | Grad 0.0633 \n","[2023-12-09 07:35:49,187::train::INFO] [Train] Iter 4594 | Loss 0.026275 | Grad 0.0384 \n","[2023-12-09 07:35:49,278::train::INFO] [Train] Iter 4595 | Loss 0.027534 | Grad 0.0323 \n","[2023-12-09 07:35:49,371::train::INFO] [Train] Iter 4596 | Loss 0.025740 | Grad 0.0297 \n","[2023-12-09 07:35:49,465::train::INFO] [Train] Iter 4597 | Loss 0.026098 | Grad 0.0346 \n","[2023-12-09 07:35:49,574::train::INFO] [Train] Iter 4598 | Loss 0.024661 | Grad 0.0423 \n","[2023-12-09 07:35:49,665::train::INFO] [Train] Iter 4599 | Loss 0.025261 | Grad 0.0310 \n","[2023-12-09 07:35:49,756::train::INFO] [Train] Iter 4600 | Loss 0.028087 | Grad 0.0311 \n","[2023-12-09 07:35:49,847::train::INFO] [Train] Iter 4601 | Loss 0.029347 | Grad 0.0420 \n","[2023-12-09 07:35:49,939::train::INFO] [Train] Iter 4602 | Loss 0.025482 | Grad 0.0287 \n","[2023-12-09 07:35:50,032::train::INFO] [Train] Iter 4603 | Loss 0.024779 | Grad 0.0277 \n","[2023-12-09 07:35:50,123::train::INFO] [Train] Iter 4604 | Loss 0.027786 | Grad 0.0375 \n","[2023-12-09 07:35:50,214::train::INFO] [Train] Iter 4605 | Loss 0.025531 | Grad 0.0317 \n","[2023-12-09 07:35:50,307::train::INFO] [Train] Iter 4606 | Loss 0.027926 | Grad 0.0280 \n","[2023-12-09 07:35:50,397::train::INFO] [Train] Iter 4607 | Loss 0.025726 | Grad 0.0281 \n","[2023-12-09 07:35:50,492::train::INFO] [Train] Iter 4608 | Loss 0.028320 | Grad 0.0294 \n","[2023-12-09 07:35:50,583::train::INFO] [Train] Iter 4609 | Loss 0.027237 | Grad 0.0385 \n","[2023-12-09 07:35:50,674::train::INFO] [Train] Iter 4610 | Loss 0.028080 | Grad 0.0283 \n","[2023-12-09 07:35:50,765::train::INFO] [Train] Iter 4611 | Loss 0.027997 | Grad 0.0307 \n","[2023-12-09 07:35:50,855::train::INFO] [Train] Iter 4612 | Loss 0.026164 | Grad 0.0437 \n","[2023-12-09 07:35:50,946::train::INFO] [Train] Iter 4613 | Loss 0.026291 | Grad 0.0326 \n","[2023-12-09 07:35:51,035::train::INFO] [Train] Iter 4614 | Loss 0.026559 | Grad 0.0264 \n","[2023-12-09 07:35:51,130::train::INFO] [Train] Iter 4615 | Loss 0.028324 | Grad 0.0275 \n","[2023-12-09 07:35:51,225::train::INFO] [Train] Iter 4616 | Loss 0.028605 | Grad 0.0281 \n","[2023-12-09 07:35:51,316::train::INFO] [Train] Iter 4617 | Loss 0.026435 | Grad 0.0436 \n","[2023-12-09 07:35:51,408::train::INFO] [Train] Iter 4618 | Loss 0.025909 | Grad 0.0316 \n","[2023-12-09 07:35:51,497::train::INFO] [Train] Iter 4619 | Loss 0.028250 | Grad 0.0299 \n","[2023-12-09 07:35:51,583::train::INFO] [Train] Iter 4620 | Loss 0.024709 | Grad 0.0288 \n","[2023-12-09 07:35:51,667::train::INFO] [Train] Iter 4621 | Loss 0.025492 | Grad 0.0248 \n","[2023-12-09 07:35:51,752::train::INFO] [Train] Iter 4622 | Loss 0.027242 | Grad 0.0317 \n","[2023-12-09 07:35:51,835::train::INFO] [Train] Iter 4623 | Loss 0.028348 | Grad 0.0294 \n","[2023-12-09 07:35:51,919::train::INFO] [Train] Iter 4624 | Loss 0.026678 | Grad 0.0310 \n","[2023-12-09 07:35:52,003::train::INFO] [Train] Iter 4625 | Loss 0.025730 | Grad 0.0349 \n","[2023-12-09 07:35:52,088::train::INFO] [Train] Iter 4626 | Loss 0.026506 | Grad 0.0254 \n","[2023-12-09 07:35:52,178::train::INFO] [Train] Iter 4627 | Loss 0.026532 | Grad 0.0285 \n","[2023-12-09 07:35:52,261::train::INFO] [Train] Iter 4628 | Loss 0.026411 | Grad 0.0322 \n","[2023-12-09 07:35:52,349::train::INFO] [Train] Iter 4629 | Loss 0.025539 | Grad 0.0306 \n","[2023-12-09 07:35:52,432::train::INFO] [Train] Iter 4630 | Loss 0.028552 | Grad 0.0318 \n","[2023-12-09 07:35:52,515::train::INFO] [Train] Iter 4631 | Loss 0.028158 | Grad 0.0293 \n","[2023-12-09 07:35:52,602::train::INFO] [Train] Iter 4632 | Loss 0.026342 | Grad 0.0366 \n","[2023-12-09 07:35:52,690::train::INFO] [Train] Iter 4633 | Loss 0.027065 | Grad 0.0325 \n","[2023-12-09 07:35:52,773::train::INFO] [Train] Iter 4634 | Loss 0.027638 | Grad 0.0298 \n","[2023-12-09 07:35:52,856::train::INFO] [Train] Iter 4635 | Loss 0.025580 | Grad 0.0370 \n","[2023-12-09 07:35:52,939::train::INFO] [Train] Iter 4636 | Loss 0.028605 | Grad 0.0280 \n","[2023-12-09 07:35:53,024::train::INFO] [Train] Iter 4637 | Loss 0.025914 | Grad 0.0312 \n","[2023-12-09 07:35:53,108::train::INFO] [Train] Iter 4638 | Loss 0.029760 | Grad 0.0262 \n","[2023-12-09 07:35:53,205::train::INFO] [Train] Iter 4639 | Loss 0.026242 | Grad 0.0254 \n","[2023-12-09 07:35:53,288::train::INFO] [Train] Iter 4640 | Loss 0.027640 | Grad 0.0266 \n","[2023-12-09 07:35:53,371::train::INFO] [Train] Iter 4641 | Loss 0.026358 | Grad 0.0305 \n","[2023-12-09 07:35:53,454::train::INFO] [Train] Iter 4642 | Loss 0.025950 | Grad 0.0260 \n","[2023-12-09 07:35:53,536::train::INFO] [Train] Iter 4643 | Loss 0.026515 | Grad 0.0358 \n","[2023-12-09 07:35:53,621::train::INFO] [Train] Iter 4644 | Loss 0.027620 | Grad 0.0464 \n","[2023-12-09 07:35:53,710::train::INFO] [Train] Iter 4645 | Loss 0.026537 | Grad 0.0318 \n","[2023-12-09 07:35:53,794::train::INFO] [Train] Iter 4646 | Loss 0.027535 | Grad 0.0303 \n","[2023-12-09 07:35:53,883::train::INFO] [Train] Iter 4647 | Loss 0.027576 | Grad 0.0255 \n","[2023-12-09 07:35:53,968::train::INFO] [Train] Iter 4648 | Loss 0.024824 | Grad 0.0275 \n","[2023-12-09 07:35:54,053::train::INFO] [Train] Iter 4649 | Loss 0.028218 | Grad 0.0383 \n","[2023-12-09 07:35:54,137::train::INFO] [Train] Iter 4650 | Loss 0.025103 | Grad 0.0284 \n","[2023-12-09 07:35:54,221::train::INFO] [Train] Iter 4651 | Loss 0.027751 | Grad 0.0300 \n","[2023-12-09 07:35:54,305::train::INFO] [Train] Iter 4652 | Loss 0.026679 | Grad 0.0303 \n","[2023-12-09 07:35:54,396::train::INFO] [Train] Iter 4653 | Loss 0.028844 | Grad 0.0269 \n","[2023-12-09 07:35:54,479::train::INFO] [Train] Iter 4654 | Loss 0.026839 | Grad 0.0316 \n","[2023-12-09 07:35:54,564::train::INFO] [Train] Iter 4655 | Loss 0.027054 | Grad 0.0286 \n","[2023-12-09 07:35:54,648::train::INFO] [Train] Iter 4656 | Loss 0.026892 | Grad 0.0299 \n","[2023-12-09 07:35:54,733::train::INFO] [Train] Iter 4657 | Loss 0.026779 | Grad 0.0336 \n","[2023-12-09 07:35:54,818::train::INFO] [Train] Iter 4658 | Loss 0.025330 | Grad 0.0289 \n","[2023-12-09 07:35:54,902::train::INFO] [Train] Iter 4659 | Loss 0.026314 | Grad 0.0263 \n","[2023-12-09 07:35:54,991::train::INFO] [Train] Iter 4660 | Loss 0.026702 | Grad 0.0219 \n","[2023-12-09 07:35:55,076::train::INFO] [Train] Iter 4661 | Loss 0.027088 | Grad 0.0359 \n","[2023-12-09 07:35:55,161::train::INFO] [Train] Iter 4662 | Loss 0.025973 | Grad 0.0292 \n","[2023-12-09 07:35:55,248::train::INFO] [Train] Iter 4663 | Loss 0.026904 | Grad 0.0274 \n","[2023-12-09 07:35:55,334::train::INFO] [Train] Iter 4664 | Loss 0.028626 | Grad 0.0321 \n","[2023-12-09 07:35:55,418::train::INFO] [Train] Iter 4665 | Loss 0.028058 | Grad 0.0315 \n","[2023-12-09 07:35:55,501::train::INFO] [Train] Iter 4666 | Loss 0.025920 | Grad 0.0289 \n","[2023-12-09 07:35:55,584::train::INFO] [Train] Iter 4667 | Loss 0.024212 | Grad 0.0275 \n","[2023-12-09 07:35:55,669::train::INFO] [Train] Iter 4668 | Loss 0.026767 | Grad 0.0249 \n","[2023-12-09 07:35:55,753::train::INFO] [Train] Iter 4669 | Loss 0.024454 | Grad 0.0241 \n","[2023-12-09 07:35:55,837::train::INFO] [Train] Iter 4670 | Loss 0.024129 | Grad 0.0317 \n","[2023-12-09 07:35:55,924::train::INFO] [Train] Iter 4671 | Loss 0.026327 | Grad 0.0320 \n","[2023-12-09 07:35:56,009::train::INFO] [Train] Iter 4672 | Loss 0.025905 | Grad 0.0257 \n","[2023-12-09 07:35:56,094::train::INFO] [Train] Iter 4673 | Loss 0.028036 | Grad 0.0322 \n","[2023-12-09 07:35:56,179::train::INFO] [Train] Iter 4674 | Loss 0.025977 | Grad 0.0309 \n","[2023-12-09 07:35:56,263::train::INFO] [Train] Iter 4675 | Loss 0.025772 | Grad 0.0410 \n","[2023-12-09 07:35:56,347::train::INFO] [Train] Iter 4676 | Loss 0.025378 | Grad 0.0360 \n","[2023-12-09 07:35:56,431::train::INFO] [Train] Iter 4677 | Loss 0.027634 | Grad 0.0300 \n","[2023-12-09 07:35:56,516::train::INFO] [Train] Iter 4678 | Loss 0.026868 | Grad 0.0304 \n","[2023-12-09 07:35:56,600::train::INFO] [Train] Iter 4679 | Loss 0.028591 | Grad 0.0312 \n","[2023-12-09 07:35:56,687::train::INFO] [Train] Iter 4680 | Loss 0.028380 | Grad 0.0340 \n","[2023-12-09 07:35:56,772::train::INFO] [Train] Iter 4681 | Loss 0.027077 | Grad 0.0302 \n","[2023-12-09 07:35:56,855::train::INFO] [Train] Iter 4682 | Loss 0.028434 | Grad 0.0334 \n","[2023-12-09 07:35:56,938::train::INFO] [Train] Iter 4683 | Loss 0.025111 | Grad 0.0272 \n","[2023-12-09 07:35:57,026::train::INFO] [Train] Iter 4684 | Loss 0.026427 | Grad 0.0332 \n","[2023-12-09 07:35:57,113::train::INFO] [Train] Iter 4685 | Loss 0.027016 | Grad 0.0266 \n","[2023-12-09 07:35:57,197::train::INFO] [Train] Iter 4686 | Loss 0.029037 | Grad 0.0272 \n","[2023-12-09 07:35:57,282::train::INFO] [Train] Iter 4687 | Loss 0.027332 | Grad 0.0306 \n","[2023-12-09 07:35:57,367::train::INFO] [Train] Iter 4688 | Loss 0.027195 | Grad 0.0282 \n","[2023-12-09 07:35:57,451::train::INFO] [Train] Iter 4689 | Loss 0.025477 | Grad 0.0274 \n","[2023-12-09 07:35:57,535::train::INFO] [Train] Iter 4690 | Loss 0.028551 | Grad 0.0299 \n","[2023-12-09 07:35:57,621::train::INFO] [Train] Iter 4691 | Loss 0.028041 | Grad 0.0339 \n","[2023-12-09 07:35:57,706::train::INFO] [Train] Iter 4692 | Loss 0.024530 | Grad 0.0287 \n","[2023-12-09 07:35:57,789::train::INFO] [Train] Iter 4693 | Loss 0.024845 | Grad 0.0298 \n","[2023-12-09 07:35:57,876::train::INFO] [Train] Iter 4694 | Loss 0.026229 | Grad 0.0304 \n","[2023-12-09 07:35:57,960::train::INFO] [Train] Iter 4695 | Loss 0.024720 | Grad 0.0361 \n","[2023-12-09 07:35:58,044::train::INFO] [Train] Iter 4696 | Loss 0.026098 | Grad 0.0330 \n","[2023-12-09 07:35:58,130::train::INFO] [Train] Iter 4697 | Loss 0.026548 | Grad 0.0308 \n","[2023-12-09 07:35:58,219::train::INFO] [Train] Iter 4698 | Loss 0.025827 | Grad 0.0336 \n","[2023-12-09 07:35:58,303::train::INFO] [Train] Iter 4699 | Loss 0.027510 | Grad 0.0391 \n","[2023-12-09 07:35:58,389::train::INFO] [Train] Iter 4700 | Loss 0.025894 | Grad 0.0349 \n","[2023-12-09 07:35:58,473::train::INFO] [Train] Iter 4701 | Loss 0.027418 | Grad 0.0414 \n","[2023-12-09 07:35:58,561::train::INFO] [Train] Iter 4702 | Loss 0.026028 | Grad 0.0385 \n","[2023-12-09 07:35:58,647::train::INFO] [Train] Iter 4703 | Loss 0.025278 | Grad 0.0383 \n","[2023-12-09 07:35:58,732::train::INFO] [Train] Iter 4704 | Loss 0.027995 | Grad 0.0297 \n","[2023-12-09 07:35:58,820::train::INFO] [Train] Iter 4705 | Loss 0.025183 | Grad 0.0324 \n","[2023-12-09 07:35:58,904::train::INFO] [Train] Iter 4706 | Loss 0.025750 | Grad 0.0333 \n","[2023-12-09 07:35:58,988::train::INFO] [Train] Iter 4707 | Loss 0.025096 | Grad 0.0337 \n","[2023-12-09 07:35:59,072::train::INFO] [Train] Iter 4708 | Loss 0.027526 | Grad 0.0344 \n","[2023-12-09 07:35:59,157::train::INFO] [Train] Iter 4709 | Loss 0.025803 | Grad 0.0396 \n","[2023-12-09 07:35:59,242::train::INFO] [Train] Iter 4710 | Loss 0.026959 | Grad 0.0412 \n","[2023-12-09 07:35:59,331::train::INFO] [Train] Iter 4711 | Loss 0.025146 | Grad 0.0385 \n","[2023-12-09 07:35:59,416::train::INFO] [Train] Iter 4712 | Loss 0.026664 | Grad 0.0286 \n","[2023-12-09 07:35:59,500::train::INFO] [Train] Iter 4713 | Loss 0.026169 | Grad 0.0318 \n","[2023-12-09 07:35:59,584::train::INFO] [Train] Iter 4714 | Loss 0.028915 | Grad 0.0411 \n","[2023-12-09 07:35:59,670::train::INFO] [Train] Iter 4715 | Loss 0.026956 | Grad 0.0321 \n","[2023-12-09 07:35:59,755::train::INFO] [Train] Iter 4716 | Loss 0.030831 | Grad 0.0318 \n","[2023-12-09 07:35:59,839::train::INFO] [Train] Iter 4717 | Loss 0.027874 | Grad 0.0297 \n","[2023-12-09 07:35:59,928::train::INFO] [Train] Iter 4718 | Loss 0.023559 | Grad 0.0359 \n","[2023-12-09 07:36:00,016::train::INFO] [Train] Iter 4719 | Loss 0.029398 | Grad 0.0303 \n","[2023-12-09 07:36:00,101::train::INFO] [Train] Iter 4720 | Loss 0.026998 | Grad 0.0292 \n","[2023-12-09 07:36:00,185::train::INFO] [Train] Iter 4721 | Loss 0.024297 | Grad 0.0415 \n","[2023-12-09 07:36:00,271::train::INFO] [Train] Iter 4722 | Loss 0.027923 | Grad 0.0260 \n","[2023-12-09 07:36:00,355::train::INFO] [Train] Iter 4723 | Loss 0.026054 | Grad 0.0295 \n","[2023-12-09 07:36:00,439::train::INFO] [Train] Iter 4724 | Loss 0.026867 | Grad 0.0289 \n","[2023-12-09 07:36:00,524::train::INFO] [Train] Iter 4725 | Loss 0.027590 | Grad 0.0320 \n","[2023-12-09 07:36:00,608::train::INFO] [Train] Iter 4726 | Loss 0.027167 | Grad 0.0310 \n","[2023-12-09 07:36:00,692::train::INFO] [Train] Iter 4727 | Loss 0.026527 | Grad 0.0273 \n","[2023-12-09 07:36:00,777::train::INFO] [Train] Iter 4728 | Loss 0.023072 | Grad 0.0283 \n","[2023-12-09 07:36:00,862::train::INFO] [Train] Iter 4729 | Loss 0.027188 | Grad 0.0373 \n","[2023-12-09 07:36:00,945::train::INFO] [Train] Iter 4730 | Loss 0.028094 | Grad 0.0332 \n","[2023-12-09 07:36:01,031::train::INFO] [Train] Iter 4731 | Loss 0.026315 | Grad 0.0289 \n","[2023-12-09 07:36:01,115::train::INFO] [Train] Iter 4732 | Loss 0.026655 | Grad 0.0316 \n","[2023-12-09 07:36:01,200::train::INFO] [Train] Iter 4733 | Loss 0.027409 | Grad 0.0404 \n","[2023-12-09 07:36:01,284::train::INFO] [Train] Iter 4734 | Loss 0.027174 | Grad 0.0265 \n","[2023-12-09 07:36:01,368::train::INFO] [Train] Iter 4735 | Loss 0.025709 | Grad 0.0276 \n","[2023-12-09 07:36:01,455::train::INFO] [Train] Iter 4736 | Loss 0.026320 | Grad 0.0274 \n","[2023-12-09 07:36:01,551::train::INFO] [Train] Iter 4737 | Loss 0.028886 | Grad 0.0373 \n","[2023-12-09 07:36:01,644::train::INFO] [Train] Iter 4738 | Loss 0.026773 | Grad 0.0300 \n","[2023-12-09 07:36:01,735::train::INFO] [Train] Iter 4739 | Loss 0.027116 | Grad 0.0355 \n","[2023-12-09 07:36:01,829::train::INFO] [Train] Iter 4740 | Loss 0.027437 | Grad 0.0279 \n","[2023-12-09 07:36:01,921::train::INFO] [Train] Iter 4741 | Loss 0.024614 | Grad 0.0242 \n","[2023-12-09 07:36:02,016::train::INFO] [Train] Iter 4742 | Loss 0.029238 | Grad 0.0381 \n","[2023-12-09 07:36:02,111::train::INFO] [Train] Iter 4743 | Loss 0.027222 | Grad 0.0289 \n","[2023-12-09 07:36:02,207::train::INFO] [Train] Iter 4744 | Loss 0.024831 | Grad 0.0298 \n","[2023-12-09 07:36:02,301::train::INFO] [Train] Iter 4745 | Loss 0.027240 | Grad 0.0322 \n","[2023-12-09 07:36:02,393::train::INFO] [Train] Iter 4746 | Loss 0.029339 | Grad 0.0641 \n","[2023-12-09 07:36:02,489::train::INFO] [Train] Iter 4747 | Loss 0.026332 | Grad 0.0318 \n","[2023-12-09 07:36:02,580::train::INFO] [Train] Iter 4748 | Loss 0.027789 | Grad 0.0363 \n","[2023-12-09 07:36:02,671::train::INFO] [Train] Iter 4749 | Loss 0.027019 | Grad 0.0387 \n","[2023-12-09 07:36:02,764::train::INFO] [Train] Iter 4750 | Loss 0.027456 | Grad 0.0331 \n","[2023-12-09 07:36:02,865::train::INFO] [Train] Iter 4751 | Loss 0.024449 | Grad 0.0321 \n","[2023-12-09 07:36:02,955::train::INFO] [Train] Iter 4752 | Loss 0.027080 | Grad 0.0342 \n","[2023-12-09 07:36:03,048::train::INFO] [Train] Iter 4753 | Loss 0.027154 | Grad 0.0383 \n","[2023-12-09 07:36:03,147::train::INFO] [Train] Iter 4754 | Loss 0.028372 | Grad 0.0333 \n","[2023-12-09 07:36:03,239::train::INFO] [Train] Iter 4755 | Loss 0.024452 | Grad 0.0317 \n","[2023-12-09 07:36:03,331::train::INFO] [Train] Iter 4756 | Loss 0.028814 | Grad 0.0323 \n","[2023-12-09 07:36:03,422::train::INFO] [Train] Iter 4757 | Loss 0.029220 | Grad 0.0292 \n","[2023-12-09 07:36:03,516::train::INFO] [Train] Iter 4758 | Loss 0.024391 | Grad 0.0327 \n","[2023-12-09 07:36:03,609::train::INFO] [Train] Iter 4759 | Loss 0.024792 | Grad 0.0332 \n","[2023-12-09 07:36:03,650::train::INFO] [Train] Iter 4760 | Loss 0.025040 | Grad 0.0706 \n","[2023-12-09 07:36:03,756::train::INFO] [Train] Iter 4761 | Loss 0.024833 | Grad 0.0291 \n","[2023-12-09 07:36:03,846::train::INFO] [Train] Iter 4762 | Loss 0.028319 | Grad 0.0369 \n","[2023-12-09 07:36:03,938::train::INFO] [Train] Iter 4763 | Loss 0.026214 | Grad 0.0366 \n","[2023-12-09 07:36:04,029::train::INFO] [Train] Iter 4764 | Loss 0.028046 | Grad 0.0340 \n","[2023-12-09 07:36:04,125::train::INFO] [Train] Iter 4765 | Loss 0.026580 | Grad 0.0312 \n","[2023-12-09 07:36:04,216::train::INFO] [Train] Iter 4766 | Loss 0.029025 | Grad 0.0318 \n","[2023-12-09 07:36:04,307::train::INFO] [Train] Iter 4767 | Loss 0.026812 | Grad 0.0321 \n","[2023-12-09 07:36:04,400::train::INFO] [Train] Iter 4768 | Loss 0.028138 | Grad 0.0261 \n","[2023-12-09 07:36:04,492::train::INFO] [Train] Iter 4769 | Loss 0.026698 | Grad 0.0278 \n","[2023-12-09 07:36:04,583::train::INFO] [Train] Iter 4770 | Loss 0.027894 | Grad 0.0326 \n","[2023-12-09 07:36:04,677::train::INFO] [Train] Iter 4771 | Loss 0.025869 | Grad 0.0331 \n","[2023-12-09 07:36:04,770::train::INFO] [Train] Iter 4772 | Loss 0.028601 | Grad 0.0293 \n","[2023-12-09 07:36:04,861::train::INFO] [Train] Iter 4773 | Loss 0.026380 | Grad 0.0349 \n","[2023-12-09 07:36:04,973::train::INFO] [Train] Iter 4774 | Loss 0.027226 | Grad 0.0323 \n","[2023-12-09 07:36:05,067::train::INFO] [Train] Iter 4775 | Loss 0.027200 | Grad 0.0240 \n","[2023-12-09 07:36:05,160::train::INFO] [Train] Iter 4776 | Loss 0.026644 | Grad 0.0271 \n","[2023-12-09 07:36:05,254::train::INFO] [Train] Iter 4777 | Loss 0.027165 | Grad 0.0391 \n","[2023-12-09 07:36:05,345::train::INFO] [Train] Iter 4778 | Loss 0.025802 | Grad 0.0279 \n","[2023-12-09 07:36:05,436::train::INFO] [Train] Iter 4779 | Loss 0.028555 | Grad 0.0252 \n","[2023-12-09 07:36:05,528::train::INFO] [Train] Iter 4780 | Loss 0.025925 | Grad 0.0385 \n","[2023-12-09 07:36:05,620::train::INFO] [Train] Iter 4781 | Loss 0.025018 | Grad 0.0349 \n","[2023-12-09 07:36:05,711::train::INFO] [Train] Iter 4782 | Loss 0.028215 | Grad 0.0293 \n","[2023-12-09 07:36:05,807::train::INFO] [Train] Iter 4783 | Loss 0.025932 | Grad 0.0406 \n","[2023-12-09 07:36:05,912::train::INFO] [Train] Iter 4784 | Loss 0.026298 | Grad 0.0392 \n","[2023-12-09 07:36:06,008::train::INFO] [Train] Iter 4785 | Loss 0.026136 | Grad 0.0281 \n","[2023-12-09 07:36:06,101::train::INFO] [Train] Iter 4786 | Loss 0.026857 | Grad 0.0409 \n","[2023-12-09 07:36:06,195::train::INFO] [Train] Iter 4787 | Loss 0.028703 | Grad 0.0316 \n","[2023-12-09 07:36:06,294::train::INFO] [Train] Iter 4788 | Loss 0.027590 | Grad 0.0317 \n","[2023-12-09 07:36:06,386::train::INFO] [Train] Iter 4789 | Loss 0.025439 | Grad 0.0352 \n","[2023-12-09 07:36:06,477::train::INFO] [Train] Iter 4790 | Loss 0.027190 | Grad 0.0296 \n","[2023-12-09 07:36:06,573::train::INFO] [Train] Iter 4791 | Loss 0.028946 | Grad 0.0348 \n","[2023-12-09 07:36:06,664::train::INFO] [Train] Iter 4792 | Loss 0.025641 | Grad 0.0286 \n","[2023-12-09 07:36:06,755::train::INFO] [Train] Iter 4793 | Loss 0.028439 | Grad 0.0335 \n","[2023-12-09 07:36:06,845::train::INFO] [Train] Iter 4794 | Loss 0.027276 | Grad 0.0345 \n","[2023-12-09 07:36:06,936::train::INFO] [Train] Iter 4795 | Loss 0.024940 | Grad 0.0265 \n","[2023-12-09 07:36:07,030::train::INFO] [Train] Iter 4796 | Loss 0.028990 | Grad 0.0330 \n","[2023-12-09 07:36:07,123::train::INFO] [Train] Iter 4797 | Loss 0.027218 | Grad 0.0269 \n","[2023-12-09 07:36:07,216::train::INFO] [Train] Iter 4798 | Loss 0.028872 | Grad 0.0265 \n","[2023-12-09 07:36:07,307::train::INFO] [Train] Iter 4799 | Loss 0.025412 | Grad 0.0254 \n","[2023-12-09 07:36:07,401::train::INFO] [Train] Iter 4800 | Loss 0.026885 | Grad 0.0281 \n","[2023-12-09 07:36:07,493::train::INFO] [Train] Iter 4801 | Loss 0.027855 | Grad 0.0288 \n","[2023-12-09 07:36:07,584::train::INFO] [Train] Iter 4802 | Loss 0.027209 | Grad 0.0265 \n","[2023-12-09 07:36:07,677::train::INFO] [Train] Iter 4803 | Loss 0.026704 | Grad 0.0283 \n","[2023-12-09 07:36:07,769::train::INFO] [Train] Iter 4804 | Loss 0.026302 | Grad 0.0304 \n","[2023-12-09 07:36:07,853::train::INFO] [Train] Iter 4805 | Loss 0.027145 | Grad 0.0243 \n","[2023-12-09 07:36:07,936::train::INFO] [Train] Iter 4806 | Loss 0.027224 | Grad 0.0264 \n","[2023-12-09 07:36:08,021::train::INFO] [Train] Iter 4807 | Loss 0.025032 | Grad 0.0306 \n","[2023-12-09 07:36:08,107::train::INFO] [Train] Iter 4808 | Loss 0.025911 | Grad 0.0299 \n","[2023-12-09 07:36:08,190::train::INFO] [Train] Iter 4809 | Loss 0.027714 | Grad 0.0309 \n","[2023-12-09 07:36:08,274::train::INFO] [Train] Iter 4810 | Loss 0.025021 | Grad 0.0280 \n","[2023-12-09 07:36:08,360::train::INFO] [Train] Iter 4811 | Loss 0.029076 | Grad 0.0347 \n","[2023-12-09 07:36:08,443::train::INFO] [Train] Iter 4812 | Loss 0.026152 | Grad 0.0236 \n","[2023-12-09 07:36:08,528::train::INFO] [Train] Iter 4813 | Loss 0.027672 | Grad 0.0314 \n","[2023-12-09 07:36:08,611::train::INFO] [Train] Iter 4814 | Loss 0.025812 | Grad 0.0295 \n","[2023-12-09 07:36:08,697::train::INFO] [Train] Iter 4815 | Loss 0.027037 | Grad 0.0285 \n","[2023-12-09 07:36:08,780::train::INFO] [Train] Iter 4816 | Loss 0.029695 | Grad 0.0419 \n","[2023-12-09 07:36:08,864::train::INFO] [Train] Iter 4817 | Loss 0.026709 | Grad 0.0263 \n","[2023-12-09 07:36:08,947::train::INFO] [Train] Iter 4818 | Loss 0.026491 | Grad 0.0255 \n","[2023-12-09 07:36:09,030::train::INFO] [Train] Iter 4819 | Loss 0.025610 | Grad 0.0301 \n","[2023-12-09 07:36:09,115::train::INFO] [Train] Iter 4820 | Loss 0.024798 | Grad 0.0316 \n","[2023-12-09 07:36:09,199::train::INFO] [Train] Iter 4821 | Loss 0.028165 | Grad 0.0234 \n","[2023-12-09 07:36:09,283::train::INFO] [Train] Iter 4822 | Loss 0.029242 | Grad 0.0287 \n","[2023-12-09 07:36:09,367::train::INFO] [Train] Iter 4823 | Loss 0.026569 | Grad 0.0317 \n","[2023-12-09 07:36:09,452::train::INFO] [Train] Iter 4824 | Loss 0.028664 | Grad 0.0238 \n","[2023-12-09 07:36:09,536::train::INFO] [Train] Iter 4825 | Loss 0.028396 | Grad 0.0292 \n","[2023-12-09 07:36:09,620::train::INFO] [Train] Iter 4826 | Loss 0.026435 | Grad 0.0449 \n","[2023-12-09 07:36:09,703::train::INFO] [Train] Iter 4827 | Loss 0.026998 | Grad 0.0280 \n","[2023-12-09 07:36:09,792::train::INFO] [Train] Iter 4828 | Loss 0.024873 | Grad 0.0266 \n","[2023-12-09 07:36:09,876::train::INFO] [Train] Iter 4829 | Loss 0.027303 | Grad 0.0314 \n","[2023-12-09 07:36:09,959::train::INFO] [Train] Iter 4830 | Loss 0.026735 | Grad 0.0300 \n","[2023-12-09 07:36:10,043::train::INFO] [Train] Iter 4831 | Loss 0.026989 | Grad 0.0258 \n","[2023-12-09 07:36:10,129::train::INFO] [Train] Iter 4832 | Loss 0.026409 | Grad 0.0377 \n","[2023-12-09 07:36:10,213::train::INFO] [Train] Iter 4833 | Loss 0.026846 | Grad 0.0361 \n","[2023-12-09 07:36:10,298::train::INFO] [Train] Iter 4834 | Loss 0.025881 | Grad 0.0301 \n","[2023-12-09 07:36:10,382::train::INFO] [Train] Iter 4835 | Loss 0.026816 | Grad 0.0303 \n","[2023-12-09 07:36:10,465::train::INFO] [Train] Iter 4836 | Loss 0.026160 | Grad 0.0313 \n","[2023-12-09 07:36:10,550::train::INFO] [Train] Iter 4837 | Loss 0.025988 | Grad 0.0265 \n","[2023-12-09 07:36:10,636::train::INFO] [Train] Iter 4838 | Loss 0.025797 | Grad 0.0332 \n","[2023-12-09 07:36:10,720::train::INFO] [Train] Iter 4839 | Loss 0.027314 | Grad 0.0257 \n","[2023-12-09 07:36:10,804::train::INFO] [Train] Iter 4840 | Loss 0.025626 | Grad 0.0347 \n","[2023-12-09 07:36:10,891::train::INFO] [Train] Iter 4841 | Loss 0.026715 | Grad 0.0294 \n","[2023-12-09 07:36:10,974::train::INFO] [Train] Iter 4842 | Loss 0.024191 | Grad 0.0280 \n","[2023-12-09 07:36:11,061::train::INFO] [Train] Iter 4843 | Loss 0.025527 | Grad 0.0343 \n","[2023-12-09 07:36:11,147::train::INFO] [Train] Iter 4844 | Loss 0.027639 | Grad 0.0291 \n","[2023-12-09 07:36:11,232::train::INFO] [Train] Iter 4845 | Loss 0.026749 | Grad 0.0293 \n","[2023-12-09 07:36:11,318::train::INFO] [Train] Iter 4846 | Loss 0.027578 | Grad 0.0381 \n","[2023-12-09 07:36:11,403::train::INFO] [Train] Iter 4847 | Loss 0.026572 | Grad 0.0324 \n","[2023-12-09 07:36:11,487::train::INFO] [Train] Iter 4848 | Loss 0.028654 | Grad 0.0282 \n","[2023-12-09 07:36:11,570::train::INFO] [Train] Iter 4849 | Loss 0.026523 | Grad 0.0279 \n","[2023-12-09 07:36:11,653::train::INFO] [Train] Iter 4850 | Loss 0.027944 | Grad 0.0393 \n","[2023-12-09 07:36:11,736::train::INFO] [Train] Iter 4851 | Loss 0.025437 | Grad 0.0242 \n","[2023-12-09 07:36:11,820::train::INFO] [Train] Iter 4852 | Loss 0.026663 | Grad 0.0261 \n","[2023-12-09 07:36:11,904::train::INFO] [Train] Iter 4853 | Loss 0.026674 | Grad 0.0294 \n","[2023-12-09 07:36:11,990::train::INFO] [Train] Iter 4854 | Loss 0.026537 | Grad 0.0466 \n","[2023-12-09 07:36:12,076::train::INFO] [Train] Iter 4855 | Loss 0.029114 | Grad 0.0290 \n","[2023-12-09 07:36:12,164::train::INFO] [Train] Iter 4856 | Loss 0.023586 | Grad 0.0275 \n","[2023-12-09 07:36:12,248::train::INFO] [Train] Iter 4857 | Loss 0.027065 | Grad 0.0279 \n","[2023-12-09 07:36:12,337::train::INFO] [Train] Iter 4858 | Loss 0.025822 | Grad 0.0314 \n","[2023-12-09 07:36:12,422::train::INFO] [Train] Iter 4859 | Loss 0.025508 | Grad 0.0255 \n","[2023-12-09 07:36:12,507::train::INFO] [Train] Iter 4860 | Loss 0.028748 | Grad 0.0273 \n","[2023-12-09 07:36:12,591::train::INFO] [Train] Iter 4861 | Loss 0.026550 | Grad 0.0270 \n","[2023-12-09 07:36:12,675::train::INFO] [Train] Iter 4862 | Loss 0.026301 | Grad 0.0294 \n","[2023-12-09 07:36:12,760::train::INFO] [Train] Iter 4863 | Loss 0.025927 | Grad 0.0279 \n","[2023-12-09 07:36:12,844::train::INFO] [Train] Iter 4864 | Loss 0.026375 | Grad 0.0264 \n","[2023-12-09 07:36:12,931::train::INFO] [Train] Iter 4865 | Loss 0.027096 | Grad 0.0312 \n","[2023-12-09 07:36:13,015::train::INFO] [Train] Iter 4866 | Loss 0.028162 | Grad 0.0303 \n","[2023-12-09 07:36:13,100::train::INFO] [Train] Iter 4867 | Loss 0.023822 | Grad 0.0278 \n","[2023-12-09 07:36:13,188::train::INFO] [Train] Iter 4868 | Loss 0.027798 | Grad 0.0310 \n","[2023-12-09 07:36:13,272::train::INFO] [Train] Iter 4869 | Loss 0.030260 | Grad 0.0358 \n","[2023-12-09 07:36:13,361::train::INFO] [Train] Iter 4870 | Loss 0.026181 | Grad 0.0256 \n","[2023-12-09 07:36:13,446::train::INFO] [Train] Iter 4871 | Loss 0.028539 | Grad 0.0284 \n","[2023-12-09 07:36:13,530::train::INFO] [Train] Iter 4872 | Loss 0.026565 | Grad 0.0347 \n","[2023-12-09 07:36:13,614::train::INFO] [Train] Iter 4873 | Loss 0.026208 | Grad 0.0307 \n","[2023-12-09 07:36:13,696::train::INFO] [Train] Iter 4874 | Loss 0.026956 | Grad 0.0372 \n","[2023-12-09 07:36:13,780::train::INFO] [Train] Iter 4875 | Loss 0.026312 | Grad 0.0283 \n","[2023-12-09 07:36:13,863::train::INFO] [Train] Iter 4876 | Loss 0.027236 | Grad 0.0382 \n","[2023-12-09 07:36:13,948::train::INFO] [Train] Iter 4877 | Loss 0.026980 | Grad 0.0251 \n","[2023-12-09 07:36:14,033::train::INFO] [Train] Iter 4878 | Loss 0.026348 | Grad 0.0387 \n","[2023-12-09 07:36:14,116::train::INFO] [Train] Iter 4879 | Loss 0.023100 | Grad 0.0248 \n","[2023-12-09 07:36:14,205::train::INFO] [Train] Iter 4880 | Loss 0.027983 | Grad 0.0335 \n","[2023-12-09 07:36:14,289::train::INFO] [Train] Iter 4881 | Loss 0.025685 | Grad 0.0279 \n","[2023-12-09 07:36:14,372::train::INFO] [Train] Iter 4882 | Loss 0.023811 | Grad 0.0256 \n","[2023-12-09 07:36:14,456::train::INFO] [Train] Iter 4883 | Loss 0.025413 | Grad 0.0289 \n","[2023-12-09 07:36:14,541::train::INFO] [Train] Iter 4884 | Loss 0.027265 | Grad 0.0335 \n","[2023-12-09 07:36:14,629::train::INFO] [Train] Iter 4885 | Loss 0.026777 | Grad 0.0265 \n","[2023-12-09 07:36:14,714::train::INFO] [Train] Iter 4886 | Loss 0.026900 | Grad 0.0282 \n","[2023-12-09 07:36:14,798::train::INFO] [Train] Iter 4887 | Loss 0.025194 | Grad 0.0255 \n","[2023-12-09 07:36:14,881::train::INFO] [Train] Iter 4888 | Loss 0.026276 | Grad 0.0290 \n","[2023-12-09 07:36:14,964::train::INFO] [Train] Iter 4889 | Loss 0.027435 | Grad 0.0300 \n","[2023-12-09 07:36:15,047::train::INFO] [Train] Iter 4890 | Loss 0.024692 | Grad 0.0340 \n","[2023-12-09 07:36:15,132::train::INFO] [Train] Iter 4891 | Loss 0.027537 | Grad 0.0279 \n","[2023-12-09 07:36:15,225::train::INFO] [Train] Iter 4892 | Loss 0.027464 | Grad 0.0332 \n","[2023-12-09 07:36:15,309::train::INFO] [Train] Iter 4893 | Loss 0.026485 | Grad 0.0251 \n","[2023-12-09 07:36:15,393::train::INFO] [Train] Iter 4894 | Loss 0.025268 | Grad 0.0359 \n","[2023-12-09 07:36:15,478::train::INFO] [Train] Iter 4895 | Loss 0.025865 | Grad 0.0263 \n","[2023-12-09 07:36:15,563::train::INFO] [Train] Iter 4896 | Loss 0.024660 | Grad 0.0334 \n","[2023-12-09 07:36:15,647::train::INFO] [Train] Iter 4897 | Loss 0.025513 | Grad 0.0296 \n","[2023-12-09 07:36:15,735::train::INFO] [Train] Iter 4898 | Loss 0.026143 | Grad 0.0423 \n","[2023-12-09 07:36:15,819::train::INFO] [Train] Iter 4899 | Loss 0.027034 | Grad 0.0428 \n","[2023-12-09 07:36:15,902::train::INFO] [Train] Iter 4900 | Loss 0.026720 | Grad 0.0298 \n","[2023-12-09 07:36:15,986::train::INFO] [Train] Iter 4901 | Loss 0.027241 | Grad 0.0314 \n","[2023-12-09 07:36:16,070::train::INFO] [Train] Iter 4902 | Loss 0.026589 | Grad 0.0319 \n","[2023-12-09 07:36:16,155::train::INFO] [Train] Iter 4903 | Loss 0.028661 | Grad 0.0287 \n","[2023-12-09 07:36:16,247::train::INFO] [Train] Iter 4904 | Loss 0.026437 | Grad 0.0319 \n","[2023-12-09 07:36:16,331::train::INFO] [Train] Iter 4905 | Loss 0.029255 | Grad 0.0274 \n","[2023-12-09 07:36:16,414::train::INFO] [Train] Iter 4906 | Loss 0.027449 | Grad 0.0263 \n","[2023-12-09 07:36:16,497::train::INFO] [Train] Iter 4907 | Loss 0.026318 | Grad 0.0297 \n","[2023-12-09 07:36:16,579::train::INFO] [Train] Iter 4908 | Loss 0.026940 | Grad 0.0269 \n","[2023-12-09 07:36:16,662::train::INFO] [Train] Iter 4909 | Loss 0.027672 | Grad 0.0244 \n","[2023-12-09 07:36:16,744::train::INFO] [Train] Iter 4910 | Loss 0.028825 | Grad 0.0307 \n","[2023-12-09 07:36:16,826::train::INFO] [Train] Iter 4911 | Loss 0.029402 | Grad 0.0347 \n","[2023-12-09 07:36:16,909::train::INFO] [Train] Iter 4912 | Loss 0.028376 | Grad 0.0382 \n","[2023-12-09 07:36:16,992::train::INFO] [Train] Iter 4913 | Loss 0.026469 | Grad 0.0270 \n","[2023-12-09 07:36:17,076::train::INFO] [Train] Iter 4914 | Loss 0.026048 | Grad 0.0399 \n","[2023-12-09 07:36:17,161::train::INFO] [Train] Iter 4915 | Loss 0.027273 | Grad 0.0350 \n","[2023-12-09 07:36:17,245::train::INFO] [Train] Iter 4916 | Loss 0.027930 | Grad 0.0292 \n","[2023-12-09 07:36:17,330::train::INFO] [Train] Iter 4917 | Loss 0.024518 | Grad 0.0315 \n","[2023-12-09 07:36:17,414::train::INFO] [Train] Iter 4918 | Loss 0.026812 | Grad 0.0297 \n","[2023-12-09 07:36:17,497::train::INFO] [Train] Iter 4919 | Loss 0.024213 | Grad 0.0333 \n","[2023-12-09 07:36:17,580::train::INFO] [Train] Iter 4920 | Loss 0.025477 | Grad 0.0309 \n","[2023-12-09 07:36:17,664::train::INFO] [Train] Iter 4921 | Loss 0.026236 | Grad 0.0329 \n","[2023-12-09 07:36:17,749::train::INFO] [Train] Iter 4922 | Loss 0.027651 | Grad 0.0311 \n","[2023-12-09 07:36:17,841::train::INFO] [Train] Iter 4923 | Loss 0.028800 | Grad 0.0417 \n","[2023-12-09 07:36:17,943::train::INFO] [Train] Iter 4924 | Loss 0.028286 | Grad 0.0309 \n","[2023-12-09 07:36:18,037::train::INFO] [Train] Iter 4925 | Loss 0.025693 | Grad 0.0256 \n","[2023-12-09 07:36:18,128::train::INFO] [Train] Iter 4926 | Loss 0.027443 | Grad 0.0301 \n","[2023-12-09 07:36:18,219::train::INFO] [Train] Iter 4927 | Loss 0.026312 | Grad 0.0284 \n","[2023-12-09 07:36:18,322::train::INFO] [Train] Iter 4928 | Loss 0.028456 | Grad 0.0404 \n","[2023-12-09 07:36:18,415::train::INFO] [Train] Iter 4929 | Loss 0.024523 | Grad 0.0308 \n","[2023-12-09 07:36:18,506::train::INFO] [Train] Iter 4930 | Loss 0.024564 | Grad 0.0353 \n","[2023-12-09 07:36:18,601::train::INFO] [Train] Iter 4931 | Loss 0.025838 | Grad 0.0274 \n","[2023-12-09 07:36:18,692::train::INFO] [Train] Iter 4932 | Loss 0.029888 | Grad 0.0315 \n","[2023-12-09 07:36:18,783::train::INFO] [Train] Iter 4933 | Loss 0.029248 | Grad 0.0619 \n","[2023-12-09 07:36:18,875::train::INFO] [Train] Iter 4934 | Loss 0.025903 | Grad 0.0333 \n","[2023-12-09 07:36:18,966::train::INFO] [Train] Iter 4935 | Loss 0.027390 | Grad 0.0317 \n","[2023-12-09 07:36:19,057::train::INFO] [Train] Iter 4936 | Loss 0.025453 | Grad 0.0296 \n","[2023-12-09 07:36:19,154::train::INFO] [Train] Iter 4937 | Loss 0.025850 | Grad 0.0322 \n","[2023-12-09 07:36:19,246::train::INFO] [Train] Iter 4938 | Loss 0.024353 | Grad 0.0418 \n","[2023-12-09 07:36:19,339::train::INFO] [Train] Iter 4939 | Loss 0.025051 | Grad 0.0320 \n","[2023-12-09 07:36:19,435::train::INFO] [Train] Iter 4940 | Loss 0.027832 | Grad 0.0311 \n","[2023-12-09 07:36:19,528::train::INFO] [Train] Iter 4941 | Loss 0.029133 | Grad 0.0377 \n","[2023-12-09 07:36:19,619::train::INFO] [Train] Iter 4942 | Loss 0.025105 | Grad 0.0266 \n","[2023-12-09 07:36:19,712::train::INFO] [Train] Iter 4943 | Loss 0.024586 | Grad 0.0288 \n","[2023-12-09 07:36:19,805::train::INFO] [Train] Iter 4944 | Loss 0.027508 | Grad 0.0336 \n","[2023-12-09 07:36:19,899::train::INFO] [Train] Iter 4945 | Loss 0.025280 | Grad 0.0299 \n","[2023-12-09 07:36:19,991::train::INFO] [Train] Iter 4946 | Loss 0.027714 | Grad 0.0282 \n","[2023-12-09 07:36:20,087::train::INFO] [Train] Iter 4947 | Loss 0.025532 | Grad 0.0274 \n","[2023-12-09 07:36:20,177::train::INFO] [Train] Iter 4948 | Loss 0.028158 | Grad 0.0288 \n","[2023-12-09 07:36:20,269::train::INFO] [Train] Iter 4949 | Loss 0.027051 | Grad 0.0389 \n","[2023-12-09 07:36:20,366::train::INFO] [Train] Iter 4950 | Loss 0.027819 | Grad 0.0279 \n","[2023-12-09 07:36:20,462::train::INFO] [Train] Iter 4951 | Loss 0.027730 | Grad 0.0305 \n","[2023-12-09 07:36:20,552::train::INFO] [Train] Iter 4952 | Loss 0.025944 | Grad 0.0453 \n","[2023-12-09 07:36:20,645::train::INFO] [Train] Iter 4953 | Loss 0.026039 | Grad 0.0321 \n","[2023-12-09 07:36:20,736::train::INFO] [Train] Iter 4954 | Loss 0.026393 | Grad 0.0278 \n","[2023-12-09 07:36:20,828::train::INFO] [Train] Iter 4955 | Loss 0.028166 | Grad 0.0291 \n","[2023-12-09 07:36:20,920::train::INFO] [Train] Iter 4956 | Loss 0.028427 | Grad 0.0280 \n","[2023-12-09 07:36:21,014::train::INFO] [Train] Iter 4957 | Loss 0.026194 | Grad 0.0374 \n","[2023-12-09 07:36:21,106::train::INFO] [Train] Iter 4958 | Loss 0.025671 | Grad 0.0309 \n","[2023-12-09 07:36:21,199::train::INFO] [Train] Iter 4959 | Loss 0.028067 | Grad 0.0291 \n","[2023-12-09 07:36:21,292::train::INFO] [Train] Iter 4960 | Loss 0.024495 | Grad 0.0275 \n","[2023-12-09 07:36:21,384::train::INFO] [Train] Iter 4961 | Loss 0.025287 | Grad 0.0246 \n","[2023-12-09 07:36:21,480::train::INFO] [Train] Iter 4962 | Loss 0.027077 | Grad 0.0312 \n","[2023-12-09 07:36:21,573::train::INFO] [Train] Iter 4963 | Loss 0.028203 | Grad 0.0303 \n","[2023-12-09 07:36:21,664::train::INFO] [Train] Iter 4964 | Loss 0.026369 | Grad 0.0274 \n","[2023-12-09 07:36:21,756::train::INFO] [Train] Iter 4965 | Loss 0.025443 | Grad 0.0305 \n","[2023-12-09 07:36:21,848::train::INFO] [Train] Iter 4966 | Loss 0.026304 | Grad 0.0260 \n","[2023-12-09 07:36:21,938::train::INFO] [Train] Iter 4967 | Loss 0.026265 | Grad 0.0257 \n","[2023-12-09 07:36:22,031::train::INFO] [Train] Iter 4968 | Loss 0.026165 | Grad 0.0289 \n","[2023-12-09 07:36:22,123::train::INFO] [Train] Iter 4969 | Loss 0.025304 | Grad 0.0278 \n","[2023-12-09 07:36:22,215::train::INFO] [Train] Iter 4970 | Loss 0.028355 | Grad 0.0310 \n","[2023-12-09 07:36:22,311::train::INFO] [Train] Iter 4971 | Loss 0.027961 | Grad 0.0295 \n","[2023-12-09 07:36:22,403::train::INFO] [Train] Iter 4972 | Loss 0.026118 | Grad 0.0336 \n","[2023-12-09 07:36:22,495::train::INFO] [Train] Iter 4973 | Loss 0.026912 | Grad 0.0314 \n","[2023-12-09 07:36:22,590::train::INFO] [Train] Iter 4974 | Loss 0.027348 | Grad 0.0258 \n","[2023-12-09 07:36:22,684::train::INFO] [Train] Iter 4975 | Loss 0.025299 | Grad 0.0301 \n","[2023-12-09 07:36:22,778::train::INFO] [Train] Iter 4976 | Loss 0.028402 | Grad 0.0286 \n","[2023-12-09 07:36:22,870::train::INFO] [Train] Iter 4977 | Loss 0.025648 | Grad 0.0299 \n","[2023-12-09 07:36:22,961::train::INFO] [Train] Iter 4978 | Loss 0.029495 | Grad 0.0267 \n","[2023-12-09 07:36:23,054::train::INFO] [Train] Iter 4979 | Loss 0.025992 | Grad 0.0238 \n","[2023-12-09 07:36:23,147::train::INFO] [Train] Iter 4980 | Loss 0.027417 | Grad 0.0282 \n","[2023-12-09 07:36:23,240::train::INFO] [Train] Iter 4981 | Loss 0.026111 | Grad 0.0317 \n","[2023-12-09 07:36:23,331::train::INFO] [Train] Iter 4982 | Loss 0.025692 | Grad 0.0260 \n","[2023-12-09 07:36:23,422::train::INFO] [Train] Iter 4983 | Loss 0.026205 | Grad 0.0328 \n","[2023-12-09 07:36:23,519::train::INFO] [Train] Iter 4984 | Loss 0.027301 | Grad 0.0404 \n","[2023-12-09 07:36:23,610::train::INFO] [Train] Iter 4985 | Loss 0.026254 | Grad 0.0297 \n","[2023-12-09 07:36:23,702::train::INFO] [Train] Iter 4986 | Loss 0.027187 | Grad 0.0278 \n","[2023-12-09 07:36:23,807::train::INFO] [Train] Iter 4987 | Loss 0.027351 | Grad 0.0229 \n","[2023-12-09 07:36:23,899::train::INFO] [Train] Iter 4988 | Loss 0.024576 | Grad 0.0250 \n","[2023-12-09 07:36:23,994::train::INFO] [Train] Iter 4989 | Loss 0.027924 | Grad 0.0379 \n","[2023-12-09 07:36:24,080::train::INFO] [Train] Iter 4990 | Loss 0.024848 | Grad 0.0272 \n","[2023-12-09 07:36:24,163::train::INFO] [Train] Iter 4991 | Loss 0.027509 | Grad 0.0306 \n","[2023-12-09 07:36:24,246::train::INFO] [Train] Iter 4992 | Loss 0.026430 | Grad 0.0289 \n","[2023-12-09 07:36:24,329::train::INFO] [Train] Iter 4993 | Loss 0.028580 | Grad 0.0245 \n","[2023-12-09 07:36:24,415::train::INFO] [Train] Iter 4994 | Loss 0.026603 | Grad 0.0275 \n","[2023-12-09 07:36:24,499::train::INFO] [Train] Iter 4995 | Loss 0.026816 | Grad 0.0255 \n","[2023-12-09 07:36:24,587::train::INFO] [Train] Iter 4996 | Loss 0.026681 | Grad 0.0299 \n","[2023-12-09 07:36:24,672::train::INFO] [Train] Iter 4997 | Loss 0.026560 | Grad 0.0347 \n","[2023-12-09 07:36:24,756::train::INFO] [Train] Iter 4998 | Loss 0.025041 | Grad 0.0258 \n","[2023-12-09 07:36:24,839::train::INFO] [Train] Iter 4999 | Loss 0.026083 | Grad 0.0273 \n","[2023-12-09 07:36:24,922::train::INFO] [Train] Iter 5000 | Loss 0.026539 | Grad 0.0231 \n","Validate: 100% 241/241 [00:03<00:00, 60.51it/s]\n","val loss list [tensor(0.0289, device='cuda:0'), tensor(0.0245, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0247, device='cuda:0'), tensor(0.0223, device='cuda:0'), tensor(0.0211, device='cuda:0'), tensor(0.0234, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0227, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0232, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0227, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0293, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0230, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0226, device='cuda:0'), tensor(0.0310, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0225, device='cuda:0'), tensor(0.0294, device='cuda:0'), tensor(0.0236, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0263, device='cuda:0'), tensor(0.0256, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0240, device='cuda:0'), tensor(0.0245, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0242, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0279, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0220, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0247, device='cuda:0'), tensor(0.0238, device='cuda:0'), tensor(0.0305, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0305, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0324, device='cuda:0'), tensor(0.0317, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0216, device='cuda:0'), tensor(0.0239, device='cuda:0'), tensor(0.0251, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0247, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0247, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0281, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0277, device='cuda:0'), tensor(0.0267, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0248, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0328, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0303, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0308, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0257, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0234, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0226, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0231, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0237, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0244, device='cuda:0'), tensor(0.0222, device='cuda:0'), tensor(0.0256, device='cuda:0'), tensor(0.0280, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0230, device='cuda:0'), tensor(0.0245, device='cuda:0'), tensor(0.0256, device='cuda:0'), tensor(0.0211, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0274, device='cuda:0'), tensor(0.0244, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0258, device='cuda:0'), tensor(0.0251, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0239, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0234, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0248, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0187, device='cuda:0'), tensor(0.0231, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0207, device='cuda:0'), tensor(0.0321, device='cuda:0'), tensor(0.0234, device='cuda:0'), tensor(0.0246, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0262, device='cuda:0'), tensor(0.0234, device='cuda:0'), tensor(0.0259, device='cuda:0'), tensor(0.0230, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0245, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0232, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0319, device='cuda:0'), tensor(0.0254, device='cuda:0'), tensor(0.0261, device='cuda:0'), tensor(0.0241, device='cuda:0'), tensor(0.0244, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0316, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0223, device='cuda:0'), tensor(0.0286, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0251, device='cuda:0'), tensor(0.0238, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0296, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0239, device='cuda:0'), tensor(0.0253, device='cuda:0'), tensor(0.0267, device='cuda:0'), tensor(0.0249, device='cuda:0'), tensor(0.0244, device='cuda:0'), tensor(0.0288, device='cuda:0'), tensor(0.0249, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0235, device='cuda:0'), tensor(0.0318, device='cuda:0'), tensor(0.0250, device='cuda:0'), tensor(0.0284, device='cuda:0'), tensor(0.0264, device='cuda:0'), tensor(0.0258, device='cuda:0'), tensor(0.0252, device='cuda:0'), tensor(0.0239, device='cuda:0'), tensor(0.0237, device='cuda:0'), tensor(0.0287, device='cuda:0'), tensor(0.0247, device='cuda:0'), tensor(0.0251, device='cuda:0'), tensor(0.0314, device='cuda:0'), tensor(0.0238, device='cuda:0'), tensor(0.0228, device='cuda:0'), tensor(0.0260, device='cuda:0'), tensor(0.0312, device='cuda:0'), tensor(0.0300, device='cuda:0'), tensor(0.0228, device='cuda:0'), tensor(0.0222, device='cuda:0'), tensor(0.0289, device='cuda:0'), tensor(0.0222, device='cuda:0'), tensor(0.0255, device='cuda:0'), tensor(0.0282, device='cuda:0'), tensor(0.0272, device='cuda:0'), tensor(0.0248, device='cuda:0'), tensor(0.0241, device='cuda:0'), tensor(0.0258, device='cuda:0'), tensor(0.0266, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0240, device='cuda:0'), tensor(0.0265, device='cuda:0'), tensor(0.0304, device='cuda:0'), tensor(0.0291, device='cuda:0'), tensor(0.0246, device='cuda:0'), tensor(0.0245, device='cuda:0'), tensor(0.0270, device='cuda:0'), tensor(0.0247, device='cuda:0'), tensor(0.0283, device='cuda:0'), tensor(0.0297, device='cuda:0'), tensor(0.0268, device='cuda:0'), tensor(0.0276, device='cuda:0'), tensor(0.0227, device='cuda:0'), tensor(0.0275, device='cuda:0'), tensor(0.0175, device='cuda:0'), tensor(0.0242, device='cuda:0'), tensor(0.0271, device='cuda:0'), tensor(0.0273, device='cuda:0'), tensor(0.0298, device='cuda:0'), tensor(0.0290, device='cuda:0'), tensor(0.0190, device='cuda:0'), tensor(0.0225, device='cuda:0'), tensor(0.0241, device='cuda:0'), tensor(0.0269, device='cuda:0'), tensor(0.0278, device='cuda:0'), tensor(0.0316, device='cuda:0')]\n"]}]}]}